title,abstract,year,annotation
$_texttt{LeadCache}$_ Regret-Optimal Caching in Networks,"LeadCache : Regret-Optimal Caching in Networks
Debjit Paria∗
Department of Computer Science
Chennai Mathematical Institute
Chennai 603103, India
debjit.paria1999@gmail.comAbhishek Sinha
Department of Electrical Engineering
Indian Institute of Technology Madras
Chennai 600036, India
abhishek.sinha@ee.iitm.ac.in
Abstract
We consider an online prediction problem in the context of network caching.
Assume that multiple users are connected to several caches via a bipartite network.
At any time slot, e",2021,Unknown
(Almost) Free Incentivized Exploration from Decentralized Learning Agents,"(Almost) Free Incentivized Exploration from
Decentralized Learning Agents
Chengshuai Shi
University of Virginia
cs7ync@virginia.eduHaifeng Xu
University of Virginia
hx4ad@virginia.edu
Wei Xiong
The Hong Kong University of Science and Technology
wxiongae@connect.ust.hkCong Shen
University of Virginia
cong@virginia.edu
Abstract
Incentivized exploration in multi-armed bandits (MAB) has witnessed increasing
interests and many progresses in recent years, where a principal offers bonuses to
agents to ",2021,Unknown
3D Pose Transfer with Correspondence Learning and Mesh Refinement,"3D Pose Transfer with Correspondence Learning and
Mesh Reﬁnement
Chaoyue Song1, Jiacheng Wei2, Ruibo Li1,3, Fayao Liu4and Guosheng Lin1,3
1S-Lab, Nanyang Technological University, Singapore
2School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore
3School of Computer Science and Engineering, Nanyang Technological University, Singapore
4Institute for Inforcomm Research, A*STAR, Singapore
{chaoyue.song, gslin}@ntu.edu.sg
Abstract
3D pose transfer is one of the ",2021,Unknown
A Bayesian-Symbolic Approach to Reasoning and Learning in Intuitive Physics,"A Bayesian-Symbolic Approach to
Reasoning and Learning in Intuitive Physics
Kai Xu
University of Edinburgh
contact@xuk.aiAkash Srivastava
MIT-IBM Watson AI Lab
akash.srivastava@ibm.com
Dan Gutfreund
MIT-IBM Watson AI Lab
dgutfre@us.ibm.comFelix A. Sosa
Harvard University
fsosa@fas.harvard.eduTomer Ullman
Harvard University
tomerullman@gmail.com
Joshua B. Tenenbaum
Massachusetts Institute of Technology
jbt@mit.eduCharles Sutton
University of Edinburgh & Google AI
c.sutton@ed.ac.uk
Abstract
Humans",2021,Unknown
A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning,"A Consciousness-Inspired Planning Agent for
Model-Based Reinforcement Learning
Mingde Zhao14, Zhen Liu24, Sitao Luan14, Shuyuan Zhang14
Doina Precup1345y, Yoshua Bengio245y
1McGill University;2Université de Montréal;3DeepMind;4Mila;5CIFAR AI Chair
: Equal Contribution,y: Equal Supervision
Abstract
We present an end-to-end, model-based deep reinforcement learning agent
whichdynamicallyattendstorelevantpartsofitsstateduringplanning. The
agent uses a bottleneck mechanism over a se",2021,Unknown
A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering,"A Constant Approximation Algorithm for Sequential
Random-Order No-Substitution k-Median Clustering
Tom Hess
Department of Computer Science
Ben-Gurion University of the Negev
Beer-Sheva, Israel
tomhe@post.bgu.ac.ilMichal Moshkovitz
Department of Computer Science
Tel-Aviv University
Tel Aviv, Israel
mmoshkovitz@eng.ucsd.edu
Sivan Sabato
Department of Computer Science
Ben-Gurion University of the Negev
Beer-Sheva, Israel
sabatos@cs.bgu.ac.il
Abstract
We studyk-median clustering under the sequentia",2021,Unknown
A Contrastive Learning Approach for Training Variational Autoencoder Priors,"A Contrastive Learning Approach for Training
Variational Autoencoder Priors
Jyoti Aneja1, Alexander G. Schwing1, Jan Kautz2, Arash Vahdat2
1University of Illinois at Urbana-Champaign,2NVIDIA
1{janeja2, aschwing}@illinois.edu,2{jkautz,avahdat}@nvidia.com
Abstract
Variational autoencoders (V AEs) are one of the powerful likelihood-based gen-
erative models with applications in many domains. However, they struggle to
generate high-quality images, especially when samples are obtained from the prior
",2021,Unknown
A Critical Look at the Consistency of Causal Estimation with Deep Latent Variable Models,"A Critical Look at the Consistency of Causal
Estimation with Deep Latent Variable Models
Severi Rissanen
Department of Computer Science
Aalto University
Espoo, Finland
severi.rissanen@aalto.fiPekka Marttinen
Department of Computer Science
Aalto University
Espoo, Finland
pekka.marttinen@aalto.fi
Abstract
Using deep latent variable models in causal inference has attracted considerable
interest recently, but an essential open question is their ability to yield consistent
causal estimates. While the",2021,Unknown
A Gang of Adversarial Bandits,"A Gang of Adversarial Bandits
Mark Herbster*, Stephen Pasteris*
Department of Computer Science
University College London
London WC1E 6BT
{m.herbster,s.pasteris}@cs.ucl.ac.ukFabio Vitale
University of Lille
59653 Villeneuve d’Ascq CEDEX
France
fabio.vitale2@univ-lille.fr
Massimiliano Pontil
CSML, Istituto Italiano di Tecnologia and
Department of Computer Science
University College London
massimiliano.pontil@iit.it
Abstract
We consider running multiple instances of multi-armed bandit (MAB) problem",2021,Unknown
A No-go Theorem for Robust Acceleration in the Hyperbolic Plane,"A No-go Theorem for Robust Acceleration in the
Hyperbolic Plane
Linus HamiltonAnkur Moitray
Abstract
In recent years there has been signiﬁcant effort to adapt the key tools and ideas in
convex optimization to the Riemannian setting. One key challenge has remained: Is
there a Nesterov-like accelerated gradient method for geodesically convex functions
on a Riemannian manifold? Recent work has given partial answers and the hope
was that this ought to be possible. Here we prove that in a noisy sett",2021,Unknown
A Winning Hand_ Compressing Deep Networks Can Improve Out-of-Distribution Robustness,"A Winning Hand : Compressing Deep Networks Can
Improve Out-Of-Distribution Robustness
James Diffenderfer, Brian R. Bartoldson, Shreya Chaganti, Jize Zhang, Bhavya Kailkhura
Lawrence Livermore National Laboratory
{diffenderfer2, bartoldson, chaganti1, zhang64, kailkhura1}@llnl.gov
Abstract
Successful adoption of deep learning (DL) in the wild requires models to be: (1)
compact, (2) accurate, and (3) robust to distributional shifts. Unfortunately, efforts
towards simultaneously meeting these req",2021,Unknown
Accumulative Poisoning Attacks on Real-time Data,"Accumulative Poisoning Attacks on Real-time Data
Tianyu Pang1, Xiao Yang1, Yinpeng Dong1;2, Hang Su1;3, Jun Zhuy1;2;3
1Department of Computer Science & Technology, Institute for AI, BNRist Center,
Tsinghua-Bosch Joint ML Center, THBI Lab, Tsinghua University2RealAI
3Tsinghua University-China Mobile Communications Group Co., Ltd. Joint Institute
{pty17,yangxiao19,dyp17}@mails.tsinghua.edu.cn, {suhangss,dcszj}@tsinghua.edu.cn
Abstract
Collecting training data from untrusted sources exposes machi",2021,Unknown
Accurately Solving Rod Dynamics with Graph Learning,"Accurately Solving Rod Dynamics
with Graph Learning
Han Shao
KAUST
han.shao@kaust.edu.saTassilo Kugelstadt
RWTH Aachen University
kugelstadt@cs.rwth-aachen.de
Torsten H ¨adrich
KAUST
torsten.hadrich@kaust.edu.saWojciech Pałubicki
AMU
wp06@amu.edu.plJan Bender
RWTH Aachen University
bender@cs.rwth-aachen.de
S¨oren Pirk
Google Research
pirk@google.comDominik L. Michels
KAUST
dominik.michels@kaust.edu.sa
Abstract
Iterative solvers are widely used to accurately simulate physical systems. These
solve",2021,Unknown
Adaptable Agent Populations via a Generative Model of Policies,"Adaptable Agent Populations
via a Generative Model of Policies
Kenneth Derek
MIT CSAIL
kderek@alum.mit.eduPhillip Isola
MIT CSAIL
phillipi@mit.edu
Abstract
In the natural world, life has found innumerable ways to survive and often thrive.
Between and even within species, each individual is in some manner unique, and
this diversity lends adaptability and robustness to life. In this work, we aim to
learn a space of diverse and high-reward policies in a given environment. To this
end, we introduce ",2021,Unknown
Adaptive Conformal Inference Under Distribution Shift,"Adaptive Conformal Inference
Under Distribution Shift
Isaac Gibbs
Department of Statistics
Stanford University
igibbs@stanford.eduEmmanuel J. Candès
Department of Statistics
Department of Mathematics
Stanford University
candes@stanford.edu
Abstract
We develop methods for forming prediction sets in an online setting where the data
generating distribution is allowed to vary over time in an unknown fashion. Our
framework builds on ideas from conformal inference to provide a general wrapper
that can",2021,Unknown
Adaptive Data Augmentation on Temporal Graphs,"Adaptive Data Augmentation on Temporal Graphs
Yiwei Wang1Yujun Cai2Yuxuan Liang1Henghui Ding3
Changhu Wang3Siddharth Bhatia1Bryan Hooi1
1National University of Singapore
2Nanyang Technological University
3ByteDance
wangyw_seu@foxmail.com, {yujun001,ding0093}@e.ntu.edu.sg,
yuxliang@outlook.com, changhu.wang@gmail.com,
{siddharth,bhooi}@comp.nus.edu.sg
Abstract
Temporal Graph Networks (TGNs) are powerful on modeling temporal graph data
based on their increased complexity. Higher complexity carries",2021,Unknown
Adversarial Attacks on Black Box Video Classifiers_ Leveraging the Power of Geometric Transformations,"Adversarial Attacks on Black Box Video Classiﬁers:
Leveraging the Power of Geometric Transformations
Shasha Li, Abhishek Aich, Shitong Zhu, M. Salman Asif, Chengyu Song,
Srikanth V . Krishnamurthy, Amit K. Roy-Chowdhury
University of California, Riverside, CA, USA
Abstract
When compared to the image classiﬁcation models, black-box adversarial attacks
against video classiﬁcation models have been largely understudied. This could be
possible because, with video, the temporal dimension poses signi",2021,Unknown
Adversarial Robustness of Streaming Algorithms through Importance Sampling,"Adversarial Robustness of Streaming Algorithms
through Importance Sampling
Vladimir Braverman
Google
vbraverman@google.comAvinatan Hassidim
Google
avinatan@google.comYossi Matias
Google
yossi@google.com
Mariano Schain
Google
marianos@google.comSandeep Silwal
MIT
silwal@mit.eduSamson Zhou
Carnegie Mellon University
samsonzhou@gmail.com
Abstract
Robustness against adversarial attacks has recently been at the forefront of algo-
rithmic design for machine learning tasks. In the adversarial streaming",2021,Unknown
Algorithmic Instabilities of Accelerated Gradient Descent,"Algorithmic Instabilities
of Accelerated Gradient Descent
Amit Attia
Blavatnik School of Computer Science
Tel Aviv University
amitattia@mail.tau.ac.ilTomer Koren
Blavatnik School of Computer Science
Tel Aviv University, and Google Research
tkoren@tauex.tau.ac.il
Abstract
We studythe algorithmic stability of Nesterov’saccelerated gradient method. For
convexquadraticobjectives,Chenetal. [10]provedthattheuniformstabilityofthe
methodgrowsquadraticallywiththenumberofoptimizationsteps,andconjectured
t",2021,Unknown
Alias-Free Generative Adversarial Networks,"Alias-Free Generative Adversarial Networks
Tero Karras
NVIDIA
tkarras@nvidia.comMiika Aittala
NVIDIA
maittala@nvidia.comSamuli Laine
NVIDIA
slaine@nvidia.com
Erik Härkönen
Aalto University and NVIDIA
erik.harkonen@aalto.fiJanne Hellsten
NVIDIA
jhellsten@nvidia.com
Jaakko Lehtinen
NVIDIA and Aalto University
jlehtinen@nvidia.comTimo Aila
NVIDIA
taila@nvidia.com
Abstract
We observe that despite their hierarchical convolutional nature, the synthesis
process of typical generative adversarial networ",2021,Unknown
Aligned Structured Sparsity Learning for Efficient Image Super-Resolution,"Aligned Structured Sparsity Learning for Efﬁcient
Image Super-Resolution
Yulun Zhang1;yHuan Wang1;y;Can Qin1Yun Fu1;2
1Department of ECE, Northeastern University
2Khoury College of Computer Science, Northeastern University
Abstract
Lightweight image super-resolution (SR) networks have obtained promising re-
sults with moderate model size. Many SR methods have focused on designing
lightweight architectures, which neglect to further reduce the redundancy of net-
work parameters. On the other hand",2021,Unknown
Aligning Silhouette Topology for Self-Adaptive 3D Human Pose Recovery,"Aligning Silhouette Topology for Self-Adaptive
3D Human Pose Recovery
Mugalodi Rakesh1Jogendra Nath Kundu1Varun Jampani2R. Venkatesh Babu1
1Indian Institute of Science, Bangalore2Google Research
Abstract
Articulation-centric 2D/3D pose supervision forms the core training objective in
most existing 3D human pose estimation techniques. Except for synthetic source
environments, acquiring such rich supervision for each real target domain at de-
ployment is highly inconvenient. However, we realize ",2021,Unknown
An Analysis of Constant Step Size SGD in the Non-convex Regime_ Asymptotic Normality and Bias,"An Analysis of Constant Step Size SGD in the
Non-convex Regime: Asymptotic Normality and Bias
Lu Yu
University of Toronto & Vector Institute
stat.yu@mail.utoronto.caKrishnakumar Balasubramanian
University of California, Davis
kbala@ucdavis.edu
Stanislav Volgushev
University of Toronto
stanislav.volgushev@utoronto.caMurat A. Erdogdu
University of Toronto & Vector Institute
erdogdu@cs.toronto.edu
Abstract
Structured non-convex learning problems, for which critical points have favorable
statistical",2021,Unknown
An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders,"Improved Analysis and Rates for Variance Reduction
under Without-replacement Sampling Orders
Xinmeng Huang
University of Pennsylvania
Philadelphia, PA 19104
xinmengh@sas.upenn.eduKun Yuan
DAMO Academy, Alibaba Group
Bellevue, WA 98004
kun.yuan@alibaba-inc.com
Xianghui Mao
Tsinghua University
Beijing, China 100084
xianghui.xh.mao@gmail.comWotao Yin
DAMO Academy, Alibaba Group
Bellevue, WA 98004
wotao.yin@alibaba-inc.com
Abstract
When applying a stochastic algorithm, one must choose an order to ",2021,Unknown
Analytical Study of Momentum-Based Acceleration Methods in Paradigmatic High-Dimensional Non-Convex Problems,"Analytical Study of Momentum-Based Acceleration
Methods in Paradigmatic High-Dimensional
Non-Convex Problems
Stefano Sarao Mannelli
Department of Experimental Psychology
University of Oxford
Oxford, United Kingdom
stefano.saraomannelli@psy.ox.ac.ukPierfrancesco Urbani
Universit ´e Paris-Saclay, CNRS, CEA
Institut de physique th ´eorique
Gif-sur-Yvette, France
pierfrancesco.urbani@ipht.fr
Abstract
The optimization step in many machine learning problems rarely relies on vanilla
gradient descent bu",2021,Unknown
Approximate Decomposable Submodular Function Minimization for Cardinality-Based Components,"Approximate Decomposable Submodular Function
Minimization for Cardinality-Based Components
Nate Veldt
nveldt@tamu.edu
Texas A&M UniversityAustin R. Benson
arb@cs.cornell.edu
Cornell UniversityJon Kleinberg
kleinberg@cornell.edu
Cornell University
Abstract
Minimizing a sum of simple submodular functions of limited support is a spe-
cial case of general submodular function minimization that has seen numerous
applications in machine learning. We develop fast techniques for instances where
componen",2021,Unknown
Approximating the Permanent with Deep Rejection Sampling,"Approximating the Permanent with
Deep Rejection Sampling
Juha Harviainen
University of Helsinki
juha.harviainen@helsinki.fiAntti Röyskö
ETH Zürich
aroeyskoe@ethz.ch
Mikko Koivisto
University of Helsinki
mikko.koivisto@helsinki.fi
Abstract
We present a randomized approximation scheme for the permanent of a matrix with
nonnegative entries. Our scheme extends a recursive rejection sampling method
of Huber and Law (SODA 2008) by replacing the upper bound for the permanent
with a linear combination o",2021,Unknown
Arbitrary Conditional Distributions with Energy,"Arbitrary Conditional Distributions with Energy
Ryan R. Strauss
Department of Computer Science
UNC at Chapel Hill
Chapel Hill, NC 27514
rrs@cs.unc.eduJunier B. Oliva
Department of Computer Science
UNC at Chapel Hill
Chapel Hill, NC 27514
joliva@cs.unc.edu
Abstract
Modeling distributions of covariates, or density estimation , is a core challenge in
unsupervised learning. However, the majority of work only considers the joint
distribution, which has limited utility in practical situations. A more ",2021,Unknown
Associating Objects with Transformers for Video Object Segmentation,"Associating Objects with Transformers for
Video Object Segmentation
Zongxin Yang1,2, Yunchao Wei3,4, Yi Yang1
1CCAI, College of Computer Science and Technology, Zhejiang University2Baidu Research
3Institute of Information Science, Beijing Jiaotong University
4Beijing Key Laboratory of Advanced Information Science and Network
{zongxinyang1996, wychao1987, yee.i.yang}@gmail.com
Abstract
This paper investigates how to realize better and more efficient embedding learn-
ing to tackle the semi-supervi",2021,Unknown
Associative Memories via Predictive Coding,"Associative Memories via Predictive Coding
Tommaso Salvatori1, Yuhang Song1;3;, Yujian Hong1, Lei Sha1, Simon Frieder1,
Zhenghua Xu2, Rafal Bogacz3, Thomas Lukasiewicz1
1Department of Computer Science, University of Oxford, UK
2State Key Laboratory of Reliability and Intelligence of Electrical Equipment,
Hebei University of Technology, Tianjin, China
3MRC Brain Network Dynamics Unit, University of Oxford, UK
{tommaso.salvatori, yuhang.song, yujian.hong, lei.sha, frieder.simon, thomas.lukasiewic",2021,Unknown
AugMax_ Adversarial Composition of Random Augmentations for Robust Training,"AugMax: Adversarial Composition of Random
Augmentations for Robust Training
Haotao Wang1,Chaowei Xiao2,3,Jean Kossaiﬁ2,Zhiding Yu2,
Anima Anandkumar2,4, and Zhangyang Wang1
1Department of Electrical and Computer Engineering, University of Texas at Austin
2NVIDIA3Arizona State University4California Institute of Technology
1{htwang, atlaswang}@utexas.edu
2{chaoweix, jkossaiﬁ, zhidingy, aanandkumar}@nvidia.com
Abstract
Data augmentation is a simple yet effective way to improve the robustness of de",2021,Unknown
AutoBalance_ Optimized Loss Functions for Imbalanced Data,"AutoBalance: Optimized Loss Functions for
Imbalanced Data
Mingchen Li Xuechen Zhang
University of California, Riverside
{mli176,xzhan394}@ucr.eduChristos Thrampoulidis
University of British Columbia
cthrampo@ece.ubc.edu.ca
Jiasi Chen
University of California, Riverside
jiasi@cs.ucr.eduSamet Oymak
University of California, Riverside
oymak@ece.ucr.edu
Abstract
Imbalanced datasets are commonplace in modern machine learning problems. The
presence of under-represented classes or groups with sensitive",2021,Unknown
Automatic Symmetry Discovery with Lie Algebra Convolutional Network,"Automatic Symmetry Discovery with Lie Algebra
Convolutional Network
Nima Dehmamy
Northwestern University
nimadt@bu.eduRobin Walters
Northeastern University
rwalters@northeastern.edu
Yanchen Liu
Northeastern University
liu.yanc@northeastern.eduDashun Wang
Northwestern University
dashun.wang@kellogg.northwestern.edu
Rose Yu
University of California San Diego
roseyu@ucsd.edu
Abstract
Existing equivariant neural networks require prior knowledge of the symmetry
group and discretization for continuous",2021,Unknown
Automatic Unsupervised Outlier Model Selection,"Automatic Unsupervised Outlier Model Selection
Yue Zhao
Carnegie Mellon University
zhaoy@cmu.eduRyan A. Rossi
Adobe Research
ryrossi@adobe.comLeman Akoglu
Carnegie Mellon University
lakoglu@andrew.cmu.edu
Abstract
Given an unsupervised outlier detection task on a new dataset, how can we au-
tomatically select a good outlier detection algorithm and its hyperparameter(s)
(collectively called a model)? In this work, we tackle the unsupervised outlier
model selection (UOMS) problem, and propose META",2021,Unknown
Backward-Compatible Prediction Updates_ A Probabilistic Approach,"Backward-Compatible Prediction Updates:
A Probabilistic Approach
Frederik Tr ¨auble1yJulius von K ¨ugelgen1,3Matth ¨aus Kleindessner2
Francesco Locatello2Bernhard Sch ¨olkopf2Peter Gehler2y
1Max Planck Institute for Intelligent Systems, T ¨ubingen, Germany
2Amazon T ¨ubingen, Germany
3Department of Engineering, University of Cambridge, United Kingdom
Abstract
When machine learning systems meet real world applications, accuracy is only
one of several requirements. In this paper, we assay a comp",2021,Unknown
BAST_ Bayesian Additive Regression Spanning Trees for Complex Constrained Domain,"BAST: Bayesian Additive Regression Spanning Trees
for Complex Constrained Domain
Zhao Tang Luo
Department of Statistics
Texas A&M University
ztluo@stat.tamu.eduHuiyan Sang
Department of Statistics
Texas A&M University
huiyan@stat.tamu.eduBani Mallick
Department of Statistics
Texas A&M University
bmallick@stat.tamu.edu
Abstract
Nonparametric regression on complex domains has been a challenging task as
most existing methods, such as ensemble models based on binary decision trees,
are not designed ",2021,Unknown
Batch Normalization Orthogonalizes Representations in Deep Random Networks,"Batch Normalization Orthogonalizes Representations
in Deep Random Networks
Hadi Daneshmand
INRIA Paris
seyed.daneshmand@inria.frAmir Joudaki
ETH Zurich
amir.joudaki@inf.ethz.ch
Francis Bach
INRIA-ENS-PSL Paris
francis.bach@inria.fr
Abstract
This paper underlines a subtle property of batch-normalization (BN): Successive
batch normalizations with random linear transformations make hidden representa-
tions increasingly orthogonal across layers of a deep neural network. We establish
a non-asymptotic",2021,Unknown
BatchQuant_ Quantized-for-all Architecture Search with Robust Quantizer,"BatchQuant: Quantized-for-all Architecture Search
with Robust Quantizer
Haoping Bai∗Meng Cao Ping Huang Jiulong Shan
Apple
{haoping_bai, mengcao, huang_ping, jiulong_shan}@apple.com
Abstract
As the applications of deep learning models on edge devices increase at an acceler-
ating pace, fast adaptation to various scenarios with varying resource constraints
has become a crucial aspect of model deployment. As a result, model optimization
strategies with adaptive configuration are becoming increasin",2021,Unknown
Bayesian Adaptation for Covariate Shift,"Training on Test Data with Bayesian Adaptation for
Covariate Shift
Aurick Zhou, Sergey Levine
Department of Electrical Engineering and Computer Sciences
University of California, Berkeley
{aurick,svlevine}@berkeley.edu
Abstract
When faced with distribution shift at test time, deep neural networks often make
inaccurate predictions with unreliable uncertainty estimates. While improving the
robustness of neural networks is one promising approach to mitigate this issue, an
appealing alternate to rob",2021,Unknown
BayesIMP_ Uncertainty Quantification for Causal Data Fusion,"BAYES IMP: Uncertainty Quantiﬁcation for Causal Data Fusion
Siu Lun Chau
University of OxfordJean-François Ton
University of OxfordJavier González
Microsoft Research Cambridge
Yee Whye Teh
University of OxfordDino Sejdinovic
University of Oxford
Abstract
While causal models are becoming one of the mainstays of machine learning, the
problem of uncertainty quantiﬁcation in causal inference remains challenging. In
this paper, we study the causal data fusion problem, where datasets pertaining to
m",2021,Unknown
Beltrami Flow and Neural Diffusion on Graphs,"Beltrami Flow and Neural Diffusion on Graphs
Benjamin P. Chamberlain
Twitter Inc.
bchamberlain@twitter.comJames Rowbottom
Twitter Inc.Davide Eynard
Twitter Inc.
Francesco Di Giovanni
Twitter Inc.Xiaowen Dong
University of OxfordMichael M. Bronstein
Twitter Inc. and Imperial College London
Abstract
We propose a novel class of graph neural networks based on the discretised Beltrami
ﬂow, a non-Euclidean diffusion PDE. In our model, node features are supplemented
with positional encodings derived ",2021,Unknown
Beyond BatchNorm_ Towards a Unified Understanding of Normalization in Deep Learning,"Beyond BatchNorm: Towards a Uniﬁed
Understanding of Normalization in Deep Learning
Ekdeep Singh Lubana1, Robert P. Dick1, Hidenori Tanaka2;3
1EECS Department, University of Michigan
2Department of Applied Physics, Stanford University
3Physics & Informatics Laboratories, NTT Research, Inc.
Abstract
Inspired by BatchNorm, there has been an explosion of normalization layers in
deep learning. Recent works have identiﬁed a multitude of beneﬁcial properties
in BatchNorm to explain its success. Howeve",2021,Unknown
Beyond Value-Function Gaps_ Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning,"Beyond Value-Function Gaps: Improved
Instance-Dependent Regret Bounds for Episodic
Reinforcement Learning
Chris Dann
Google Research
chrisdann@google.comTeodor V . Marinov
Google Research
tvmarinov@google.com
Mehryar Mohri
Courant Institute and Google Research
mohri@google.comJulian Zimmert
Google Research
zimmert@google.com
Abstract
We provide improved gap-dependent regret bounds for reinforcement learning in
ﬁnite episodic Markov decision processes. Compared to prior work, our bounds
depend o",2021,Unknown
Bias Out-of-the-Box_ An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models,"Bias Out-of-the-Box: An Empirical Analysis of
Intersectional Occupational Biases in Popular
Generative Language Models
Hannah Rose Kirkyz, Yennie Juny, Haider Iqbaly, Elias Benussiy,
Filippo Volpiny, Frederic A. Dreyery, Aleksandar Shtedritskiy, Yuki M. Asanoy
yOxford Artiﬁcial Intelligence Society, University of Oxford
zhannah.kirk@oii.ox.ac.uk
Abstract
The capabilities of natural language models trained on large-scale data have in-
creased immensely over the past few years. Open source librari",2021,Unknown
Breaking the Dilemma of Medical Image-to-image Translation,"Breaking the Dilemma of Medical Image-to-image
Translation
Lingke Kong∗
Manteia Tech
konglingke@manteiatech.comChenyu Lian∗
Xiamen University
cylian@stu.xmu.edu.cn
Detian Huang
Huaqiao University
huangdetian@hqu.edu.cnZhenjiang Li
Shandong University
zhenjli1987@163.comYanle Hu†
Mayo Clinic Arizona
Hu.Yanle@mayo.edu
Qichao Zhou†
Manteia Tech
zhouqc@manteiatech.com
Abstract
Supervised Pix2Pix and unsupervised Cycle-consistency are two modes that dom-
inate the ﬁeld of medical image-to-image trans",2021,Unknown
CAFE_ Catastrophic Data Leakage in Vertical Federated Learning,"CAFE: Catastrophic Data Leakage in
Vertical Federated Learning
Xiao Jin
Rensselaer Polytechnic Institute
jinx2@rpi.eduPin-Yu Chen
IBM Research
pin-yu.chen@ibm.comChia-Yi Hsu
National Yang Ming Chiao Tung University
chiayihsu8315@gmail.com
Chia-Mu Yu
National Yang Ming Chiao Tung University
chiamuyu@gmail.comTianyi Chen
Rensselaer Polytechnic Institute
chent18@rpi.edu
Abstract
Recent studies show that private training data can be leaked through the gradients
sharing mechanism deployed in distribu",2021,Unknown
Can Information Flows Suggest Targets for Interventions in Neural Circuits_,"Can Information Flows Suggest Targets
for Interventions in Neural Circuits?
Praveen Venkatesh1*, Sanghamitra Dutta2*†, Neil Mehta3†and Pulkit Grover4
1Allen Institute,1University of Washington, Seattle;2JP Morgan Chase AI Research;
1–4Department of Electrical and Computer Engineering,4Neuroscience Institute,
Carnegie Mellon University
1praveen.venkatesh@alleninstitute.org ,2sanghamitra2612@gmail.com ,
3neilashm@andrew.cmu.edu ,4pulkit@cmu.edu
Abstract
Motivated by neuroscientiﬁc and clinical app",2021,Unknown
Cardinality-Regularized Hawkes-Granger Model,"Cardinality-Regularized Hawkes-Granger Model
Tsuyoshi Idé
IBM Research, T. J. Watson Research Center
tide@us.ibm.comGeorgios Kollias
IBM Research, T. J. Watson Research Center
gkollias@us.ibm.com
Dzung T. Phan
IBM Research, T. J. Watson Research Center
phandu@us.ibm.comNaoki Abe
IBM Research, T. J. Watson Research Center
nabe@us.ibm.com
Abstract
We propose a new sparse Granger-causal learning framework for temporal event
data. We focus on a speciﬁc class of point processes called the Hawkes proc",2021,Unknown
Celebrating Diversity in Shared Multi-Agent Reinforcement Learning,"Celebrating Diversity in Shared Multi-Agent
Reinforcement Learning
Chenghao Li, Tonghan Wang, Chengjie Wu, Qianchuan Zhao, Jun Yang, Chongjie Zhang
Tsinghua University
{lich18, wangth18, wucj19}@mails.tsinghua.edu.cn,
{zhaoqc, yangjun603, chongjie}@tsinghua.edu.cn
Abstract
Recently, deep multi-agent reinforcement learning (MARL) has shown the promise
to solve complex cooperative tasks. Its success is partly because of parameter
sharing among agents. However, such sharing may lead agents to beh",2021,Unknown
CentripetalText_ An Efficient Text Instance Representation for Scene Text Detection,"CentripetalText: An Efﬁcient Text Instance
Representation for Scene Text Detection
Tao Sheng, Jie Chen, Zhouhui Lian⇤
Wangxuan Institute of Computer Technology
Peking University, Beijing, China
{shengtao, jiechen01, lianzhouhui}@pku.edu.cn
Abstract
Scene text detection remains a grand challenge due to the variation in text curva-
tures, orientations, and aspect ratios. One of the hardest problems in this task is how
to represent text instances of arbitrary shapes. Although many methods have been",2021,Unknown
Circa_ Stochastic ReLUs for Private Deep Learning,"Circa: Stochastic ReLUs for Private Deep Learning
Zahra Ghodsi1, Nandan Kumar Jha2, Brandon Reagen2, Siddharth Garg2
1University of California San Diego,2New York University
zghodsi@ucsd.edu ,{nj2049, bjr5, sg175}@nyu.edu
Abstract
The simultaneous rise of machine learning as a service and concerns over user pri-
vacy have increasingly motivated the need for private inference (PI). While recent
work demonstrates PI is possible using cryptographic primitives, the computational
overheads render it ",2021,Unknown
Class-agnostic Reconstruction of Dynamic Objects from Videos,"Class-agnostic Reconstruction of
Dynamic Objects from Videos
Zhongzheng Ren⇤, Xiaoming Zhao⇤, Alexander G. Schwing
University of Illinois at Urbana-Champaign
https://jason718.github.io/redo
Abstract
We introduce REDO , a class-agnostic framework to REconstruct the Dynamic
Objects from RGBD or calibrated videos. Compared to prior work, our problem
setting is more realistic yet more challenging for three reasons: 1) due to occlusion
or camera settings an object of interest may never be entirely vi",2021,Unknown
CoAtNet_ Marrying Convolution and Attention for All Data Sizes,"CoAtNet: Marrying Convolution and Attention
for All Data Sizes
Zihang Dai, Hanxiao Liu, Quoc V . Le, Mingxing Tan
Google Research, Brain Team
{zihangd,hanxiaol,qvl,tanmingxing}@google.com
Abstract
Transformers have attracted increasing interests in computer vision, but they still
fall behind state-of-the-art convolutional networks. In this work, we show that
while Transformers tend to have larger model capacity, their generalization can be
worse than convolutional networks due to the lack of the",2021,Unknown
Combining Human Predictions with Model Probabilities via Confusion Matrices and Calibration,"Combining Human Predictions with Model
Probabilities via Confusion Matrices and Calibration
Gavin Kerrigan1Padhraic Smyth1Mark Steyvers2
1Department of Computer Science2Department of Cognitive Sciences
University of California, Irvine
gavin.k@uci.edu smyth@ics.uci.edu mark.steyvers@uci.edu
Abstract
An increasingly common use case for machine learning models is augmenting
the abilities of human decision makers. For classiﬁcation tasks where neither the
human nor model are perfectly accurate, a ke",2021,Unknown
"Combining Recurrent, Convolutional, and Continuous-time Models with Linear State Space Layers","Combining Recurrent, Convolutional,
and Continuous-time Models with
Linear State-Space Layers
Albert Guy, Isys Johnsonz, Karan Goely, Khaled Saab, Tri Daoy, Atri Rudraz, Christopher Réy
yDepartment of Computer Science, Stanford University
Department of Electrical Engineering, Stanford University
zDepartment of Computer Science and Engineering, University at Buffalo, SUNY
{albertgu,knrg,ksaab,trid}@stanford.edu ,chrismre@cs.stanford.edu
{isysjohn,atri}@buffalo.edu
Abstract
Recurrent neural netw",2021,Unknown
Compacter_ Efficient Low-Rank Hypercomplex Adapter Layers,"COMPACTER :
Efﬁcient Low-Rank Hypercomplex Adapter Layers
Rabeeh Karimi Mahabadi
EPFL University, Idiap Research Institute
rabeeh.karimi@idiap.chJames Henderson
Idiap Research Institute
james.henderson@idiap.ch
Sebastian Ruder
DeepMind
ruder@google.com
Abstract
Adapting large-scale pretrained language models to downstream tasks via
ﬁne-tuning is the standard method for achieving state-of-the-art performance on
NLP benchmarks. However, ﬁne-tuning all weights of models with millions or
billions of",2021,Unknown
Complexity Lower Bounds for Nonconvex-Strongly-Concave Min-Max Optimization,"Complexity Lower Bounds for
Nonconvex-Strongly-Concave Min-Max Optimization
Haochuan Li
Department of EECS
MIT
Cambridge, MA 02139
haochuan@mit.eduYi Tian
Department of EECS
MIT
Cambridge, MA 02139
yitian@mit.edu
Jingzhao Zhang
Department of EECS
MIT
Cambridge, MA 02139
jzhzhang@mit.eduAli Jadbabaie
Department of CEE
MIT
Cambridge, MA 02139
jadbabai@mit.edu
Abstract
We provide a ﬁrst-order oracle complexity lower bound for ﬁnding stationary
points of min-max optimization problems where the objec",2021,Unknown
"Conditionally Parameterized, Discretization-Aware Neural Networks for Mesh-Based Modeling of Physical Systems","Conditionally-Parameterized, Discretization-Aware
Neural Networks for Mesh-Based Modeling of
Physical Systems
Jiayang Xu
davidxu@umich.eduAniruddhe Pradhan
anipra@umich.eduKarthik Duraisamy
kdur@umich.edu
Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI 48109.
Abstract
Simulations of complex physical systems are typically realized by discretizing
partial differential equations (PDEs) on unstructured meshes. While neural net-
works have recently been explored for the sur",2021,Unknown
Confident Anchor-Induced Multi-Source Free Domain Adaptation,"Conﬁdent-Anchor-Induced Multi-Source-Free
Domain Adaptation
Jiahua Dong1, 2, Zhen Fang3, Anjin Liu3, Gan Sun1y, Tongliang Liu4
1State Key Laboratory of Robotics, Shenyang Institute of Automation,
Chinese Academy of Sciences.
2University of Chinese Academy of Sciences.
3DeSI Lab, AAII, University of Technology Sydney.4TML Lab, University of Sydney.
{dongjiahua1995, fzjlyt, sungan1412}@gmail.com, anjin.liu@uts.edu.au,
tongliang.liu@sydney.edu.au
Abstract
Unsupervised domain adaptation has attrac",2021,Unknown
Constrained Robust Submodular Partitioning,"Constrained Robust Submodular Partitioning
Shengjie Wang⇤,1,Tianyi Zhou⇤,1,2, Chandrashekhar Lavania1& Jeff A. Bilmes1
University of Washington, Seattle1; University of Maryland, College Park2
{wangsj,tianyizh,lavaniac,bilmes}@uw.edu
Abstract
In the robust submodular partitioning problem, we aim to allocate a set of items
into mblocks, so that the evaluation of the minimum block according to a
submodular function is maximized. Robust submodular partitioning promotes
the diversity of every block ",2021,Unknown
Contextual Similarity Aggregation with Self-attention for Visual Re-ranking,"Contextual Similarity Aggregation with Self-attention
for Visual Re-ranking
Jianbo Ouyang1Hui Wu1Min Wang2yWengang Zhou1;2yHouqiang Li1;2
1CAS Key Laboratory of Technology in GIPAS, EEIS Department
University of Science and Technology of China
2Institute of Artiﬁcial Intelligence, Hefei Comprehensive National Science Center
{ouyjb,wh241300}@mail.ustc.edu.cn
wangmin@iai.ustc.edu.cn, {zhwg,lihq}@ustc.edu.cn
Abstract
In content-based image retrieval, the ﬁrst-round retrieval result by simple visu",2021,Unknown
Continuous Mean-Covariance Bandits,"Continuous Mean-Covariance Bandits
Yihan Du
IIIS, Tsinghua University
Beijing, China
duyh18@mails.tsinghua.edu.cnSiwei Wang
CST, Tsinghua University
Beijing, China
wangsw2020@mail.tsinghua.edu.cn
Zhixuan Fang
IIIS, Tsinghua University, Beijing, China
Shanghai Qi Zhi Institute, Shanghai, China
zfang@mail.tsinghua.edu.cnLongbo Huang
IIIS, Tsinghua University
Beijing, China
longbohuang@mail.tsinghua.edu.cn
Abstract
Existing risk-aware multi-armed bandit models typically focus on risk measures of
i",2021,Unknown
Continuous vs. Discrete Optimization of Deep Neural Networks,"Continuous vs. Discrete Optimization
of Deep Neural Networks
Omer Elkabetz
Tel Aviv University
omer.elkabetz@cs.tau.ac.ilNadav Cohen
Tel Aviv University
cohennadav@cs.tau.ac.il
Abstract
Existing analyses of optimization in deep learning are either continuous, focusing on
(variants of) gradient flow, or discrete, directly treating (variants of) gradient descent.
Gradient flow is amenable to theoretical analysis, but is stylized and disregards
computational efficiency. The extent to which it repre",2021,Unknown
Continuous-time edge modelling using non-parametric point processes,"Continuous-time edge modelling using non-parametric
point processes
Xuhui Fan1,Bin Li2,Feng Zhou3, and Scott A. Sisson1
1UNSW Data Science Hub, and School of Mathematics & Statistics, University of New South Wales
2Shanghai Key Lab of IIP, School of Computer Science, Fudan University
3Department of Computer Science & Technology, Tsinghua University,
{xuhui.fan, scott.sisson}@unsw.edu.au; libin@fudan.edu.cn; zhoufeng6288@tsinghua.edu.cn
Abstract
The mutually-exciting Hawkes process (ME-HP) is a n",2021,Unknown
Control Variates for Slate Off-Policy Evaluation,"Control Variates for Slate Off-Policy Evaluation
Nikos Vlassis
NetﬂixAshok Chandrashekar
WarnerMedia
Fernando Amat Gil
NetﬂixNathan Kallus
Cornell University and Netﬂix
Abstract
We study the problem of off-policy evaluation from batched contextual bandit
data with multidimensional actions, often termed slates. The problem is common
to recommender systems and user-interface optimization, and it is particularly
challenging because of the combinatorially-sized action space. Swaminathan et
al. (201",2021,Unknown
Convex Polytope Trees,"Convex Polytope Trees
Mohammadreza Armandpour
Department of Statistics
Texas A&M University
armand@stat.tamu.eduAli Sadeghian
Department of Computer Science
University of Florida
asadeghian@ufl.edu
Mingyuan Zhou
McCombs School of Business
The University of Texas at Austin
mingyuan.zhou@mccombs.utexas.edu
Abstract
A decision tree is commonly restricted to use a single hyperplane to split the
covariate space at each of its internal nodes. It often requires a large number of
nodes to achieve high a",2021,Unknown
Convex-Concave Min-Max Stackelberg Games,"Convex-Concave Min-Max Stackelberg Games
Denizalp Goktas
Department of Computer Science
Brown University
Providence, RI 02912
denizalp_goktas@brown.eduAmy Greenwald
Department of Computer Science
Brown University
Providence, RI 02912
amy_greenwald@brown.edu
Abstract
Min-max optimization problems (i.e., min-max games) have been attracting a great
deal of attention because of their applicability to a wide range of machine learning
problems. Although signiﬁcant progress has been made recently, the ",2021,Unknown
Counterfactual Explanations Can Be Manipulated,"Counterfactual Explanations Can Be Manipulated
Dylan Slack
UC Irvine
dslack@uci.eduSophie Hilgard
Harvard University
ash798@g.harvard.eduHimabindu Lakkaraju
Harvard University
hlakkaraju@hbs.eduSameer Singh
UC Irvine
sameer@uci.edu
Abstract
Counterfactual explanations are emerging as an attractive option for providing
recourse to individuals adversely impacted by algorithmic decisions. As they
are deployed in critical applications (e.g. law enforcement, ﬁnancial lending), it
becomes important to",2021,Unknown
Coupled Segmentation and Edge Learning via Dynamic Graph Propagation,"Coupled Segmentation and Edge Learning via
Dynamic Graph Propagation
Zhiding YuRui Huangy, Wonmin Byeon, Sifei Liu, Guilin Liu,
Thomas Breuel, Anima Anandkumar, Jan Kautz
NVIDIA
Abstract
Image segmentation and edge detection are both central problems in perceptual
grouping. It is therefore interesting to study how these two tasks can be coupled to
beneﬁt each other. Indeed, segmentation can be easily transformed into contour
edges to guide edge learning. However, the converse is nontrivial sin",2021,Unknown
Credit Assignment in Neural Networks through Deep Feedback Control,"Credit Assignment in Neural Networks through
Deep Feedback Control
Alexander Meulemans∗, Matilde Tristany Farinha∗, Javier García Ordóñez,
Pau Vilimelis Aceituno, João Sacramento, Benjamin F. Grewe
Institute of Neuroinformatics, University of Zürich and ETH Zürich
ameulema@ethz.ch
Abstract
The success of deep learning sparked interest in whether the brain learns by using
similar techniques for assigning credit to each synaptic weight for its contribution
to the network output. However, the major",2021,Unknown
CrypTen_ Secure Multi-Party Computation Meets Machine Learning,"CRYPTEN: Secure Multi-Party Computation
Meets Machine Learning
Brian Knott Shobha Venkataraman Awni Hannun
Shubho Sengupta Mark Ibrahim Laurens van der Maaten
Facebook AI Research
{brianknott,shobha,awni,ssengupta,marksibrahim,lvdmaaten}@fb.com
Abstract
Secure multi-party computation (MPC) allows parties to perform computations
on data while keeping that data private. This capability has great potential for
machine-learning applications: it facilitates training of machine-learning models
on priv",2021,Unknown
"Damped Anderson Mixing for Deep Reinforcement Learning_ Acceleration, Convergence, and Stabilization","Damped Anderson Mixing for Deep Reinforcement
Learning: Acceleration, Convergence, and
Stabilization
Ke Sun1, Yafei Wang1, Yi Liu1, Yingnan Zhao1;2, Bo Pan1, Shangling Jui3,
Bei Jiang1, Linglong Kong1y
1University of Alberta, Edmonton, Canada
2Harbin Institute of Technology, Harbin, China
3Huawei Technologies Ltd.
{ksun6,yafei2,yliu16,yingnan6,pan1,bei1,lkong}@ublberta.ca
jui.shangling@huawei.com
Abstract
Anderson mixing has been heuristically applied to reinforcement learning (RL)
algorithms ",2021,Unknown
Dangers of Bayesian Model Averaging under Covariate Shift,"Dangers of Bayesian Model Averaging
under Covariate Shift
Pavel Izmailov
NYUPatrick Nicholson
Covera HealthSanae Lotﬁ
NYUAndrew Gordon Wilson
NYU
Abstract
Approximate Bayesian inference for neural networks is considered a robust alterna-
tive to standard training, often providing good performance on out-of-distribution
data. However, Bayesian neural networks (BNNs) with high-ﬁdelity approximate
inference via full-batch Hamiltonian Monte Carlo achieve poor generalization
under covariate shift, ev",2021,Unknown
Debiased Visual Question Answering from Feature and Sample Perspectives,"Debiased Visual Question Answering from Feature
and Sample Perspectives
Zhiquan Wen1;2, Guanghui Xu1, Mingkui Tan1;3, Qingyao Wu1, Qi Wu4
1School of Software Engineering, South China University of Technology, China
2PengCheng Laboratory, China
3Key Laboratory of Big Data and Intelligent Robot (South China University of Technology),
Ministry of Education
4School of Computer Science, University of Adelaide
{sewenzhiquan, sexuguanghui}@mail.scut.edu.cn,
{mingkuitan, qyw}@scut.edu.cn, qi.wu01@adel",2021,Unknown
Deep inference of latent dynamics with spatio-temporal super-resolution using selective backpropagation through time,"Deep inference of latent dynamics with
spatio-temporal super-resolution using selective
backpropagation through time
Feng Zhu*1, Andrew R. Sedler*2, Harrison A. Grier3, Nauman Ahad4, Mark A. Davenport4,
Matthew T. Kaufman5,6, Andrea Giovannucci7,8,9, and Chethan Pandarinath10,11
1Neuroscience Graduate Program, Emory University
2Center for Machine Learning, Georgia Tech
3Computational Neuroscience Graduate Program, The University of Chicago
4School of Electrical and Computer Engineering, Georgia ",2021,Unknown
Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space,"Deep learning is adaptive to intrinsic dimensionality
of model smoothness in anisotropic Besov space
Taiji Suzuki
Department of Mathematical Informatics, The University of Tokyo, Tokyo, Japan
RIKEN Center for Advanced Intelligence Project, Tokyo, Japan
taiji@mist.i.u-tokyo.ac.jp
Atsushi Nitanda
Kyushu Institute of Technology, Fukuoka, Japan
RIKEN Center for Advanced Intelligence Project, Tokyo, Japan
nitanda@ai.kyutech.ac.jp
Abstract
Deep learning has exhibited superior performance for various t",2021,Unknown
Deep Self-Dissimilarities as Powerful Visual Fingerprints,"Deep Self-Dissimilarities as Powerful Visual
Fingerprints
Idan Kligvasser
Technion–Israel Institute of Technology
kligvasser@campus.technion.ac.ilTamar Rott Shaham
Technion–Israel Institute of Technology
stamarot@campus.technion.ac.il
Yuval Bahat
Technion–Israel Institute of Technology
yuval.bahat@campus.technion.ac.ilTomer Michaeli
Technion–Israel Institute of Technology
tomer.m@ee.technion.ac.il
Abstract
Features extracted from deep layers of classiﬁcation networks are widely used as
image des",2021,Unknown
Deep Synoptic Monte-Carlo Planning in Reconnaissance Blind Chess,"Deep Synoptic Monte Carlo Planning in
Reconnaissance Blind Chess
Gregory Clark
ML Collective, Google
gregoryclark@google.com
Abstract
This paper introduces deep synoptic Monte Carlo planning (DSMCP) for large
imperfect information games. The algorithm constructs a belief state with an
unweighted particle ﬁlter and plans via playouts that start at samples drawn from
the belief state. The algorithm accounts for uncertainty by performing inference on
“synopses,” a novel stochastic abstraction of in",2021,Unknown
Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design_ Implicit Regularization and Sample Complexity,"Derivative-Free Policy Optimization for Linear
Risk-Sensitive and Robust Control Design:
Implicit Regularization and Sample Complexity
Kaiqing Zhang\Xiangyuan Zhang\Bin Hu Tamer Ba¸ sar
Abstract
Direct policy search serves as one of the workhorses in modern reinforcement
learning (RL), and its applications in continuous control tasks have recently at-
tracted increasing attention. In this work, we investigate the convergence theory
of policy gradient (PG) methods for learning the linear risk-sen",2021,Unknown
Differentiable Unsupervised Feature Selection based on a Gated Laplacian,"Differentiable Unsupervised Feature Selection based
on a Gated Laplacian
Oﬁr Lindenbaum
Faculty of Engineering
Bar-Ilan University
Ramat Gan, Israel 5290002
ofir.lindenbaum@biu.ac.ilUri Shaham
Center for Outcome Research and Evaluation
Yale University
New Haven, CT 06510, USA
uri.shaham@yale.edu
Erez Peterfreund
Hebrew UniversityJonathan Svirsky
Independent ResearcherNicolas Casey
University of Pennsylvania
Yuval Kluger
Program in Applied Math
Department of Pathology
Yale University
New Haven,",2021,Unknown
Discrete-Valued Neural Communication,"Discrete-Valued Neural Communication in
Structured Architectures Enhances Generalization
Dianbo Liu
MilaAlex Lamb
MilaKenji Kawaguchi
Harvard University
Anirudh Goyal
MilaChen Sun
MilaMichael C. Mozer
Google Research, Brain TeamYoshua Bengio
Mila
Abstract
Deep learning has advanced from fully connected architectures to structured models
organized into components, e.g., the transformer composed of positional elements,
modular architectures divided into slots, and graph neural nets made up of no",2021,Unknown
Disentangling Identifiable Features from Noisy Data with Structured Nonlinear ICA,"Disentangling Identiﬁable Features from Noisy Data
with Structured Nonlinear ICA
Hermanni Hälvä1Sylvain Le Corff2Luc Lehéricy3
Jonathan So4Yongjie Zhu1Elisabeth Gassiat5yAapo Hyvärinen1y
1Department of Computer Science, University of Helsinki, Finland
2Samovar, Télécom SudParis, département CITI, Institut Polytechnique de Paris, Palaiseau, France
3Laboratoire J. A. Dieudonné, Université Côte d’Azur, CNRS, 06100, Nice, France
4Department of Engineering, University of Cambridge, UK
5Université Pa",2021,Unknown
Distilling Image Classifiers in Object Detectors,"Distilling Image Classifiers in Object Detectors
Shuxuan Guo1, 2∗Jose M. Alvarez2Mathieu Salzmann1
1CVLab, EPFL, Lausanne 1015, Switzerland
2NVIDIA, Santa Clara, CA 95051, USA
shuxuan.guo@epfl.ch ,josea@nvidia.com ,mathieu.salzmann@epfl.ch
Abstract
Knowledge distillation constitutes a simple yet effective way to improve the per-
formance of a compact student network by exploiting the knowledge of a more
powerful teacher. Nevertheless, the knowledge distillation literature remains lim-
ited to th",2021,Unknown
Distributed Principal Component Analysis with Limited Communication,"Distributed Principal Component Analysis
with Limited Communication
Foivos Alimisis
Department of Mathematics
University of GenevaPeter Davies
Department of Computer Science
University of SurreyBart Vandereycken
Department of Mathematics
University of Geneva
Dan Alistarh
IST Austria &
Neural Magic, Inc.
Abstract
We study efficient distributed algorithms for the fundamental problem of principal
component analysis and leading eigenvector computation on the sphere, when the
data are randomly distri",2021,Unknown
Distributional Reinforcement Learning for Multi-Dimensional Reward Functions,"Distributional Reinforcement Learning for
Multi-Dimensional Reward Functions
Pushi Zhangy
Tsinghua University
zpschang@gmail.comXiaoyu Cheny
Tsinghua University
chen-xy21@mails.tsinghua.edu.cnLi Zhaoz
Microsoft Research Asia
lizo@microsoft.com
Wei Xiongy
The Hong Kong University
of Science and Technology
wxiongae@connect.ust.hkTao Qin
Microsoft Research Asia
taoqin@microsoft.comTie-Yan Liu
Microsoft Research Asia
tyliu@microsoft.com
Abstract
A growing trend for value-based reinforcement learni",2021,Unknown
Diverse Message Passing for Attribute with Heterophily,"Diverse Message Passing for Attribute with
Heterophily
Liang Yang1,2,⇤, Mengzhe Li1,⇤, Liyang Liu1,⇤
Bingxin Niu1, Chuan Wang2, Xiaochun Cao3, Yuanfang Guo4,†
1School of Artiﬁcial Intelligence, Hebei University of Technology, Tianjin, China
2State Key Laboratory of Information Security, IIE, CAS, Beijing, China
3School of Cyber Science and Technology, Sun Yat-sen University, Shenzhen, China
4State Key Laboratory of Software Development Environment, Beihang University, China
yangliang@vip.qq.com,",2021,Unknown
Do Different Tracking Tasks Require Different Appearance Models_,"Do Different Tracking Tasks Require
Different Appearance Models?
Zhongdao Wang1;2Hengshuang Zhao3;4Ya-Li Li1;2
Shengjin Wang1;2Philip H.S. Torr3Luca Bertinetto5
1Beijing National Research Center for Information Science and Technology (BNRist)
2Department of Electronic Engineering, Tsinghua University
3Torr Vision Group, University of Oxford
4The University of Hong Kong
5Five AI
https://zhongdao.github.io/UniTrack
Abstract
Tracking objects of interest in a video is one of the most popular and wi",2021,Unknown
Do Input Gradients Highlight Discriminative Features_,"Do Input Gradients Highlight
Discriminative Features?
Harshay Shah
Microsoft Research India
harshay@google.comPrateek Jain
Microsoft Research India
prajain@google.comPraneeth Netrapalli
Microsoft Research India
pnetrapalli@google.com
Abstract
Post-hoc gradient-based interpretability methods [ 1,2] that provide instance-
speciﬁc explanations of model predictions are often based on assumption ( A):
magnitude of input gradients—gradients of logits with respect to input—noisily
highlight discrimi",2021,Unknown
DRIVE_ One-bit Distributed Mean Estimation,"DRIVE: One-bit Distributed Mean Estimation
Shay Vargaftik
VMware Research
shayv@vmware.comRan Ben Basat
University College London
r.benbasat@cs.ucl.ac.ukAmit Portnoy
Ben-Gurion University
amitport@post.bgu.ac.il
Gal Mendelson
Stanford University
galmen@stanford.eduYaniv Ben-Itzhak
VMware Research
ybenitzhak@vmware.comMichael Mitzenmacher
Harvard University
michaelm@eecs.harvard.edu
Abstract
We consider the problem where nclients transmit d-dimensional real-valued vec-
tors usingdp1 op1qqbits ",2021,Unknown
Dual Progressive Prototype Network for Generalized Zero-Shot Learning,"Dual Progressive Prototype Network for Generalized 
Zero-Shot Learning 
Chaoqun Wang1 2, Shaobo Min3, Xuejin Chen1 2∗, Xiaoyan Sun2, Houqiang Li1 2 
1School of Data Science 
2The National Engineering Laboratory for Brain-inspired Intelligence Technology and Application 
University of Science and Technology of China, Hefei, Anhui, China 
3Tencent Data Platform, Shenzhen, Guangdong, China 
cq14@mail.ustc.edu.cn,bobmin@tencent.com,{xjchen99,sunxiaoyan,lihq}@ustc.edu.cn 
Abstract 
Generalized Zero-S",2021,Unknown
Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit,"Dynamic Analysis of Higher-Order Coordination in
Neuronal Assemblies via De-Sparsiﬁed Orthogonal
Matching Pursuit
Shoutik Mukherjee and Behtash Babadi
Department of Electrical and Computer Engineering
Institute for Systems Research
University of Maryland, College Park
College Park, MD 20742
{smukher2, behtash}@umd.edu
Abstract
Coordinated ensemble spiking activity is widely observable in neural recordings
and central in the study of population codes, with hypothesized roles including
robust stim",2021,Unknown
Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data,"Dynamic Distillation Network for Cross-Domain
Few-Shot Recognition with Unlabeled Data
Ashraful Islam
Rensselaer Polytechnic Institute
islama6@rpi.eduChun-Fu Chen
MIT-IBM Watson AI Lab
chenrich@us.ibm.comRameswar Panda
MIT-IBM Watson AI Lab
rpanda@ibm.com
Leonid Karlinsky
IBM Research
leonidka@il.ibm.comRogerio Feris
IBM Research
rsferis@us.ibm.comRichard J. Radke
Rensselaer Polytechnic Institute
rjradke@ecse.rpi.edu
Abstract
Most existing works in few-shot learning rely on meta-learning the net",2021,Unknown
Dynamic Visual Reasoning by Learning Differentiable Physics Models from Video and Language,"Dynamic Visual Reasoning by
Learning Differentiable Physics Models
from Video and Language
Mingyu Ding
MIT CSAIL and HKUZhenfang Chen
MIT-IBM Watson AI LabTao Du
MIT CSAILPing Luo
HKU
Joshua B. Tenenbaum
MIT BCS, CBMM, CSAILChuang Gan
MIT-IBM Watson AI Lab
Abstract
In this work, we propose a uniﬁed framework, called Visual Reasoning with Differ-
entiable Physics (VRDP)1, that can jointly learn visual concepts and infer physics
models of objects and their interactions from videos and language. Th",2021,Unknown
E(n) Equivariant Normalizing Flows,"E(n) Equivariant Normalizing Flows
Victor Garcia Satorras1⇤, Emiel Hoogeboom1⇤, Fabian B. Fuchs2,
Ingmar Posner2, Max Welling1
UvA-Bosch Delta Lab, University of Amsterdam1,
Department of Engineering Science, University of Oxford2
v.garciasatorras@uva.nl,e.hoogeboom@uva.nl,fabian@robots.ox.ac.uk
Abstract
This paper introduces a generative model equivariant to Euclidean symmetries:
E(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the
discriminative E( n) graph neural networ",2021,Unknown
Early-stopped neural networks are consistent,"Early-stopped neural networks are consistent
Ziwei Ji Justin D. Li Matus Telgarsky
<{ziweiji2,jdli3,mjt}@illinois.edu>
University of Illinois, Urbana-Champaign
Abstract
This work studies the behavior of shallow ReLU networks trained with the logistic
loss via gradient descent on binary classification data where the underlying data
distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this
setting, it is shown that gradient descent with early stopping achieves populati",2021,Unknown
"EF21_ A New, Simpler, Theoretically Better, and Practically Faster Error Feedback","EF21: A New, Simpler, Theoretically Better,
and Practically Faster Error Feedback
Peter Richtárik
KAUST*Igor Sokolov
KAUSTIlyas Fatkhullin
KAUST†& TU Munich
Abstract
Error feedback ( EF), also known as error compensation, is an immensely popular
convergence stabilization mechanism in the context of distributed training of super-
vised machine learning models enhanced by the use of contractive communication
compression mechanisms, such as Top- 𝑘. First proposed by Seide et al. [2014] as
a heurist",2021,Unknown
Efficient Bayesian network structure learning via local Markov boundary search,"Efﬁcient Bayesian network structure learning via
local Markov boundary search
Ming Gao
The University of Chicago
minggao@uchicago.eduBryon Aragam
The University of Chicago
bryon@chicagobooth
Abstract
We analyze the complexity of learning directed acyclic graphical models from
observational data in general settings without speciﬁc distributional assumptions.
Our approach is information-theoretic and uses a local Markov boundary search
procedure in order to recursively construct ancestral sets in ",2021,Unknown
Efficient Training of Retrieval Models using Negative Cache,"Efﬁcient Training of Retrieval Models
Using Negative Cache
Erik M. Lindgren
Google Research, New York
erikml@google.comSashank Reddi
Google Research, New York
sashank@google.com
Ruiqi Guo
Google Research, New York
guorq@google.comSanjiv Kumar
Google Research, New York
sanjivk@google.com
Abstract
Factorized models, such as two tower neural network models, are widely used for
scoring (query, document) pairs in information retrieval tasks. These models are
typically trained by optimizing the model ",2021,Unknown
Efficient Truncated Linear Regression with Unknown Noise Variance,"Efﬁcient Truncated Linear Regression with Unknown
Noise Variance
Constantinos Daskalakis
*EECS and CSAIL, MIT
costis@csail.mit.eduPatroklos Stefanou
EECS and CSAIL, MIT
stefanou@mit.eduRui Yao
EECS and CSAIL, MIT
rayyao@mit.edu
Manolis Zampetakis†
EECS, UC Berkeley
mzampet@berkeley.edu
Abstract
Truncated linear regression is a classical challenge in statistics, wherein a label,
𝑦=𝑤𝑇𝑥+𝜀, and its corresponding feature vector, 𝑥∈R𝑘, are only observed
if the label falls in some subset 𝑆⊆R; otherwise",2021,Unknown
End-to-End Weak Supervision,"End-to-End Weak Supervision
Salva Rühling Cachay1,2∗Benedikt Boecking1Artur Dubrawski1
1Carnegie Mellon University2Technical University of Darmstadt
Abstract
Aggregating multiple sources of weak supervision (WS) can ease the data-labeling
bottleneck prevalent in many machine learning applications, by replacing the
tedious manual collection of ground truth labels. Current state of the art approaches
that do not use any labeled training data, however, require two separate modeling
steps: Learning ",2021,Unknown
Environment Generation for Zero-Shot Compositional Reinforcement Learning,"Environment Generation for Zero-Shot
Compositional Reinforcement Learning
Izzeddin Gur, Natasha Jaques, Yingjie Miao, Jongwook Choi,
Manoj Tiwari, Honglak Lee, Aleksandra Faust
Google Research, Brain Team
Mountain View, California, 94043
{izzeddin, natashajaques, yingjiemiao, mjtiwari, sandrafaust}@google.com
{jwook, honglak}@umich.edu
Abstract
Many real-world problems are compositional – solving them requires completing
interdependent sub-tasks, either in series or in parallel, that can be repr",2021,Unknown
Episodic Multi-agent Reinforcement Learning with Curiosity-driven Exploration,"Episodic Multi-agent Reinforcement Learning with
Curiosity-driven Exploration
Lulu Zheng1, Jiarui Chen2 3, Jianhao Wang1, Jiamin He4y, Yujing Hu3, Yingfeng Chen3,
Changjie Fan3, Yang Gao2, Chongjie Zhang1
1Institute for Interdisciplinary Information Sciences, Tsinghua University, China
2Department of Computer Science and Technology, Nanjing University, China
3Fuxi AI Lab, NetEase, China
4Department of Computing Science, University of Alberta, Canada
zll19@mails.tsinghua.edu.cn
chenjiarui@smail",2021,Unknown
Estimating the Long-Term Effects of Novel Treatments,"Estimating the Long-Term Effects of Novel
Treatments
Keith Battocchi
Microsoft ResearchEleanor W. Dillon
Microsoft ResearchMaggie Hei
Microsoft ResearchGreg Lewis
Microsoft Research
Miruna Oprescu
Microsoft ResearchVasilis Syrgkanis
Microsoft Research
Abstract
Policy makers often need to estimate the long-term effects of newly-developed
treatments, while only having historical data of older treatment options. We propose
a surrogate-based approach using a long-term dataset where only past treatm",2021,Unknown
Evolution Gym_ A Large-Scale Benchmark for Evolving Soft Robots,"Evolution Gym: A Large-Scale Benchmark for
Evolving Soft Robots
Jagdeep Singh Bhatia
MIT CSAIL
jagdeep@mit.eduHolly Jackson
MIT CSAIL
hjackson@mit.eduYunsheng Tian
MIT CSAIL
yunsheng@csail.mit.edu
Jie Xu
MIT CSAIL
jiex@csail.mit.eduWojciech Matusik
MIT CSAIL
wojciech@csail.mit.edu
Abstract
Both the design and control of a robot play equally important roles in its task
performance. However, while optimal control is well studied in the machine learn-
ing and robotics community, less attention is p",2021,Unknown
Exact marginal prior distributions of finite Bayesian neural networks,"Exact marginal prior distributions
of ﬁnite Bayesian neural networks
Jacob A. Zavatone-Veth
Department of Physics
Harvard University
Cambridge, MA 02138
jzavatoneveth@g.harvard.edu
Cengiz Pehlevan
John A. Paulson School of Engineering and Applied Sciences
Harvard University
Cambridge, MA 02138
cpehlevan@seas.harvard.edu
Abstract
Bayesian neural networks are theoretically well-understood only in the inﬁnite-
width limit, where Gaussian priors over network weights yield Gaussian priors over
networ",2021,Unknown
Explaining Hyperparameter Optimization via Partial Dependence Plots,"Explaining Hyperparameter Optimization
via Partial Dependence Plots
Julia Moosbauer⇤, Julia Herbinger⇤, Giuseppe Casalicchio, Marius Lindauer, Bernd Bischl
Department of Statistics, Ludwig-Maximilians-University Munich, Munich, Germany
Institute of Information Processing, Leibniz University Hannover, Hannover, Germany
{julia.moosbauer, julia.herbinger, giuseppe.casalicchio,
bernd.bischl}@stat.uni-muenchen.de
lindauer@tnt.uni-hannover.de
Abstract
Automated hyperparameter optimization (HPO) can su",2021,Unknown
Explicit loss asymptotics in the gradient descent training of neural networks,"Explicit loss asymptotics in the gradient descent
training of neural networks
Maksim Velikanov
Skolkovo Institute of Science and Technology
maksim.velikanov@skoltech.ruDmitry Yarotsky
Skolkovo Institute of Science and Technology
d.yarotsky@skoltech.ru
Abstract
Current theoretical results on optimization trajectories of neural networks trained
by gradient descent typically have the form of rigorous but potentially loose bounds
on the loss values. In the present work we take a different approach a",2021,Unknown
Exploiting Local Convergence of Quasi-Newton Methods Globally_ Adaptive Sample Size Approach,"Exploiting Local Convergence of Quasi-Newton
Methods Globally: Adaptive Sample Size Approach
Qiujiang Jin
ECE Department
The University of Texas at Austin
Austin, TX 78712, USA
qiujiang@austin.utexas.eduAryan Mokhtari
ECE Department
The University of Texas at Austin
Austin, TX 78712, USA
mokhtari@austin.utexas.edu
Abstract
In this paper, we study the application of quasi-Newton methods for solving empir-
ical risk minimization (ERM) problems deﬁned over a large dataset. Traditional
deterministic",2021,Unknown
Exploring Forensic Dental Identification with Deep Learning,"Exploring Forensic Dental Identiﬁcation with
Deep Learning
Yuan Liang1;2, Weikun Han1, Liang Qiu1, Chen Wu1, Yiting Shao1, Kun Wang1, Lei He1
1University of California, Los Angeles
2Topaz Labs
liangyuandg@ucla.edu
Abstract
Dental forensic identiﬁcation targets to identify persons with dental traces. The
task is vital for the investigation of criminal scenes and mass disasters because
of the resistance of dental structures and the wide-existence of dental imaging.
However, no widely accepted au",2021,Unknown
Fast Training of Neural Lumigraph Representations using Meta Learning,"Fast Training of Neural Lumigraph Representations
using Meta Learning
Alexander W. Bergman
Stanford University
awb@stanford.eduPetr Kellnhofer
Stanford University
pkellnho@stanford.eduGordon Wetzstein
Stanford University
gordon.wetzstein@stanford.edu
computationalimaging.org/publications/metanlr/
Abstract
Novel view synthesis is a long-standing problem in machine learning and computer
vision. Signiﬁcant progress has recently been made in developing neural scene
representations and rendering tech",2021,Unknown
Fast Tucker Rank Reduction for Non-Negative Tensors Using Mean-Field Approximation,"Fast Tucker Rank Reduction for Non-Negative
Tensors Using Mean-Field Approximation
Kazu Ghalamkari1,2Mahito Sugiyama1,2
1National Institute of Informatics
2The Graduate University for Advanced Studies, SOKENDAI
{gkazu,mahito}@nii.ac.jp
Abstract
We present an efﬁcient low-rank approximation algorithm for non-negative ten-
sors. The algorithm is derived from our two ﬁndings: First, we show that rank-1
approximation for tensors can be viewed as a mean-ﬁeld approximation by treat-
ing each tensor as",2021,Unknown
Faster Directional Convergence of Linear Neural Networks under Spherically Symmetric Data,"Faster Directional Convergence of Linear Neural
Networks under Spherically Symmetric Data
Dachao Lin1Ruoyu Sun2Zhihua Zhang3
1Academy for Advanced Interdisciplinary Studies, Peking University
2Department of Industrial and Enterprise Engineering, Coordinate Science Lab (afﬁliated)
University of Illinois Urbana-Champaign
3School of Mathematical Sciences, Peking University
lindachao@pku.edu.cn ruoyus@illinois.edu zhzhang@math.pku.edu.cn
Abstract
In this paper, we study gradient methods for training",2021,Unknown
Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee,"Fault-Tolerant Federated Reinforcement Learning
with Theoretical Guarantee
Flint Xiaofeng Fan1, 3,Yining Ma2,Zhongxiang Dai1,Wei Jing4,
Cheston Tan3,Bryan Kian Hsiang Low1
1Dept. of Computer Science, National University of Singapore, Republic of Singapore
2Dept. of ISEM, National University of Singapore, Republic of Singapore
3Institute for Infocomm Research, A*STAR, Republic of Singapore
4Alibaba DAMO Academy, Hangzhou, China
1{xiaofeng,daizhongxiang,lowkh}@comp.nus.edu.sg,2yiningma@u.nus.edu
3",2021,Unknown
Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution,"Finding Discriminative Filters for Specific
Degradations in Blind Super-Resolution
Liangbin Xie∗1,2,3Xintao Wang∗3Chao Dong1,4Zhongang Qi3Ying Shan3
1Shenzhen Key Lab of Computer Vision and Pattern Recognition,
Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences
2University of Chinese Academy of Sciences
3ARC Lab, Tencent PCG
4Shanghai AI Laboratory, Shanghai, China
{lb.xie, chao.dong}@siat.ac.cn
{xintaowang, zhongangqi, yingsshan}@tencent.com
Abstract
Recent blind super-resol",2021,Unknown
Finite Sample Analysis of Average-Reward TD Learning and $Q$-Learning,"Finite Sample Analysis of Average-Reward TD
Learning and Q-Learning
Sheng ZhangZhe ZhangSiva Theja Maguluri
The H. Milton Stewart School of Industrial and Systems Engineering
Georgia Institute of Technology
{shengzhang, jimmy_zhang, siva.theja}@gatech.edu
Abstract
The focus of this paper is on sample complexity guarantees of average-reward
reinforcement learning algorithms, which are known to be more challenging to
study than their discounted-reward counterparts. To the best of our knowledge, ",2021,Unknown
Flexible Option Learning,"Flexible Option Learning
Martin Klissarov
Mila, McGill University
martin.klissarov@mail.mcgill.caDoina Precup
Mila, McGill University and DeepMind
dprecup@cs.mcgill.ca
Abstract
Temporal abstraction in reinforcement learning (RL), offers the promise of im-
proving generalization and knowledge transfer in complex environments, by prop-
agating information more efﬁciently over time. Although option learning was
initially formulated in a way that allows updating many options simultaneously,
using of",2021,Unknown
Framing RNN as a kernel method_ A neural ODE approach,"Framing RNN as a kernel method:
A neural ODE approach
Adeline Fermanian1Pierre Marion1Jean-Philippe Vert2Gérard Biau1
1Sorbonne Université, CNRS,
Laboratoire de Probabilités, Statistique et Modélisation, LPSM,
F-75005 Paris, France
{adeline.fermanian, pierre.marion, gerard.biau}@sorbonne-universite.fr
2Google Research, Brain team,
Paris, France
jpvert@google.com
Abstract
Building on the interpretation of a recurrent neural network (RNN) as a continuous-
time neural differential equation, we sh",2021,Unknown
From Canonical Correlation Analysis to Self-supervised Graph Neural Networks,"From Canonical Correlation Analysis to
Self-supervised Graph Neural Networks
Hengrui Zhang1⇤, Qitian Wu2, Junchi Yan2, David Wipf3, Philip S. Yu1†
1Department of Computer Science, University of Illinois at Chicago
2Department of Computer Science and Engineering, Shanghai Jiao Tong University
3AWS Shanghai AI Lab
hzhan55@uic.edu, {echo740, yanjunchi}@sjtu.edu.cn
daviwipf@amazon.com, psyu@uic.edu
Abstract
We introduce a conceptually simple yet effective model for self-supervised represen-
tation l",2021,Unknown
From global to local MDI variable importances for random forests and when they are Shapley values,"From global to local MDI variable importances for
random forests and when they are Shapley values
Antonio Sutera∗, Gilles Louppe, Van Anh Huynh-Thu, Louis Wehenkel, Pierre Geurts
Dept. of EE & CS, University of Liège, Belgium
{a.sutera,g.louppe,vahuynh,l.wehenkel,p.geurts}@uliege.be
Abstract
Random forests have been widely used for their ability to provide so-called impor-
tance measures , which give insight at a global (per dataset) level on the relevance
of input variables to predict a certain",2021,Unknown
Fuzzy Clustering with Similarity Queries,"Fuzzy Clustering with Similarity Queries
Wasim Huleihel
Department of Electrical Engineering
Tel Aviv University
Tel Aviv 6997801, Israel
wasimh@tauex.tau.ac.ilArya Mazumdar
Halıcıo ˘glu Data Science Institute
University of California, San Diego
La Jolla, CA 92093
arya@ucsd.edu
Soumyabrata Pal
College of Information & Computer Sciences
University of Massachusetts Amherst
Amherst, MA 01003
soumyabratap@umass.edu
Abstract
The fuzzy or soft k-means objective is a popular generalization of the well-",2021,Unknown
G-PATE_ Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators,"G-PATE: Scalable Differentially Private Data Generator via
Private Aggregation of Teacher Discriminators
Yunhui Long1⇤Boxin Wang1⇤Zhuolin Yang1Bhavya Kailkhura2Aston Zhang1
Carl A. Gunter1Bo Li1
1University of Illinois, Urbana Champaign2Lawrence Livermore National Laboratory
{ylong4, boxinw2, zhuolin5, lzhang74, cgunter, lbo}@illinois.edu
Abstract
Recent advances in machine learning have largely beneﬁted from the massive
accessible training data. However, large-scale data sharing has raised grea",2021,Unknown
Generalization Bounds for Graph Embedding Using Negative Sampling_ Linear vs Hyperbolic,"Generalization Error Bounds for Graph Embedding
Using Negative Sampling: Linear vs Hyperbolic
Atsushi Suzuki
University of Greenwich
London, United Kingdom
atsushi.suzuki.rd@gmail.comAtsushi Nitanda
Kyushu Institute of Technology
Fukuoka, Japan
nitanda@ai.kyutech.ac.jp
Jing Wang
University of Greenwich
London, United Kingdom
jing.wang@greenwich.ac.ukLinchuan Xu
The Hong Kong Polytechnic University
Hong Kong SAR, China
linch.xu@polyu.edu.hk
Kenji Yamanishi
The University of Tokyo
Tokyo, Japan
ya",2021,Unknown
Generalization Bounds for Meta-Learning via PAC-Bayes and Uniform Stability,"Generalization Bounds for Meta-Learning via
PAC-Bayes and Uniform Stability
Alec Farid Anirudha Majumdar
Department of Mechanical and Aerospace Engineering, Princeton University
{afarid, ani.majumdar }@princeton.edu
Abstract
We are motivated by the problem of providing strong generalization guarantees in
the context of meta-learning. Existing generalization bounds are either challenging
to evaluate or provide vacuous guarantees in even relatively simple settings. We
derive a probably approximate",2021,Unknown
Generalized Shape Metrics on Neural Representations,"Generalized Shape Metrics on Neural Representations
Alex H. Williams
Statistics Department
Stanford University
ahwillia@stanford.eduErin Kunz
Electrical Engineering Department
Stanford University
ekunz@stanford.edu
Simon Kornblith
Google Research, Toronto
skornblith@google.comScott W. Linderman
Statistics Department
Stanford University
scott.linderman@stanford.edu
Abstract
Understanding the operation of biological and artiﬁcial networks remains a difﬁcult
and important challenge. To identify gen",2021,Unknown
Global Convergence of Gradient Descent for Asymmetric Low-Rank Matrix Factorization,"Global Convergence of Gradient Descent for
Asymmetric Low-Rank Matrix Factorization
Tian Ye
Institute for Interdisciplinary Information Sciences
Tsinghua University
yet17@mails.tsinghua.edu.cn
Simon S. Du
Paul G. Allen School of Computer Science and Engineering
University of Washington
ssdu@cs.washington.edu
Abstract
We study the asymmetric low-rank factorization problem:
min
U2Rmd;V2Rnd1
2kUV> k2
F
where is a given matrix of size mnand rankd. This is a canonical problem that
admits two dif",2021,Unknown
Global Filter Networks for Image Classification,"Global Filter Networks for Image Classiﬁcation
Yongming RaoWenliang ZhaoZheng Zhu Jiwen Lu†Jie Zhou
Department of Automation, Tsinghua University
State Key Lab of Intelligent Technologies and Systems
Beijing National Research Center for Information Science and Technology
Abstract
Recent advances in self-attention and pure multi-layer perceptrons (MLP) models
for vision have shown great potential in achieving promising performance with
fewer inductive biases. These models are generally based on",2021,Unknown
Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning,"Goal-Aware Cross-Entropy
for Multi-Target Reinforcement Learning
Kibeom Kim1,2, Min Whoo Lee1, Yoonsung Kim1, Je-Hwan Ryu1,
Minsu Lee1,3∗,Byoung-Tak Zhang1,3∗
1Seoul National University,2Surromind,3AIIS†
{kbkim, mwlee, yskim, jhryu, mslee, btzhang}@bi.snu.ac.kr
Abstract
Learning in a multi-target environment without prior knowledge about the targets
requires a large amount of samples and makes generalization difficult. To solve
this problem, it is important to be able to discriminate targets thr",2021,Unknown
Gradient Starvation_ A Learning Proclivity in Neural Networks,"Gradient Starvation:
A Learning Proclivity in Neural Networks
Mohammad Pezeshki1;2Sékou-Oumar Kaba1;3Yoshua Bengio1;2
Aaron Courville1;2Doina Precup1;3;4Guillaume Lajoie1;2
1Mila2Université de Montréal3McGill University4Google DeepMind
corresponding authors:{pezeshki, guillaume.lajoie}@mila.quebec
Abstract
We identify and formalize a fundamental gradient descent phenomenon leading to
a learning proclivity in over-parameterized neural networks. Gradient Starvation
arises when cross-entropy loss i",2021,Unknown
Greedy Approximation Algorithms for Active Sequential Hypothesis Testing,"Greedy Approximation Algorithms
for Active Sequential Hypothesis Testing
Kyra Gan⇤, Su Jia⇤, Andrew A. Li
Carnegie Mellon University
Pittsburgh, PA 15213
{kyragan ,sujia ,aali1 }@cmu.edu
Abstract
In the problem of active sequential hypothesis testing (ASHT), a learner seeks to
identify the truehypothesis from among a known set of hypotheses. The learner
is given a set of actions and knows the random distribution of the outcome of
any action under any true hypothesis. Given a target error  >0, th",2021,Unknown
Grounding Representation Similarity Through Statistical Testing,"Grounding Representation Similarity with Statistical
Testing
Frances Ding, Jean-Stanislas Denain, Jacob Steinhardt
University of California Berkeley
{frances, js_denain, jsteinhardt}@berkeley.edu
Abstract
To understand neural network behavior, recent works quantitatively compare differ-
ent networks’ learned representations using canonical correlation analysis (CCA),
centered kernel alignment (CKA), and other dissimilarity measures. Unfortunately,
these widely used measures often disagree on fun",2021,Unknown
Habitat 2.0_ Training Home Assistants to Rearrange their Habitat,"Habitat 2.0:
Training Home Assistants to Rearrange their Habitat
Andrew Szot2,⇤Alex Clegg1, Eric Undersander1, Erik Wijmans1,2, Yili Zhao1, John Turner1,
Noah Maestre1, Mustafa Mukadam1, Devendra Chaplot1, Oleksandr Maksymets1,
Aaron Gokaslan1, Vladimir Vondrus, Sameer Dharur2, Franziska Meier1, Wojciech Galuba1,
Angel Chang4, Zsolt Kira2, Vladlen Koltun3, Jitendra Malik1,5, Manolis Savva4, Dhruv Batra1,2
1Facebook AI Research,2Georgia Tech,3Intel Research,4Simon Fraser University5UC Berkeley
Ab",2021,Unknown
High-probability Bounds for Non-Convex Stochastic Optimization with Heavy Tails,"High-probability bounds for Non-Convex Stochastic
Optimization with Heavy Tails
Ashok Cutkosky
Boston University
ashok@cutkosky.comHarsh Mehta
Google Research
harshm@google.com
Abstract
We consider non-convex stochastic optimization using ﬁrst-order algorithms for
which the gradient estimates may have heavy tails. We show that a combination of
gradient clipping, momentum, and normalized gradient descent yields convergence
to critical points in high-probability with best-known rates for smooth lo",2021,Unknown
Hindsight Task Relabelling_ Experience Replay for Sparse Reward Meta-RL,"Hindsight Task Relabelling:
Experience Replay for Sparse Reward Meta-RL
Charles Packer
UC BerkeleyPieter Abbeel
UC BerkeleyJoseph E. Gonzalez
UC Berkeley
Abstract
Meta-reinforcement learning (meta-RL) has proven to be a successful framework
for leveraging experience from prior tasks to rapidly learn new related tasks, how-
ever, current meta-RL approaches struggle to learn in sparse reward environments.
Although existing meta-RL algorithms can learn strategies for adapting to new
sparse reward t",2021,Unknown
How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness_,"How Should Pre-Trained Language Models Be
Fine-Tuned Towards Adversarial Robustness?
Xinshuai Dong
Nanyang Technological University & Sea AI Lab
dongxinshuai@outlook.comLuu Anh Tuan
Nanyang Technological University
anhtuan.luu@ntu.edu.sg
Min Lin
Sea AI Lab
linmin@sea.comShuicheng Yan
Sea AI Lab
yansc@sea.comHanwang Zhang
Nanyang Technological University
hanwangzhang@ntu.edu.sg
Abstract
The ﬁne-tuning of pre-trained language models has a great success in many NLP
ﬁelds. Yet, it is strikingly vuln",2021,Unknown
How Tight Can PAC-Bayes be in the Small Data Regime_,"How Tight Can PAC-Bayes be in the
Small Data Regime?
Andrew Y. K. Foong∗
University of Cambridge
ykf21@cam.ac.ukWessel P. Bruinsma∗
University of Cambridge
Invenia Labs
wpb23@cam.ac.uk
David R. Burt
University of Cambridge
drb62@cam.ac.ukRichard E. Turner
University of Cambridge
ret26@cam.ac.uk
Abstract
In this paper, we investigate the question: Given a small number of datapoints, for
exampleN= 30 , how tight can PAC-Bayes and test set bounds be made? For
such small datasets, test set bounds ad",2021,Unknown
Hybrid Regret Bounds for Combinatorial Semi-Bandits and Adversarial Linear Bandits,"Hybrid Regret Bounds for Combinatorial
Semi-Bandits and Adversarial Linear Bandits
Shinji Ito
NEC Corporation
i-shinji@nec.com
Abstract
This study aims to develop bandit algorithms that automatically exploit tendencies
of certain environments to improve performance, without any prior knowledge
regarding the environments. We ﬁrst propose an algorithm for combinatorial
semi-bandits with a hybrid regret bound that includes two main features: a best-
of-three-worlds guarantee and multiple data-depen",2021,Unknown
Hyperbolic Busemann Learning with Ideal Prototypes,"Hyperbolic Busemann Learning with Ideal Prototypes
Mina Ghadimi Atigh
University of AmsterdamMartin Keller-Ressel
Technische Universität DresdenPascal Mettes
University of Amsterdam
Abstract
Hyperbolic space has become a popular choice of manifold for representation learn-
ing of various datatypes from tree-like structures and text to graphs. Building on the
success of deep learning with prototypes in Euclidean and hyperspherical spaces,
a few recent works have proposed hyperbolic prototypes for",2021,Unknown
Hypergraph Propagation and Community Selection for Objects Retrieval,"Hypergraph Propagation and Community Selection
for Objects Retrieval
Guoyuan An1, Yuchi Huo2,3, and Sung-Eui Yoon1
1School of Computing, KAIST
2Zhejiang Lab
3State Key Lab of CAD&CG, Zhejiang University
Abstract
Spatial verification is a crucial technique for particular object retrieval. It utilizes
spatial information for the accurate detection of true positive images. However,
existing query expansion and diffusion methods cannot efficiently propagate the
spatial information in an ordinary gra",2021,Unknown
"Hyperparameter Optimization Is Deceiving Us, and How to Stop It","Hyperparameter Optimization Is Deceiving Us,
and How to Stop It
A. Feder Cooper∗
Cornell University
afc78@cornell.eduYucheng Lu
Cornell University
yl2967@cornell.eduJessica Zosa Forde
Brown University
jforde2@cs.brown.edu
Christopher De Sa
Cornell University
cdesa@cs.cornell.edu
Abstract
Recent empirical work shows that inconsistent results based on choice of hyper-
parameter optimization (HPO) conﬁguration are a widespread problem in ML
research. When comparing two algorithms JandK, searching o",2021,Unknown
ImageBART_ Bidirectional Context with Multinomial Diffusion for Autoregressive Image Synthesis,"ImageBART: Bidirectional Context with Multinomial
Diffusion for Autoregressive Image Synthesis
Patrick EsserRobin RombachAndreas BlattmannBjörn Ommer
Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany
https://compvis.github.io/imagebart/
Abstract
Autoregressive models and their sequential factorization of the data likelihood
have recently demonstrated great potential for image representation and synthesis.
Nevertheless, they incorporate image context in a linear 1D o",2021,Unknown
Improved Variance-Aware Confidence Sets for Linear Bandits and Linear Mixture MDP,"Improved Variance-Aware Conﬁdence Sets for
Linear Bandits and Linear Mixture MDP
Zihan Zhang
Tsinghua University
zihan-zh17@mails.tsinghua.edu.cnJiaqi Yang
Tsinghua University
yangjq17@gmail.com
Xiangyang Ji
Tsinghua University
xyji@tsinghua.edu.cnSimon S. Du
University of Washington
ssdu@cs.washington.edu
Abstract
This paper presents new variance-aware conﬁdence sets for linear bandits and
linear mixture Markov Decision Processes (MDPs). With the new conﬁdence sets,
we obtain the follow regre",2021,Unknown
Improving black-box optimization in VAE latent space using decoder uncertainty,"Improving black-box optimization in V AE latent
space using decoder uncertainty
Pascal Notin
Department of Computer Science
University of Oxford
Oxford, UK
pascal.notin@cs.ox.ac.ukJosé Miguel Hernández-Lobato
Department of Engineering
University of Cambridge
Cambridge, UK
jmh233@cam.ac.uk
Yarin Gal
Department of Computer Science
University of Oxford
Oxford, UK
yarin@cs.ox.ac.uk
Abstract
Optimization in the latent space of variational autoencoders is a promising ap-
proach to generate high-dimens",2021,Unknown
Improving Conditional Coverage via Orthogonal Quantile Regression,"Improving Conditional Coverage via Orthogonal
Quantile Regression
Shai Feldman
Department of Computer Science
Technion, Israel
shai.feldman@cs.technion.ac.ilStephen Bates
Departments of Statistics and of EECS
UC Berkeley
stephenbates@cs.berkeley.edu
Yaniv Romano
Departments of Electrical and Computer Engineering
and of Computer Science
Technion, Israel
yromano@technion.ac.il
Abstract
We develop a method to generate prediction intervals that have a user-speciﬁed
coverage level across all regions ",2021,Unknown
Improving Robustness using Generated Data,"Improving Robustness using Generated Data
Sven Gowal*, Sylvestre-Alvise Rebufﬁ*, Olivia Wiles,
Florian Stimberg ,Dan Calian andTimothy Mann
DeepMind, London
{sgowal,sylvestre}@deepmind.com
Abstract
Recent work argues that robust training requires substantially larger datasets than
those required for standard classiﬁcation. On CIFAR -10andCIFAR -100 , this
translates into a sizable robust-accuracy gap between models trained solely on data
from the original training set and those trained with addi",2021,Unknown
INDIGO_ GNN-Based Inductive Knowledge Graph Completion Using Pair-Wise Encoding,"INDIGO: GNN-Based Inductive Knowledge Graph
Completion Using Pair-Wise Encoding
Shuwen Liu1, Bernardo Cuenca Grau1, Ian Horrocks1, and Egor V . Kostylev2
1Department of Computer Science, University of Oxford, UK
{shuwen.liu, bernardo.cuenca.grau, ian.horrocks}@cs.ox.ac.uk
2Department of Informatics, University of Oslo
egork@ifi.uio.no
Abstract
The aim of knowledge graph (KG) completion is to extend an incomplete KG
with missing triples. Popular approaches based on graph embeddings typically
work",2021,Unknown
Influence Patterns for Explaining Information Flow in BERT,"Inﬂuence Patterns for Explaining Information Flow
in BERT
Kaiji Lu, Zifan Wang, Piotr Mardziel, Anupam Datta
Electrical and Computer Engineering
Carnegie Mellon University
Mountain View, CA 94089
Abstract
While “attention is all you need” may be proving true, we do not know why:
attention-based transformer models such as BERT are superior but how information
ﬂows from input tokens to output predictions are unclear. We introduce inﬂuence
patterns , abstractions of sets of paths through a transfo",2021,Unknown
Information Directed Reward Learning for Reinforcement Learning,"Information Directed Reward Learning
for Reinforcement Learning
David Lindner
Department of Computer Science
ETH Zurich
david.lindner@inf.ethz.chMatteo Turchetta
Department of Computer Science
ETH Zurich
matteo.turchetta@inf.ethz.ch
Sebastian Tschiatschek
Department of Computer Science
University of Vienna
sebastian.tschiatschek@univie.ac.atKamil Ciosek
Spotify
kamilc@spotify.com
Andreas Krause
Department of Computer Science
ETH Zurich
krausea@ethz.ch
Abstract
For many reinforcement learning (R",2021,Unknown
Instance-dependent Label-noise Learning under a Structural Causal Model,"Instance-Dependent Label-Noise Learning under
Structural Causal Models
Yu Yao1Tongliang Liu1yMingming Gong2
Bo Han3Gang Niu4Kun Zhang5
1TML Lab, University of Sydney;2University of Melbourne;3Hong Kong Baptist University;
4RIKEN AIP;5Carnegie Mellon University
Abstract
Label noise generally degenerates the performance of deep learning algorithms
because deep neural networks easily overﬁt label errors. Let XandYdenote the
instance and clean label, respectively. When Yis a cause of X, according to",2021,Unknown
Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization,"Invariance Principle Meets Information Bottleneck
for Out-of-Distribution Generalization
Kartik AhujayEthan CaballeroyDinghuai Zhangy
Jean-Christophe Gagnon-AudetyYoshua BengioyIoannis Mitliagkasy
Irina Rishy
Abstract
The invariance principle from causality is at the heart of notable approaches such
as invariant risk minimization (IRM) that seek to address out-of-distribution (OOD)
generalization failures. Despite the promising theory, invariance principle-based
approaches fail in common class",2021,Unknown
Invariant Causal Imitation Learning for Generalizable Policies,"Invariant Causal Imitation Learning for
Generalizable Policies
Ioana Bica⇤
University of Oxford, Oxford, UK
The Alan Turing Institute, London, UK
ioana.bica@eng.ox.ac.ukDaniel Jarrett⇤
University of Cambridge, Cambridge, UK
daniel.jarrett@maths.cam.ac.uk
Mihaela van der Schaar
University of Cambridge, Cambridge, UK
University of California, Los Angeles, USA
The Alan Turing Institute, London, UK
mv472@cam.ac.uk
Abstract
Consider learning an imitation policy on the basis of demonstrated behavior f",2021,Unknown
Inverse-Weighted Survival Games,"Inverse-Weighted Survival Games
Xintian Han
NYU
xintian.han@nyu.eduMark Goldstein
NYU
goldstein@nyu.eduAahlad Puli
NYU
aahlad@nyu.edu
Thomas Wies
NYU
wies@cs.nyu.eduAdler J. Perotte
Columbia University
adler.perotte@columbia.eduRajesh Ranganath
NYU
rajeshr@cims.nyu.edu
Abstract
Deep models trained through maximum likelihood have achieved state-of-the-art
results for survival analysis. Despite this training scheme, practitioners evaluate
models under other criteria, such as binary classiﬁcation",2021,Unknown
Invertible Tabular GANs_ Killing Two Birds with One Stone for Tabular Data Synthesis,"Invertible Tabular GANs: Killing Two Birds with One
Stone for Tabular Data Synthesis
Jaehoon Lee
Yonsei University
ljh5694@yonsei.ac.krJihyeon Hyeong
Yonsei University
jiji.hyeong@yonsei.ac.krJinsung Jeon
Yonsei University
Jjsjjs0902@yonsei.ac.kr
Noseong Park
Yonsei University
noseong@yonsei.ac.krJihoon Cho
Samsung SDS
jihoon1.cho@samsung.com
Abstract
Tabular data synthesis has received wide attention in the literature. This is because
available data is often limited, incomplete, or cannot be ob",2021,Unknown
IQ-Learn_ Inverse soft-Q Learning for Imitation,"IQ-Learn: Inverse soft-Q Learning for Imitation
Divyansh Garg Shuvam Chakraborty Chris Cundy
Jiaming Song Stefano Ermon
Stanford University
{divgarg, shuvamc, cundy, tsong, ermon}@stanford.edu
Abstract
In many sequential decision-making problems (e.g., robotics control, game play-
ing, sequential prediction), human or expert data is available containing useful
information about the task. However, imitation learning (IL) from a small amount
of expert data can be challenging in high-dimensional en",2021,Unknown
Is Automated Topic Model Evaluation Broken_ The Incoherence of Coherence,"Is Automated Topic Model Evaluation Broken?:
The Incoherence of Coherence
Alexander Hoyle∗Pranav Goel∗Denis Peskov∗Andrew Hian-Cheong∗
Computer Science
Jordan Boyd-Graber Philip Resnik
CS, iSchool, UMIACS ,LSC UMIACS , Lingusitics
University of Maryland
{hoyle,pgoel1,dpeskov,andrewhc,jbg,resnik}@cs.umd.edu
Abstract
Topic model evaluation, like evaluation of other unsupervised methods, can be contentious.
However, the field has coalesced around automated estimates of topic coherence, which rely
o",2021,Unknown
Iterative Causal Discovery in the Possible Presence of Latent Confounders and Selection Bias,"Iterative Causal Discovery in the Possible Presence of
Latent Confounders and Selection Bias
Raanan Y. Rohekar, Shami Nisimov, Yaniv Gurwicz, Gal Novik
Intel Labs
{raanan.yehezkel, shami.nisimov, yaniv.gurwicz, gal.novik}@intel.com
Abstract
We present a sound and complete algorithm, called iterative causal discovery (ICD),
for recovering causal graphs in the presence of latent confounders and selection
bias. ICD relies on the causal Markov and faithfulness assumptions and recovers
the equivalenc",2021,Unknown
Iterative Connecting Probability Estimation for Networks,"Iterative Connecting Probability Estimation for
Networks
Yichen Qin
University of Cincinnati
qinyn@ucmail.uc.eduLinhan Yu
Renmin University of China
yulinhan47@foxmail.comYang Li∗
Renmin University of China
yang.li@ruc.edu.cn
Abstract
Estimating the probabilities of connections between vertices in a random network
using an observed adjacency matrix is an important task for network data analy-
sis. Many existing estimation methods are based on certain assumptions on net-
work structure, which lim",2021,Unknown
Iterative Methods for Private Synthetic Data_ Unifying Framework and New Methods,"Iterative Methods for Private Synthetic Data:
Unifying Framework and New Methods
Terrance Liu
Carnegie Mellon University
Pittsburgh, PA 15213
terrancl@andrew.cmu.eduGiuseppe Vietri
University of Minnesota
Minneapolis, MN 55455
vietr002@umn.eduZhiwei Steven Wu
Carnegie Mellon University
Pittsburgh, PA 15213
zstevenwu@cmu.edu
Abstract
We study private synthetic data generation for query release, where the goal is to
construct a sanitized version of a sensitive dataset, subject to differential pr",2021,Unknown
Iteratively Reweighted Least Squares for Basis Pursuit with Global Linear Convergence Rate,"Iteratively Reweighted Least Squares for Basis
Pursuit with Global Linear Convergence Rate
Christian Kümmerlex
Department of Applied Mathematics & Statistics
Johns Hopkins University
Claudio Mayrink Verdunyx
Department of Mathematics and Department of Electrical and Computer Engineering
Technical University of Munich
Dominik Stögerzx
Department of Mathematics
KU Eichstätt–Ingolstadt
Abstract
The recovery of sparse data is at the core of many applications in machine learning
and signal processin",2021,Unknown
Kernel Functional Optimisation,"Kernel Functional Optimisation
Arun Kumar A V , Alistair Shilton, Santu Rana, Sunil Gupta, Svetha Venkatesh
Applied Artiﬁcial Intelligence Institute (A2I2), Deakin University
Waurn Ponds, Geelong, Australia
{aanjanapuravenk, alistair.shilton, santu.rana, sunil.gupta,
svetha.venkatesh}@deakin.edu.au
Abstract
Traditional methods for kernel selection rely on parametric kernel functions or
a combination thereof and although the kernel hyperparameters are tuned, these
methods often provide sub-optima",2021,Unknown
KS-GNN_ Keywords Search over Incomplete Graphs via Graphs Neural Network,"KS-GNN: Keywords Search over Incomplete Graphs
via Graph Neural Network
Yu Hao
University of New South Wales
NSW, Australia
yu.hao@unsw.edu.auXin Cao
University of New South Wales
NSW, Australia
xin.cao@unsw.edu.au
Yufan Sheng
University of New South Wales
NSW, Australia
yufan.sheng@unsw.edu.auYixiang Fang
Chinese University of Hong
Kong, Shenzhen, China
fangyixiang@cuhk.edu.cn
Wei Wang
The Hong Kong University of Science
and Technology, Guangzhou, China
weiwcs@ust.hk
Abstract
Keyword search is",2021,Unknown
Landmark-RxR_ Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision,"Landmark-RxR: Solving Vision-and-Language
Navigation with Fine-Grained Alignment Supervision
Keji He1,2Yan Huang1,2Qi Wu3Jianhua Yang5Dong An1,4Shuanglin Sima1,2
Liang Wang∗1,2,6,7
1Center for Research on Intelligent Perception and Computing
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
2School of Artiﬁcial Intelligence, University of Chinese Academy of Sciences
3School of Computer Science, University of Adelaide
4School of Future Technology, Uni",2021,Unknown
Learning Compact Representations of Neural Networks using DiscriminAtive Masking (DAM),"Learning Compact Representations of Neural
Networks using DiscriminAtive Masking (DAM)
Jie Bu∗
Virginia Tech
jayroxis@vt.eduArka Daw∗
Virginia Tech
darka@vt.edu
M. Maruf∗
Virginia Tech
marufm@vt.eduAnuj Karpatne
Virginia Tech
karpatne@vt.edu
Abstract
A central goal in deep learning is to learn compact representations of features at
every layer of a neural network, which is useful for both unsupervised representa-
tion learning and structured network pruning. While there is a growing body of
work",2021,Unknown
Learning Conjoint Attentions for Graph Neural Nets,"Learning Conjoint Attentions for Graph Neural Nets
Tiantian He1,2Yew-Soon Ong1,2Lu Bai1,2
1Agency for Science, Technology and Research (A*STAR)
2DSAIR, Nanyang Technological University
f He_Tiantian,Bai_Lu g @ihpc.a-star.edu.sg, Ong_Yew_Soon@hq.a-star.edu.sg
f tiantian.he,bailu,asysong g @ntu.edu.sg
Abstract
In this paper, we present Conjoint Attentions (CAs), a class of novel learning-
to-attend strategies for graph neural networks (GNNs). Besides considering the
layer-wise node features propag",2021,Unknown
Learning Domain Invariant Representations in Goal-conditioned Block MDPs,"Learning Domain Invariant Representations in
Goal-conditioned Block MDPs
Beining Han
IIIS, Tsinghua University
bouldinghan@gmail.comChongyi Zheng
Carnegie Mellon University
chongyiz@andrew.cmu.edu
Harris Chan Keiran Paster Michael R. Zhang Jimmy Ba
University of Toronto & Vector Institute
{hchan, keirp, michael, jba}@cs.toronto.edu
Abstract
Deep Reinforcement Learning (RL) is successful in solving many complex Markov
Decision Processes (MDPs) problems. However, agents often face unanticipated
en",2021,Unknown
Learning Dynamic Graph Representation of Brain Connectome with Spatio-Temporal Attention,"Learning Dynamic Graph Representation of Brain
Connectome with Spatio-Temporal Attention
Byung-Hoon Kim
Department of Psychiatry
Institute of Behavioral Sciences in Medicine
College of Medicine, Yonsei University
egyptdj@yonsei.ac.krJong Chul Ye
Department of Bio/Brain Engineering
Kim Jaechul Graduate School of AI
KAIST
jong.ye@kaist.ac.kr
Jae-Jin Kim
Department of Psychiatry
Institute of Behavioral Sciences in Medicine
College of Medicine, Yonsei University
jaejkim@yonsei.ac.kr
Abstract
Functi",2021,Unknown
Learning Equilibria in Matching Markets from Bandit Feedback,"Learning Equilibria in Matching Markets from
Bandit Feedback
Meena Jagadeesany
UC Berkeley
mjagadeesan@berkeley.eduAlexander Weiy
UC Berkeley
awei@berkeley.edu
Yixin Wang
UC Berkeley
ywang@eecs.berkeley.eduMichael I. Jordan
UC Berkeley
jordan@cs.berkeley.eduJacob Steinhardt
UC Berkeley
jsteinhardt@berkeley.edu
Abstract
Large-scale, two-sided matching platforms must ﬁnd market outcomes that align
with user preferences while simultaneously learning these preferences from data.
But since preference",2021,Unknown
Learning Knowledge Graph-based World Models of Textual Environments,"Learning Knowledge Graph-based
World Models of Textual Environments
Prithviraj Ammanabrolu
School of Interactive Computing
Georgia Institute of Technology
raj.ammanabrolu@gatech.eduMark O. Riedl
School of Interactive Computing
Georgia Institute of Technology
riedl@cc.gatech.edu
Abstract
World models improve a learning agent’s ability to efﬁciently operate in interactive
and situated environments. This work focuses on the task of building world models
of text-based game environments. Text-based g",2021,Unknown
Learning on Random Balls is Sufficient for Estimating (Some) Graph Parameters,"Learning on Random Balls is Sufﬁcient
for Estimating (Some) Graph Parameters
Takanori Maehara
Facebook AI
London, United Kingdom
tmaehara@fb.comHoang NT
Tokyo Tech & RIKEN AIP
Tokyo, Japan
hoangnt@net.c.titech.ac.jp
Abstract
Theoretical analyses for graph learning methods often assume a complete obser-
vation of the input graph. Such an assumption might not be useful for handling
any-size graphs due to the scalability issues in practice. In this work, we develop a
theoretical framework for graph",2021,Unknown
Learning One Representation to Optimize All Rewards,"Learning One Representation to Optimize All
Rewards
Ahmed Touati⇤
Mila, University of Montreal
ahmed.touati@umontreal.caYann Ollivier
Facebook Artiﬁcial Intelligence Research
Paris
yol@fb.com
Abstract
We introduce the forward-backward (FB) representation of the dynamics of a
reward-free Markov decision process. It provides explicit near-optimal policies for
any reward speciﬁed a posteriori. During an unsupervised phase, we use reward-
free interactions with the environment to learn two represent",2021,Unknown
Learning Optimal Predictive Checklists,"Learning Optimal Predictive Checklists
Haoran Zhang
Massachusetts Institute of Technology
haoranz@mit.eduQuaid Morris
Memorial Sloan Kettering Cancer Center
morrisq@mskcc.org
Berk Ustun*
UC San Diego
berk@ucsd.eduMaryzeh Ghassemi*
Massachusetts Institute of Technology
mghassem@mit.edu
Abstract
Checklists are simple decision aids that are often used to promote safety and
reliability in clinical applications. In this paper, we present a method to learn
checklists for clinical decision support. We ",2021,Unknown
Learning Space Partitions for Path Planning,"Learning Space Partitions for Path Planning
Kevin Yang1Tianjun Zhang1Chris Cummins2Brandon Cui2Benoit Steiner2
Linnan Wang3Joseph E. Gonzalez1Dan Klein1Yuandong Tian2
1UC Berkeley2Facebook AI Research3Brown University
{yangk,tianjunz,jegonzal,klein}@berkeley.edu
{cummins,bcui,benoitsteiner,yuandong}@fb.com
linnan_wang@brown.edu
Abstract
Path planning, the problem of efﬁciently discovering high-reward trajectories, often
requires optimizing a high-dimensional and multimodal reward function. Pop",2021,Unknown
Learning Stochastic Majority Votes by Minimizing a PAC-Bayes Generalization Bound,"Learning Stochastic Majority Votes by
Minimizing a PAC-Bayes Generalization Bound
Valentina Zantedeschi123Paul Viallard4Emilie Morvant4Rémi Emonet4
Amaury Habrard4Pascal Germain5Benjamin Guedj123
1Inria, Lille - Nord Europe research centre, France2The Inria London Programme, France and UK
3University College London, Department of Computer Science, Centre for Artiﬁcial Intelligence, UK
4Univ Lyon, UJM-Saint-Etienne, CNRS, Institut d Optique Graduate School,
Laboratoire Hubert Curien UMR 5516, F-4",2021,Unknown
Learning to Adapt via Latent Domains for Adaptive Semantic Segmentation,"Learning to Adapt via Latent Domains for Adaptive
Semantic Segmentation
Yunan Liu, Shanshan Zhang, Yang Li, Jian Yang
PCA Lab, Key Lab of Intelligent Perception and Systems
for High-Dimensional Information of Ministry of Education,
Jiangsu Key Lab of Image and Video Understanding for Social Security,
School of Computer Science and Engineering,
Nanjing University of Science and Technology, Nanjing, China
{liuyunan, shanshan.zhang, yangli1995, csjyang}@njust.edu.cn
Abstract
Domain adaptive semant",2021,Unknown
Learning to Execute_ Efficient Learning of Universal Plan-Conditioned Policies in Robotics,"Learning to Execute: Efﬁciently Learning Universal
Plan-Conditioned Policies in Robotics
Ingmar Schubert1, Danny Driess1, Ozgur S. Oguz2, and Marc Toussaint1
1Learning and Intelligent Systems Group, TU Berlin, Germany
2Machine Learning and Robotics Lab, University of Stuttgart, Germany
{ingmar.schubert@,danny.driess@campus.,toussaint@}tu-berlin.de
ozgur.oguz@ipvs.uni-stuttgart.de
Abstract
Applications of Reinforcement Learning (RL) in robotics are often limited by high
data demand. On the other ",2021,Unknown
Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware  Adversarial Training,"Learning to Generate Realistic Noisy Images via
Pixel-level Noise-aware Adversarial Training
Yuanhao Cai1;2,Xiaowan Hu1;2,Haoqian Wang1;2;,
Yulun Zhang3,Hanspeter Pﬁster4,Donglai Wei5
1Shenzhen International Graduate School, Tsinghua University,
2Shenzhen Institute of Future Media Technology,
3ETH Zürich,4Harvard University,5Boston College
Abstract
Existing deep learning real denoising methods require a large amount of noisy-
clean image pairs for supervision. Nonetheless, capturing a real nois",2021,Unknown
Learning to Learn Graph Topologies,"Learning to Learn Graph TopologiesXingyue PuUniversity of Oxfordxpu@robots.ox.ac.ukTianyue Cao Xiaoyun ZhangShanghai Jiao Tong University{vanessa_,xiaoyun.zhang}@sjtu.edu.cnXiaowen DongUniversity of Oxfordxdong@robots.ox.ac.ukSiheng Chen⇤Shanghai Jiao Tong Universitysihengc@sjtu.edu.cnAbstractLearning a graph topology to reveal the underlying relationship between dataentities plays an important role in various machine learning and data analysistasks. Under the assumption that structured data var",2021,Unknown
Learning to See by Looking at Noise,"Learning to See by Looking at Noise
Manel Baradad
MIT CSAIL
mbaradad@mit.eduJonas Wulff
MIT CSAIL
jwulff@csail.mit.eduTongzhou Wang
MIT CSAIL
tongzhou@mit.edu
Phillip Isola
MIT CSAIL
phillipi@mit.eduAntonio Torralba
MIT CSAIL
torralba@mit.edu
Abstract
Current vision systems are trained on huge datasets, and these datasets come with
costs: curation is expensive, they inherit human biases, and there are concerns over
privacy and usage rights. To counter these costs, interest has surged in learni",2021,Unknown
Learning to Select Exogenous Events for Marked Temporal Point Process,"Learning to Select Exogenous Events
for Marked Temporal Point Process
Ping ZhangRishabh IyerAshish TendulkaryGaurav AggarwalyAbir Dex
UT Dallas,yGoogle Inc.,xIIT Bombay.
{Ping.Zhang,rishabh.iyer}@utdallas.edu,
{ashishvt,gauravaggarwal}@google.com, abir@cse.iitb.ac.in
Abstract
Marked temporal point processes (MTPPs) have emerged as a powerful modeling
tool for a wide variety of applications which are characterized using discrete
events localized in continuous time. In this context, the events ",2021,Unknown
Limiting fluctuation and trajectorial stability of multilayer neural networks with mean field training,"Limiting ﬂuctuation and trajectorial stability of
multilayer neural networks with mean ﬁeld training
Huy Tuan Pham
Department of Mathematics, Stanford UniversityPhan-Minh Nguyen⇤
The V oleon Group
Abstract
The mean ﬁeld theory of multilayer neural networks centers around a particu-
lar inﬁnite-width scaling, in which the learning dynamics is shown to be closely
tracked by the mean ﬁeld limit. A random ﬂuctuation around this inﬁnite-width
limit is expected from a large-width expansion to the next",2021,Unknown
Lip to Speech Synthesis with Visual Context Attentional GAN,"Lip to Speech Synthesis with Visual Context
Attentional GAN
Minsu Kim, Joanna Hong, Yong Man Ro
Image and Video Systems Lab
KAIST
{ms.k, joanna2587, ymro}@kaist.ac.kr
Abstract
In this paper, we propose a novel lip-to-speech generative adversarial network,
Visual Context Attentional GAN (VCA-GAN), which can jointly model local and
global lip movements during speech synthesis. Speciﬁcally, the proposed VCA-
GAN synthesizes the speech from local lip visual features by ﬁnding a mapping
function of ",2021,Unknown
Local Explanation of Dialogue Response Generation,"Local Explanation of Dialogue Response Generation
Yi-Lin Tuan1, Connor Pryor2, Wenhu Chen1, Lise Getoor2, William Yang Wang1
1University of California, Santa Barbara
2University of California, Santa Cruz
{ytuan, wenhuchen, william}@cs.ucsb.edu
{cfpryor, getoor}@ucsc.edu
Abstract
In comparison to the interpretation of classiﬁcation models, the explanation of
sequence generation models is also an important problem, however it has seen little
attention. In this work, we study model-agnostic explana",2021,Unknown
"Localization, Convexity, and Star Aggregation","Localization, Convexity, and Star Aggregation
Suhas Vijaykumar
Statistics Center and Dept. of Economics
Massachusetts Institute of Technology
Cambridge, MA 02139
suhasv@mit.edu
Abstract
Offset Rademacher complexities have been shown to provide tight upper bounds for
the square loss in a broad class of problems including improper statistical learning
and online learning. We show that the offset complexity can be generalized to any
loss that satisﬁes a certain general convexity condition. Further",2021,Unknown
Locally private online change point detection,"Locally private online change point detection
Thomas Berrett
Department of Statistics
University of Warwick
Coventry, CV4 7AL, U.K.
tom.berrett@warwick.ac.ukYi Yu
Department of Statistics
University of Warwick
Coventry, CV4 7AL, U.K.
yi.yu.2@warwick.ac.uk
Abstract
We study online change point detection problems under the constraint of local
differential privacy (LDP) where, in particular, the statistician does not have access
to the raw data. As a concrete problem, we study a multivariate nonpar",2021,Unknown
Long Short-Term Transformer for Online Action Detection,"Long Short-Term Transformer for
Online Action Detection
Mingze Xu Yuanjun Xiong Hao Chen Xinyu Li
Wei Xia Zhuowen Tu Stefano Soatto
Amazon/AWS AI
{xumingze,yuanjx,hxen,xxnl,wxia,ztu,soattos}@amazon.com
Abstract
We present Long Short-term TRansformer (LSTR), a temporal modeling algo-
rithm for online action detection, which employs a long- and short-term memory
mechanism to model prolonged sequence data. It consists of an LSTR encoder
that dynamically leverages coarse-scale historical information",2021,Unknown
Looking Beyond Single Images for Contrastive Semantic Segmentation Learning,"Looking Beyond Single Images for Contrastive
Semantic Segmentation Learning
Feihu Zhang Philip Torr
University of OxfordRené RanftlStephan R. Richter
Intel Labs
Abstract
We present an approach to contrastive representation learning for semantic
segmentation. Our approach leverages the representational power of existing
feature extractors to ﬁnd corresponding regions across images. These cross-image
correspondences are used as auxiliary labels to guide the pixel-level selection of
positive and ",2021,Unknown
Low-Rank Constraints for Fast Inference in Structured Models,"Low-Rank Constraints for Fast Inference in
Structured Models
Justin T. Chiu
Cornell University
jtc257@cornell.eduYuntian Deng
Harvard University
dengyuntian@seas.harvard.edu
Alexander M. Rush
Cornell University
arush@cornell.edu
Abstract
Structured distributions, i.e. distributions over combinatorial spaces, are commonly
used to learn latent probabilistic representations from observed data. However,
scaling these models is bottlenecked by the high computational and memory
complexity with respe",2021,Unknown
Luna_ Linear Unified Nested Attention,"Luna: Linear Uniﬁed Nested Attention
Xuezhe Ma
ISI, USC
xuezhema@isi.eduXiang Kong
LTI, CMU
xiangk@cs.cmu.eduSinong Wang
Facebook AI
sinongwang@fb.com
Chunting Zhou
LTI, CMU
chuntinz@cs.cmu.eduJonathan May
ISI, USC
jonmay@isi.eduHao Ma, Luke Zettlemoyer
Facebook AI
{haom, lsz}@fb.com
Abstract
The quadratic computational and memory complexities of the Transformer’s at-
tention mechanism have limited its scalability for modeling long sequences. In
this paper, we propose Luna, a linear uniﬁed ne",2021,Unknown
Matrix factorisation and the interpretation of geodesic distance,"Matrix factorisation and the interpretation of
geodesic distance
Nick Whiteley
University of Bristol
nick.whiteley@bristol.ac.ukAnnie Gray
University of Bristol
annie.gray@bristol.ac.uk
Patrick Rubin-Delanchy
University of Bristol
patrick.rubin-delanchy@bristol.ac.uk
Abstract
Given a graph or similarity matrix, we consider the problem of recovering a
notion of true distance between the nodes, and so their true positions. We show
that this can be accomplished in two steps: matrix factorisation, f",2021,Unknown
MAUVE_ Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers,"MAUVE: Measuring the Gap
Between Neural Text and Human Text
using Divergence Frontiers
Krishna Pillutla1Swabha Swayamdipta2Rowan Zellers1John Thickstun3
Sean Welleck1,2Yejin Choi1,2Zaid Harchaoui4
1Paul G. Allen School of Computer Science & Engineering, University of Washington
2Allen Institute for Artiﬁcial Intelligence
3Department of Computer Science, Stanford University
4Department of Statistics, University of Washington
Abstract
As major progress is made in open-ended text generation, measur",2021,Unknown
Maximum Likelihood Training of Score-Based Diffusion Models,"Maximum Likelihood Training of
Score-Based Diffusion Models
Yang Song
Computer Science Department
Stanford University
yangsong@cs.stanford.eduConor Durkan
School of Informatics
University of Edinburgh
conor.durkan@ed.ac.uk
Iain Murray
School of Informatics
University of Edinburgh
i.murray@ed.ac.ukStefano Ermon
Computer Science Department
Stanford University
ermon@cs.stanford.edu
Abstract
Score-based diffusion models synthesize samples by reversing a stochastic process
that diffuses data to noi",2021,Unknown
MCMC Variational Inference via Uncorrected Hamiltonian Annealing,"MCMC Variational Inference via Uncorrected
Hamiltonian Annealing
Tomas Geffner
College of Information and Computer Science
University of Massachusetts, Amherst
Amherst, MA
tgeffner@cs.umass.eduJustin Domke
College of Information and Computer Science
University of Massachusetts, Amherst
Amherst, MA
domke@cs.umass.edu
Abstract
Given an unnormalized target distribution we want to obtain approximate samples
from it and a tight lower bound on its (log) normalization constant logZ. Annealed
Importance",2021,Unknown
Medical Dead-ends and Learning to Identify High-Risk States and Treatments,"Medical Dead-ends and Learning to Identify
High-risk States and Treatments
Mehdi Fatemi
Microsoft Research
mehdi.fatemi@microsoft.comTaylor W. Killian
University of Toronto, Vector Institute
twkillian@cs.toronto.edu
Jayakumar Subramanian
Media and Data Science Research, Adobe India
jayakumar.subramanian@gmail.comMarzyeh Ghassemi
Massachusetts Institute of Technology
mghassem@mit.edu
Abstract
Machine learning has successfully framed many sequential decision making prob-
lems as either supervised ",2021,Unknown
Memory-efficient Patch-based Inference for Tiny Deep Learning,"MCUNetV2: Memory-Efﬁcient Patch-based
Inference for Tiny Deep Learning
Ji Lin1Wei-Ming Chen1Han Cai1Chuang Gan2Song Han1
1MIT2MIT-IBM Watson AI Lab
https://mcunet.mit.edu
Abstract
Tiny deep learning on microcontroller units (MCUs) is challenging due to the
limited memory size. We ﬁnd that the memory bottleneck is due to the imbalanced
memory distribution in convolutional neural network (CNN) designs: the ﬁrst
several blocks have an order of magnitude larger memory usage than the rest of
the netw",2021,Unknown
Meta-Learning Reliable Priors in the Function Space,"Meta-Learning Reliable Priors in the Function Space
Jonas Rothfuss
ETH Zurich
jonas.rothfuss@inf.ethz.chDominique Heyn
ETH Zurich
heynd@student.ethz.ch
Jinfan Chen
ETH Zurich
georgcjf@gmail.comAndreas Krause
ETH Zurich
krausea@ethz.ch
Abstract
When data are scarce, meta-learning can improve a learner’s accuracy by harness-
ing previous experience from related learning tasks. However, existing methods
have unreliable uncertainty estimates which are often overconﬁdent. Addressing
these shortcoming",2021,Unknown
MetaAvatar_ Learning Animatable Clothed Human Models from Few Depth Images,"MetaAvatar: Learning Animatable
Clothed Human Models from Few Depth Images
Shaofei Wang1
shaofei.wang@inf.ethz.chMarko Mihajlovic1
marko.mihajlovic@inf.ethz.ch
Qianli Ma1;2
qianli.ma@tue.mpg.deAndreas Geiger2;3
a.geiger@uni-tuebingen.de
Siyu Tang1
siyu.tang@inf.ethz.ch
1ETH Zürich2Max Planck Institute for Intelligent Systems, Tübingen3University of Tübingen
Abstract
In this paper, we aim to create generalizable and controllable neural signed distance
ﬁelds (SDFs) that represent clothed humans fr",2021,Unknown
Minimizing Polarization and Disagreement in Social Networks via Link Recommendation,"Minimizing Polarization and Disagreement in Social
Networks via Link Recommendation
Liwang Zhu, Qi Bao, and Zhongzhi Zhang
Shanghai Key Lab of Intelligent Information Processing, Fudan University, Shanghai, China
School of Computer Science, Fudan University, Shanghai 200433, China
{19210240147, 20110240002, zhangzz}@fudan.edu.cn
Abstract
Individual’s opinions are fundamentally shaped and evolved by their interactions
with other people, and social phenomena such as disagreement and polarization
",2021,Unknown
Mirror Langevin Monte Carlo_ the Case Under Isoperimetry,"Mirror Langevin Monte Carlo: the Case Under
Isoperimetry
Qijia Jiang⇤
UT Austin
qjiang@austin.utexas.edu
Abstract
Motivated by the connection between sampling and optimization, we study a mirror
descent analogue of Langevin dynamics and analyze three different discretization
schemes, giving nonasymptotic convergence rate under functional inequalities such
as Log-Sobolev in the corresponding metric. Compared to the Euclidean setting, the
result reveals intricate relationship between the underlyin",2021,Unknown
Misspecified Gaussian Process Bandit Optimization,"Misspeciﬁed Gaussian Process Bandit Optimization
Ilija Bogunovic
ETH ZürichAndreas Krause
ETH Zürich
Abstract
We consider the problem of optimizing a black-box function based on noisy
bandit feedback. Kernelized bandit algorithms have shown strong empirical and
theoretical performance for this problem. They heavily rely on the assumption
that the model is well-speciﬁed, however, and can fail without it. Instead, we
introduce a misspeciﬁed kernelized bandit setting where the unknown function can
",2021,Unknown
Mitigating Covariate Shift in Imitation Learning via Offline Data With Partial Coverage,"Mitigating Covariate Shift in Imitation Learning
via Ofﬂine Data Without Great Coverage
Jonathan D. Chang
Department of Computer Science
Cornell University
jdc396@cornell.eduMasatoshi Uehara
Department of Computer Science
Cornell University
mu223@cornell.edu
Dhruv Sreenivas
Department of Computer Science
Cornell University
ds844@cornell.eduRahul Kidambiy
Amazon Search & AI
rk773@cornell.eduWen Sun
Department of Computer Science
Cornell University
ws455@cornell.edu
Abstract
This paper studies o",2021,Unknown
MixACM_ Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps,"MixACM: Mixup-Based Robustness Transfer via
Distillation of Activated Channel Maps
Muhammad Awais1, 2y, Fengwei Zhou1, Chuanlong Xie1, Jiawei Li1,
Sung-Ho Bae2z, Zhenguo Li1
1Huawei Noah’s Ark Lab
2Department of Computer Science, Kyung-Hee University, South Korea
awais@khu.ac.kr ,{zhoufengwei, xie.chuanlong, li.jiawei}@huawei.com ,
shbae@khu.ac.kr ,li.zhenguo@huawei.com
Abstract
Deep neural networks are susceptible to adversarially crafted, small and impercep-
tible changes in the natural inp",2021,Unknown
Mixed Supervised Object Detection by Transferring Mask Prior and Semantic Similarity,"Mixed Supervised Object Detection by Transferring
Mask Prior and Semantic Similarity
Yan Liu, Zhijie Zhang, Li Niuy, Junjie Chen, Liqing Zhangy
MoE Key Lab of Artiﬁcial Intelligence
Department of Computer Science and Engineering
Shanghai Jiao Tong University
{loseover, zzj506506, ustcnewly, chen.bys}@sjtu.edu.cn
zhang-lq@cs.sjtu.edu.cn
Abstract
Object detection has achieved promising success, but requires large-scale fully-
annotated data, which is time-consuming and labor-extensive. Therefore",2021,Unknown
Mixture weights optimisation for Alpha-Divergence Variational Inference,"Mixture weights optimisation for Alpha-Divergence
Variational Inference
Kamélia Daudel1,2∗, Randal Douc3
1: LTCI, Télécom Paris, Institut Polytechnique de Paris, France
2: Department of Statistics, University of Oxford, United Kingdom
3: SAMOV AR, Télécom SudParis, Institut Polytechnique de Paris, France
Abstract
This paper focuses on α-divergence minimisation methods for Variational Inference.
We consider the case where the posterior density is approximated by a mixture
model and we investigate",2021,Unknown
Model Adaptation_ Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data,"Model Adaptation: Historical Contrastive Learning
for Unsupervised Domain Adaptation without Source
Data
Jiaxing Huang, Dayan Guan, Aoran Xiao, Shijian Lu
School of Computer Science Engineering, Nanyang Technological University
{Jiaxing.Huang, Dayan.Guan, Aoran.Xiao, Shijian.Lu}@ntu.edu.sg
Abstract
Unsupervised domain adaptation aims to align a labeled source domain and an
unlabeled target domain, but it requires to access the source data which often raises
concerns in data privacy, data portab",2021,Unknown
Multi-Agent Reinforcement Learning for Active Voltage Control on Power Distribution Networks,"Multi-Agent Reinforcement Learning for Active
Voltage Control on Power Distribution Networks
Jianhong Wang
Imperial College London
jianhong.wang16@imperial.ac.ukWangkun Xu
Imperial College London
wangkun.xu18@imperial.ac.uk
Yunjie Guy
University of Bath
yg934@bath.ac.ukWenbin Song
Shanghaitech University
songwb@shanghaitech.edu.cnTim C. Greenz
Imperial College London
t.green@imperial.ac.uk
Abstract
This paper presents a problem in power networks that creates an exciting and yet
challenging rea",2021,Unknown
Multi-Objective SPIBB_ Seldonian Offline Policy Improvement with Safety Constraints in Finite MDPs,"Multi-Objective SPIBB: Seldonian Offline Policy
Improvement with Safety Constraints in Finite MDPs
Harsh Satija
McGill University, Mila
harsh.satija@mail.mcgill.caPhilip S. Thomas
University of Massachusetts
pthomas@cs.umass.edu
Joelle Pineau
McGill University, Mila, Facebook AI Research
jpineau@cs.mcgill.caRomain Laroche
Microsoft Research
romain.laroche@microsoft.com
Abstract
We study the problem of Safe Policy Improvement (SPI) under constraints in the
offline Reinforcement Learning (RL) sett",2021,Unknown
Multi-view Contrastive Graph Clustering,"Multi-view Contrastive Graph Clustering 
Erlin Pan, Zhao Kang∗ 
School of Computer Science and Engineering, 
University of Electronic Science and Technology of China, Chengdu, China 
wujisixsix6@gmail.com zkang@uestc.edu.cn 
Abstract 
With the explosive growth of information technology, multi-view graph data have 
become increasingly prevalent and valuable. Most existing multi-view clustering 
techniques either focus on the scenario of multiple graphs or multi-view attributes. 
In this paper, we",2021,Unknown
Multiclass Boosting and the Cost of Weak Learning,"Multiclass Boosting and the Cost of Weak Learning
Nataly Brukhim
Princeton University
Google AI Princeton
nbrukhim@princeton.eduElad Hazan
Princeton University
Google AI Princeton
ehazan@princeton.edu
Shay Moran
Technion
Google Research
smoran@technion.ac.ilIndraneel Mukherjee
indraneel.mukherjee@protonmail.com
Robert E. Schapire
Microsoft Research
schapire@microsoft.com
Abstract
Boosting is an algorithmic approach which is based on the idea of combining weak
and moderately inaccurate hypotheses",2021,Unknown
Multimodal Few-Shot Learning with Frozen Language Models,"Multimodal Few-Shot Learning with
Frozen Language Models
Maria Tsimpoukelli
DeepMind
mrts@deepmind.comJacob Menick
DeepMind
University College London
jmenick@deepmind.comSerkan Cabi
DeepMind
cabi@deepmind.com
S. M. Ali Eslami
DeepMind
aeslami@deepmind.comOriol Vinyals
DeepMind
vinyals@deepmind.comFelix Hill
DeepMind
felixhill@deepmind.com
Abstract
When trained at sufﬁcient scale, auto-regressive language models exhibit the
notable ability to learn a new language task after being prompted with",2021,Unknown
Near Optimal Policy Optimization via REPS,"Near Optimal Policy Optimization via REPS
Aldo Pacchiano
Microsoft Research
apacchiano@microsoft.comJonathan Lee
Stanford University
jnl@stanford.eduPeter L. Bartlett
UC Berkeley
peter@berkeley.edu
Oﬁr Nachum
Google
ofirnachum@google.com
Abstract
Since its introduction a decade ago, relative entropy policy search (REPS) has
demonstrated successful policy learning on a number of simulated and real-world
robotic domains, not to mention providing algorithmic components used by many
recently propose",2021,Unknown
Near-Optimal Multi-Perturbation Experimental Design for Causal Structure Learning,"Near-Optimal Multi-Perturbation Experimental
Design for Causal Structure Learning
Scott Sussex
Department of Computer Science
ETH Zürich
Zürich, Switzerland
scott.sussex@inf.ethz.chAndreas Krause
Department of Computer Science
ETH Zürich
Zürich, Switzerland
Caroline Uhler
Laboratory for Information & Decision Systems
Massachusetts Institute of Technology
Cambridge, MA
Abstract
Causal structure learning is a key problem in many domains. Causal structures
can be learnt by performing experiments on",2021,Unknown
Neighborhood Reconstructing Autoencoders,"Neighborhood Reconstructing Autoencoders
Yonghyeon Lee1Hyeokjun Kwon1Frank C. Park1;2
Seoul National University1Saige Research2
{yhlee, hj.kwon}@robotics.snu.ac.kr fcp@snu.ac.kr
Abstract
Vanilla autoencoders often produce manifolds that overﬁt to noisy training data,
or have the wrong local connectivity and geometry. Autoencoder regularization
techniques, e.g., the denoising autoencoder, have had some success in reducing
overﬁtting, whereas recent graph-based methods that exploit local connectiv",2021,Unknown
Neural Additive Models_ Interpretable Machine Learning with Neural Nets,"Neural Additive Models:
Interpretable Machine Learning with Neural Nets
Rishabh Agarwal
Google Research, Brain TeamLevi Melnick
Microsoft Research
Nicholas Frosst
CohereXuezhou Zhang
University of Wisconsin-MadisonBen Lengerich
MIT
Rich Caruana
Microsoft ResearchGeoffrey E. Hinton
Google Research, Brain Team
Abstract
Deep neural networks (DNNs) are powerful black-box predictors that have achieved
impressive performance on a wide variety of tasks. However, their accuracy comes
at the cost of int",2021,Unknown
Neural Auto-Curricula in Two-Player Zero-Sum Games,"Neural Auto-Curricula
Xidong Feng⇤,1, Oliver Slumbers⇤,1, Ziyu Wan2, Bo Liu3,
Stephen McAleer4, Ying Wen2, Jun Wang1, Yaodong Yang†,5
1University College London,2Shanghai Jiao Tong University,
3Institute of Automation, CAS,4University of California, Irvine,
5Institute for AI, Peking University
Abstract
When solving two-player zero-sum games, multi-agent reinforcement learning
(MARL) algorithms often create populations of agents where, at each iteration,
a new agent is discovered as the best resp",2021,Unknown
NeurWIN_ Neural Whittle Index Network For Restless Bandits Via Deep RL,"NeurWIN: Neural Whittle Index Network For
Restless Bandits Via Deep RL
Khaled Nakhleh1, Santosh Ganji1, Ping-Chun Hsieh2, I-Hong Hou1, Srinivas Shakkottai1
1Electrical and Computer Engineering Department
Texas A&M University
College Station, TX
{khaled.jamal, sant1, ihou, sshakkot}@tamu.edu
2Department of Computer Science
National Chiao Tung University, Taiwan
pinghsieh@nctu.edu.tw
Abstract
Whittle index policy is a powerful tool to obtain asymptotically optimal solutions
for the notoriously int",2021,Unknown
Newton-LESS_ Sparsification without Trade-offs for the Sketched Newton Update,"Newton-LESS: Sparsiﬁcation without Trade-offs
for the Sketched Newton Update
Michał Derezi ´nski
Department of Statistics
University of California, Berkeley
mderezin@berkeley.eduJonathan Lacotte
Department of Electrical Engineering
Stanford University
lacotte@stanford.edu
Mert Pilanci
Department of Electrical Engineering
Stanford University
pilanci@stanford.eduMichael W. Mahoney
ICSI and Department of Statistics
University of California, Berkeley
mmahoney@stat.berkeley.edu
Abstract
In second-ord",2021,Unknown
Noise2Score_ Tweedie’s Approach to Self-Supervised Image Denoising without Clean Images,"Noise2Score: Tweedie’s Approach to Self-Supervised
Image Denoising without Clean Images
Kwanyoung Kim1Jong Chul Ye1;2;3
1Department of Bio and Brain Engineering
2Kim Jaechul Graduate School of AI
3Deptartment of Mathematical Sciences
Korea Advanced Institute of Science and Technology (KAIST)
{cubeyoung, jong.ye}@kaist.ac.kr
Abstract
Recently, there has been extensive research interest in training deep networks to
denoise images without clean reference. However, the representative approaches
such",2021,Unknown
Non-convex Distributionally Robust Optimization_ Non-asymptotic Analysis,"Non-convex Distributionally Robust Optimization:
Non-asymptotic Analysis
Jikai Jin1;Bohang Zhang2;Haiyang Wang3Liwei Wang2;3;4;y
1School of Mathematical Sciences, Peking University
2Key Laboratory of Machine Perception, MOE, School of EECS, Peking University
3Center of Data Science, Peking University4Institute for Artiﬁcial Intelligence, Peking Unviersity
{jkjin,zhangbohang}@pku.edu.cn, wanghaiyang6@stu.pku.edu.cn, wanglw@cis.pku.edu.cn
Abstract
Distributionally robust optimization (DRO) is a ",2021,Unknown
Non-local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation,"Non-Local Latent Relation Distillation for
Self-Adaptive 3D Human Pose Estimation
Jogendra Nath Kundu1Siddharth Seth1Anirudh Jamkhandi1Pradyumna YM1
Varun Jampani2Anirban Chakraborty1R. Venkatesh Babu1
1Indian Institute of Science, Bangalore2Google Research
Abstract
Available 3D human pose estimation approaches leverage different forms of strong
(2D/3D pose) or weak (multi-view or depth) paired supervision. Barring synthetic
or in-studio domains, acquiring such supervision for each new target en",2021,Unknown
Numerical influence of ReLU’(0) on backpropagation,"Numerical inﬂuence of ReLU’(0) on backpropagation
David Bertoin
IRT Saint Exup ´ery
ISAE-SUPAERO
ANITI
Toulouse, France
david.bertoin@irt-saintexupery.comJ´erˆome Bolte
Toulouse School of Economics
Universit ´e Toulouse 1 Capitole
ANITI
Toulouse, France
jbolte@ut-capitole.fr
S´ebastien Gerchinovitz
IRT Saint Exup ´ery
Institut de Math ´ematiques de Toulouse
ANITI
Toulouse, France
sebastien.gerchinovitz@irt-saintexupery.comEdouard Pauwels
CNRS
IRIT, Universit ´e Paul Sabatier
ANITI
Toulouse, Fran",2021,Unknown
NxMTransformer_ Semi-Structured Sparsification for Natural Language Understanding via ADMM,"NxMTransformer: Semi-Structured Sparsiﬁcation for
Natural Language Understanding via ADMM
Connor Holmes
Colorado School of Mines
Golden, CO 80401
cholmes@mines.eduMinjia Zhang
Microsoft
Bellevue, WA 98004
minjiaz@microsoft.com
Yuxiong He
Microsoft
Bellevue WA, 98004
yuxhe@microsoft.comBo Wu
Colorado School of Mines
Golden, CO 80401
bwu@mines.edu
Abstract
Natural Language Processing (NLP) has recently achieved great success by using
huge pre-trained Transformer networks. However, these models oft",2021,Unknown
Object-Aware Regularization for Addressing Causal Confusion in Imitation Learning,"Object-Aware Regularization for
Addressing Causal Confusion in Imitation Learning
Jongjin Park1Younggyo Seo1yChang Liu2Li Zhao2
Tao Qin2Jinwoo Shin1Tie-Yan Liu2
1Korea Advanced Institute of Science and Technology
2Microsoft Research Asia
Abstract
Behavioral cloning has proven to be effective for learning sequential decision-
making policies from expert demonstrations. However, behavioral cloning often
suffers from the causal confusion problem where a policy relies on the noticeable
effect of e",2021,Unknown
Offline Meta Reinforcement Learning -- Identifiability Challenges and Effective Data Collection Strategies,"Ofﬂine Meta Reinforcement Learning – Identiﬁability
Challenges and Effective Data Collection Strategies
Ron Dorfman
Technion
rdorfman@campus.technion.ac.ilIdan Shenfeld
Technion
idanshen@campus.technion.ac.il
Aviv Tamar
Technion
avivt@technion.ac.il
Abstract
Consider the following instance of the Ofﬂine Meta Reinforcement Learning
(OMRL) problem: given the complete training logs of Nconventional RL agents,
trained onNdifferent tasks, design a meta-agent that can quickly maximize reward
in a new,",2021,Unknown
Offline Reinforcement Learning as One Big Sequence Modeling Problem,"Ofﬂine Reinforcement Learning as One Big
Sequence Modeling Problem
Michael Janner Qiyang Li Sergey Levine
University of California at Berkeley
{janner, qcli}@berkeley.edu svlevine@eecs.berkeley.edu
Abstract
Reinforcement learning (RL) is typically concerned with estimating stationary
policies or single-step models, leveraging the Markov property to factorize prob-
lems in time. However, we can also view RL as a generic sequence modeling
problem, with the goal being to produce a sequence of actio",2021,Unknown
On Calibration and Out-of-Domain Generalization,"On Calibration and Out-of-domain Generalization
Yoav Wald⇤
Johns Hopkins University
yoav.wald@gmail.comAmir Feder⇤
Technion
amirfeder@gmail.comDaniel Greenfeld
Jether Energy Research
danielgreenfeld3@gmail.com
Uri Shalit
Technion
urishalit@technion.ac.il
Abstract
Out-of-domain (OOD) generalization is a signiﬁcant challenge for machine learn-
ing models. Many techniques have been proposed to overcome this challenge,
often focused on learning models with certain invariance properties. In this work",2021,Unknown
On Component Interactions in Two-Stage Recommender Systems,"On component interactions in
two-stage recommender systems
Jiri Hron
University of CambridgeKarl Krauth
UC BerkeleyMichael I. Jordan
UC Berkeley
Niki Kilbertus
Technical University of Munich
Helmholtz AI, Munich
Abstract
Thanks to their scalability, two-stage recommenders are used by many of today’s
largest online platforms, including YouTube, LinkedIn, and Pinterest. These
systems produce recommendations in two steps: (i) multiple nominators —tuned for
low prediction latency—preselect a small s",2021,Unknown
On Effective Scheduling of Model-based Reinforcement Learning,"On Effective Scheduling of Model-based
Reinforcement Learning
Hang Lai1, Jian Shen1, Weinan Zhangy1, Yimin Huang2,
Xing Zhang2,Ruiming Tang2,Yong Yu1,Zhenguo Li2
1Shanghai Jiao Tong University,2Huawei Noah’s Ark Lab
{laihang, wnzhang}@apex.sjtu.edu.cn
Abstract
Model-based reinforcement learning has attracted wide attention due to its su-
perior sample efﬁciency. Despite its impressive success so far, it is still unclear
how to appropriately schedule the important hyperparameters to achieve ade",2021,Unknown
On Interaction Between Augmentations and Corruptions in Natural Corruption Robustness,"On Interaction Between Augmentations and
Corruptions in Natural Corruption Robustness
Eric Mintun
Facebook AI Research
mintun@fb.comAlexander Kirillov
Facebook AI Research
akirillov@fb.comSaining Xie
Facebook AI Research
s9xie@fb.com
Abstract
Invariance to a broad array of image corruptions, such as warping, noise, or
color shifts, is an important aspect of building robust models in computer vision.
Recently, several new data augmentations have been proposed that signiﬁcantly
improve performanc",2021,Unknown
On Model Calibration for Long-Tailed Object Detection and Instance Segmentation,"On Model Calibration for Long-Tailed
Object Detection and Instance Segmentation
Tai-Yu Pan1Cheng Zhang1Yandong Li2Hexiang Hu2
Dong Xuan1Soravit Changpinyo2Boqing Gong2Wei-Lun Chao1
1The Ohio State University2Google Research
Abstract
Vanilla models for object detection and instance segmentation suffer from the
heavy bias toward detecting frequent objects in the long-tailed setting. Existing
methods address this issue mostly during training, e.g., by re-sampling or re-
weighting. In this paper, ",2021,Unknown
On the Convergence and Sample Efficiency of Variance-Reduced Policy Gradient Method,"On the Convergence and Sample Efﬁciency of
Variance-Reduced Policy Gradient Method
Junyu Zhang
Department of Industrial Systems Engineering and Management
National University of Singapore
Singapore, 119077
junyuz@nus.edu.sg
Chengzhuo Ni
Department of Electrical and Computer Engineering
Princeton University
Princeton, NJ, 08544
chengzhuo.ni@princeton.edu
Zheng Yu
Department of Electrical and Computer Engineering
Princeton University
Princeton, NJ, 08544
zhengy@princeton.eduCsaba Szepesvari
Depart",2021,Unknown
On the Convergence Theory of Debiased Model-Agnostic Meta-Reinforcement Learning,"On the Convergence Theory of Debiased
Model-Agnostic Meta-Reinforcement Learning
Alireza Fallah
EECS Department
Massachusetts Institute of Technology
afallah@mit.eduKristian Georgiev
EECS Department
Massachusetts Institute of Technology
krisgrg@mit.edu
Aryan Mokhtari
ECE Department
The University of Texas at Austin
mokhtari@austin.utexas.eduAsuman Ozdaglar
EECS Department
Massachusetts Institute of Technology
asuman@mit.edu
Abstract
We consider Model-Agnostic Meta-Learning (MAML) methods for Rei",2021,Unknown
On the Existence of The Adversarial Bayes Classifier,"On The Existence of The Adversarial Bayes Classifier
Pranjal Awasthi
Google Research
New York, NY 10011, USA
pranjalawasthi@google.comNatalie S. Frank
Courant Institute
New York, NY 10012
nf1066@nyu.edu
Mehryar Mohri
Google Research & Courant Institute
New York, NY 10011, USA
mohri@google.com
Abstract
Adversarial robustness is a critical property in a variety of modern machine learning
applications. While it has been the subject of several recent theoretical studies,
many important questions rel",2021,Unknown
On the Importance of Gradients for Detecting Distributional Shifts in the Wild,"On the Importance of Gradients for Detecting
Distributional Shifts in the Wild
Rui Huang
Department of Computer Sciences
University of Wisconsin-Madison
huangrui@cs.wisc.eduAndrew Geng
Department of Computer Sciences⇤
University of Wisconsin-Madison
ageng@wisc.edu
Yixuan Li
Department of Computer Sciences
University of Wisconsin-Madison
sharonli@cs.wisc.edu
Abstract
Detecting out-of-distribution (OOD) data has become a critical component in
ensuring the safe deployment of machine learning models",2021,Unknown
On the Out-of-distribution Generalization of Probabilistic Image Modelling,"On the Out-of-distribution Generalization of
Probabilistic Image Modelling
Mingtian Zhang1,2 Andi Zhang2,3Steven McDonagh2
1AI Center, University College London,2Huawei Noah’s Ark Lab,
3Department of Computer Science and Technology, University of Cambridge
mingtian.zhang.17@ucl.ac.uk az381@cam.ac.uk steven.mcdonagh@huawei.com
Abstract
Out-of-distribution (OOD) detection and lossless compression constitute two prob-
lems that can be solved by the training of probabilistic models on a ﬁrst data",2021,Unknown
On the Theory of Reinforcement Learning with Once-per-Episode Feedback,"On the Theory of Reinforcement Learning
with Once-per-Episode Feedback
Niladri S. Chatterji
Stanford University
niladri@cs.stanford.eduAldo Pacchiano
Microsoft Research
apacchiano@microsoft.comPeter L. Bartlett
UC Berkeley
peter@berkeley.edu
Michael I. Jordan
UC Berkeley
jordan@cs.berkeley.edu
Abstract
We study a theory of reinforcement learning (RL) in which the learner receives
binary feedback only once at the end of an episode. While this is an extreme test
case for theory, it is also argua",2021,Unknown
On the Value of Interaction and Function Approximation in Imitation Learning,"On the Value of Interaction and Function
Approximation in Imitation Learning
Nived Rajaraman
University of California, Berkeley
nived.rajaraman@berkeley.eduYanjun Han
University of California, Berkeley
yjhan@berkeley.edu
Lin F. Yang
University of California, Los Angeles
linyang@ee.ucla.eduJingbo Liu
University of Illinois, Urbana-Champaign
jingbol@illinois.edu
Jiantao Jiao
University of California, Berkeley
jiantao@eecs.berkeley.eduKannan Ramchandran
University of California, Berkeley
kannanr@ee",2021,Unknown
Online Facility Location with Multiple Advice,"Online Facility Location with Multiple Advice
Matteo Almanza
Dipartimento di Informatica
Sapienza University
Rome, Italy
almanza@di.uniroma1.itFlavio Chierichetti
Dipartimento di Informatica
Sapienza University
Rome, Italy
flavio@di.uniroma1.itSilvio Lattanzi
Google Research
Zurich, Switzerland
silviol@google.com
Alessandro Panconesi
Dipartimento di Informatica
Sapienza University
Rome, Italy
ale@di.uniroma1.itGiuseppe Re
Dipartimento di Informatica
Sapienza University
Rome, Italy
re@di.uniroma1",2021,Unknown
Online Knapsack with Frequency Predictions,"Online Knapsack with Frequency Predictions
Sungjin Im
Electrical Engineering and Computer Science
University of California, Merced
sim3@ucmerced.eduRavi Kumar
Google Research
Mountain View, CA
ravi.k53@gmail.com
Mahshid Montazer Qaem
Electrical Engineering and Computer Science
University of California, Merced
mmontazerqaem@ucmerced.eduManish Purohit
Google Research
Mountain View, CA
mpurohit@google.com
Abstract
There has been recent interest in using machine-learned predictions to improve the
wo",2021,Unknown
Online Multi-Armed Bandits with Adaptive Inference,"Online Multi-Armed Bandits with Adaptive Inference
Maria Dimakopoulou
Netﬂix
mdimakopoulou@netflix.comZhimei Ren
University of Chicago
zmren@statistics.uchicago.edu
Zhengyuan Zhou
NYU Stern School of Business
zzhou@stern.nyu.edu
Abstract
During online decision making in multi-armed bandits, one needs to conduct
inference on the true mean reward of each arm based on data collected so far
at each step. However, since the arms are adaptively selected–thereby yielding
non-i.i.d. data–conducting infe",2021,Unknown
Optimal Rates for Random Order Online Optimization,"Optimal Rates for Random Order Online Optimization
Uri Sherman
Blavatnik School of Computer Science
Tel Aviv University
urisherman@mail.tau.ac.il .Tomer Koren
Blavatnik School of Computer Science
Tel Aviv University, and Google Research
tkoren@tauex.tau.ac.il .
Yishay Mansour
Blavatnik School of Computer Science
Tel Aviv University, and Google Research
mansour.yishay@gmail.com .
Abstract
Westudyonlineconvexoptimizationintherandomordermodel,recentlyproposed
byGarberetal. [8],wherethelossfunctions",2021,Unknown
Optimality and Stability in Federated Learning_ A Game-theoretic Approach,"Optimality and Stability in Federated Learning:
A Game-theoretic Approach
Kate Donahue
Department of Computer Science
Cornell University
kdonahue@cs.cornell.eduJon Kleinberg
Departments of Computer Science
and Information Science
Cornell University
kleinber@cs.cornell.edu
Abstract
Federated learning is a distributed learning paradigm where multiple agents, each
only with access to local data, jointly learn a global model. There has recently been
an explosion of research aiming not only to improv",2021,Unknown
Optimizing Conditional Value-At-Risk of Black-Box Functions,"Optimizing Conditional Value-At-Risk
of Black-Box Functions
Quoc Phong Nguyen, Zhongxiang Dai, Bryan Kian Hsiang Low, and Patrick Jaillet†
Dept. of Computer Science, National University of Singapore, Republic of Singapore
Dept. of Electrical Engineering and Computer Science, MIT, USA†
{qphong,daizhongxiang,lowkh}@comp.nus.edu.sg ,jaillet@mit.edu†
Abstract
This paper presents two Bayesian optimization (BO) algorithms with theoretical
performance guarantee to maximize the conditional value-at-risk",2021,Unknown
Oracle Complexity in Nonsmooth Nonconvex Optimization,"Oracle Complexity in Nonsmooth Nonconvex
Optimization
Guy Kornowski
Weizmann Institute of Science
guy.kornowski@weizmann.ac.ilOhad Shamir
Weizmann Institute of Science
ohad.shamir@weizmann.ac.il
Abstract
It is well-known that given a smooth, bounded-from-below, and possibly non-
convex function, standard gradient-based methods can ﬁnd ✏-stationary points
(with gradient norm less than ✏) inO(1/✏2)iterations. However, many important
nonconvex optimization problems, such as those associated with tr",2021,Unknown
Overcoming the Convex Barrier for Simplex Inputs,"Overcoming the Convex Barrier for Simplex Inputs
Harkirat Singh
University of Oxford
harkirat@robots.ox.ac.ukM. Pawan Kumar
DeepMind
mpawan@deepmind.com
Philip H.S. Torr
University of Oxford
phst@robots.ox.ac.ukKrishnamurthy (Dj) Dvijotham
DeepMind
dvij@google.com
Abstract
Recent progress in neural network veriﬁcation has challenged the notion of a convex
barrier , that is, an inherent weakness in the convex relaxation of the output of
a neural network. Speciﬁcally, there now exists a tight rela",2021,Unknown
Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement,"Parallel Bayesian Optimization of Multiple Noisy
Objectives with Expected Hypervolume Improvement
Samuel Daulton
Facebook, University of Oxford
sdaulton@fb.comMaximilian Balandat
Facebook
balandat@fb.comEytan Bakshy
Facebook
ebakshy@fb.com
Abstract
Optimizing multiple competing black-box objectives is a challenging problem in
many ﬁelds, including science, engineering, and machine learning. Multi-objective
Bayesian optimization (MOBO) is a sample-efﬁcient approach for identifying
the optimal tra",2021,Unknown
Partition-Based Formulations for Mixed-Integer Optimization of Trained ReLU Neural Networks,"Partition-Based Formulations for Mixed-Integer
Optimization of Trained ReLU Neural Networks
Calvin Tsay
Department of Computing
Imperial College London
c.tsay@imperial.ac.ukJan Kronqvist
Department of Mathematics
KTH Royal Institute of Technology
jankr@kth.se
Alexander Thebelt
Department of Computing
Imperial College London
alexander.thebelt18@imperial.ac.ukRuth Misener
Department of Computing
Imperial College London
r.misener@imperial.ac.uk
Abstract
This paper introduces a class of mixed-intege",2021,Unknown
Pay Better Attention to Attention_ Head Selection in Multilingual and Multi-Domain Sequence Modeling,"Pay Better Attention to Attention: Head Selection in
Multilingual and Multi-Domain Sequence Modeling
Hongyu Gong, Yun Tang, Juan Miguel Pino, Xian Li
Facebook AI Research
{hygong,yuntang,juancarabina,xianl}@fb.com
Abstract
Multi-head attention has each of the attention heads collect salient information
from different parts of an input sequence, making it a powerful mechanism for
sequence modeling. Multilingual and multi-domain learning are common scenarios
for sequence modeling, where the key ch",2021,Unknown
PDE-GCN_ Novel Architectures for Graph Neural Networks Motivated by Partial Differential Equations,"PDE-GCN: Novel Architectures for Graph Neural
Networks Motivated by Partial Differential Equations
Moshe Eliasof
Department of Computer Science
Ben-Gurion University of the Negev
Beer-Sheva, Israel
eliasof@post.bgu.ac.ilEldad Haber
Department of Earth, Ocean and Atmospheric Sciences
University of British Columbia
Vancouver, Canada
ehaber@eoas.ubc.ca
Eran Treister
Department of Computer Science
Ben-Gurion University of the Negev
Beer-Sheva, Israel
erant@cs.bgu.ac.il
Abstract
Graph neural networks",2021,Unknown
Periodic Activation Functions Induce Stationarity,"Periodic Activation Functions Induce Stationarity
Lassi Meronen
Aalto University / Saab Finland Oy
Espoo, Finland
lassi.meronen@aalto.fiMartin Trapp
Aalto University
Espoo, Finland
martin.trapp@aalto.fiArno Solin
Aalto University
Espoo, Finland
arno.solin@aalto.fi
Abstract
Neural network models are known to reinforce hidden data biases, making them
unreliable and difﬁcult to interpret. We seek to build models that ‘know what
they do not know’ by introducing inductive biases in the function space",2021,Unknown
Perturb-and-max-product_ Sampling and learning in discrete energy-based models,"Perturb-and-max-product: Sampling and learning
in discrete energy-based models
Miguel Lázaro-Gredilla, Antoine Dedieu, Dileep George
Vicarious AI
SF Bay Area, CA
{miguel, antoine, dileep}@vicarious.com
Abstract
Perturb-and-MAP offers an elegant approach to approximately sample from an
energy-based model (EBM) by computing the maximum-a-posteriori (MAP) con-
ﬁguration of a perturbed version of the model. Sampling in turn enables learning.
However, this line of research has been hindered by the ge",2021,Unknown
Physics-Aware Downsampling with Deep Learning for Scalable Flood Modeling,"Physics-Aware Downsampling with Deep Learning
for Scalable Flood Modeling
Niv Giladi1,2Zvika Ben-Haim1Sella Nevo1Yossi Matias1Daniel Soudry2
1Google Research
2Technion - Israel Institute of Technology
{giladiniv, daniel.soudry}@gmail.com
{zvika, sellanevo, yossi}@google.com
Abstract
Background. Floods are the most common natural disaster in the world, affecting
the lives of hundreds of millions. Flood forecasting is therefore a vitally important
endeavor, typically achieved using physical water ",2021,Unknown
Play to Grade_ Testing Coding Games as Classifying Markov Decision Process,"Play to Grade: Testing Coding Games as Classifying
Markov Decision Process
Allen Nie
Computer Science
Stanford UniversityEmma Brunskill
Computer Science
Stanford UniversityChris Piech
Computer Science
Stanford University
Abstract
Contemporary coding education often presents students with the task of develop-
ing programs that have user interaction and complex dynamic systems, such as
mouse based games. While pedagogically compelling, there are no contemporary
autonomous methods for providing fe",2021,Unknown
Pooling by Sliced-Wasserstein Embedding,"Pooling by Sliced-Wasserstein Embedding
Navid Naderializadeh
Department of Electrical and Systems Engineering
University of Pennsylvania
Philadelphia, PA 19104
nnaderi@seas.upenn.edu
Joseph F. Comer, Reed W. Andrews, Heiko Hoffmann
HRL Laboratories, LLC.
Malibu, CA 90265
{jfcomer, rwandrews, hhoffmann}@hrl.com
Soheil Kolouri
Computer Science Department
Vanderbilt University
Nashville, TN 37235
soheil.kolouri@vanderbilt.edu
Abstract
Learning representations from sets has become increasingly imp",2021,Unknown
Predicting What You Already Know Helps_ Provable Self-Supervised Learning,"Predicting What You Already Know Helps:
Provable Self-Supervised Learning
Jason D. Lee1, Qi Lei1, Nikunj Saunshi1, Jiacheng Zhuo2
1Princeton University2University of Texas at Austin
{jasonlee@,qilei@,nsaunshi@cs}.princeton.edu ,jzhuo@utexas.edu
Abstract
Self-supervised representation learning solves auxiliary prediction tasks (known
as pretext tasks) without requiring labeled data to learn useful semantic represen-
tations. These pretext tasks are created solely using the input features, such as",2021,Unknown
Preserved central model for faster bidirectional compression in distributed settings,"Preserved central model for faster bidirectional
compression in distributed settings
Constantin Philippenko Aymeric Dieuleveut
CMAP, École Polytechnique, Institut Polytechnique de Paris
[fistname].[lastname]@polytechnique.edu
Abstract
We develop a new approach to tackle communication constraints in a distributed
learning problem with a central server. We propose and analyze a new algorithm
that performs bidirectional compression and achieves the same convergence rate
as algorithms using only upl",2021,Unknown
Private Non-smooth ERM and SCO in Subquadratic Steps,"Private Non-smooth ERM and SCO in Subquadratic
Steps
Janardhan Kulkarni∗Yin Tat Lee†Daogao Liu‡
Abstract
We study the differentially private Empirical Risk Minimization (ERM) and
Stochastic Convex Optimization (SCO) problems for non-smooth convex func-
tions. We get a (nearly) optimal bound on the excess empirical risk for ERM with
O(N3/2
d1/8+N2
d)gradient queries, which is achieved with the help of subsampling
and smoothing the function via convolution. Combining this result with the iter-
ati",2021,Unknown
Privately Learning Mixtures of Axis-Aligned Gaussians,"Privately Learning Mixtures of Axis-Aligned
Gaussians
Ishaq Aden-Ali
Department of Computing and Software
McMaster University
adenali@mcmaster.caHassan Ashtiani
Department of Computing and Software
McMaster University
zokaeiam@mcmaster.ca
Christopher Liaw
Department of Computer Science
University of Toronto
cvliaw@cs.toronto.edu
Abstract
We consider the problem of learning mixtures of Gaussians under the constraint of
approximate differential privacy. We prove that eO(k2dlog3=2(1=)=2"")samples
",2021,Unknown
Privately Learning Subspaces,"Privately Learning Subspaces
Vikrant Singhal
Cheriton School of Computer Science
University of Waterloo
Waterloo, ON - N2L 3G1, Canada
vikrant.singhal@uwaterloo.caThomas Steinke
Google Research, Brain Team
Mountain View, CA, United States of America
subspace@thomas-steinke.net
Abstract
Private data analysis suffers a costly curse of dimensionality. However, the data
often has an underlying low-dimensional structure. For example, when optimizing
via gradient descent, the gradients often lie in or",2021,Unknown
Probabilistic Attention for Interactive Segmentation,"Probabilistic Attention for Interactive Segmentation
Prasad Gabbur
Apple
pgabbur@apple.comManjot Bilkhu
Apple
mbilkhu@apple.comJavier Movellan
Apple
movellan@apple.com
Abstract
We provide a probabilistic interpretation of attention and show that the standard dot-
product attention in transformers is a special case of Maximum A Posteriori (MAP)
inference. The proposed approach suggests the use of Expectation Maximization
algorithms for online adaptation of key and value model parameters. This app",2021,Unknown
Probing Inter-modality_ Visual Parsing with Self-Attention for Vision-and-Language Pre-training,"Probing Inter-modality: Visual Parsing with
Self-Attention for Vision-Language Pre-training
Hongwei Xue1∗, Yupan Huang2∗, Bei Liu3, Houwen Peng3, Jianlong Fu3, Houqiang Li1, Jiebo Luo4
1University of Science and Technology of China, Hefei, China,
2Sun Yat-sen University, Guangzhou, China,
3Microsoft Research, Beijing, China,
4University of Rochester, Rochester, NY
1gh051120@mail.ustc.edu.cn ,2huangyp28@mail2.sysu.edu.cn ,
3{bei.liu, houwen.peng, jianf}@microsoft.com ,
1lihq@ustc.edu.cn ,4jluo@cs",2021,Unknown
Progressive Feature Interaction Search for Deep Sparse Network,"Progressive Feature Interaction Search for Deep
Sparse Network
Chen Gao1, Yinfeng Li1, Quanming Yao1;2, Depeng Jin1, and Yong Li1
1Beijing National Research Center for Information Science and Technology,
Department of Electronic Engineering, Tsinghua University
24Paradigm Inc.
liyong07@tsinghua.edu.cn
Abstract
Deep sparse networks (DSNs), of which the crux is exploring the high-order feature
interactions, have become the state-of-the-art on the prediction task with high-
sparsity features. Howev",2021,Unknown
Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation,"Prototypical Cross-Attention Networks for
Multiple Object Tracking and Segmentation
Lei Ke1,2Xia Li1Martin Danelljan1Yu-Wing Tai3Chi-Keung Tang2Fisher Yu1
1ETH Zürich2HKUST3Kuaishou Technology
{lkeab,cktang}@cse.ust.hk, {xia.li,martin.danelljan}@vision.ee.ethz.ch
yuwing@gmail.com, i@yf.io
Abstract
Multiple object tracking and segmentation requires detecting, tracking, and seg-
menting objects belonging to a set of given classes. Most approaches only exploit
the temporal dimension to address the ",2021,Unknown
Pruning Randomly Initialized Neural Networks with Iterative Randomization,"Pruning Randomly Initialized Neural Networks
with Iterative Randomization
Daiki Chijiwa†Shin’ya Yamaguchi†Yasutoshi Ida†
Kenji Umakoshi‡Tomohiro Inoue‡
†NTT Computer and Data Science Laboratories, NTT Corporation
‡NTT Social Informatics Laboratories, NTT Corporation
Abstract
Pruning the weights of randomly initialized neural networks plays an important
role in the context of lottery ticket hypothesis. Ramanujan et al. [ 23] empirically
showed that only pruning the weights can achieve remarkable",2021,Unknown
QuPeD_ Quantized Personalization via Distillation with Applications to Federated Learning,"QuPeD: Quantized Personalization via Distillation
with Applications to Federated Learning
Kaan Ozkara
University of California, Los Angeles
kaan@ucla.eduNavjot Singh
University of California, Los Angeles
navjotsingh@ucla.edu
Deepesh Data
University of California, Los Angeles
deepesh.data@gmail.comSuhas Diggavi
University of California, Los Angeles
suhas@ee.ucla.edu
Abstract
Traditionally, federated learning (FL) aims to train a single global model while
collaboratively using multiple clients and",2021,Unknown
ReAct_ Out-of-distribution Detection With Rectified Activations,"ReAct: Out-of-distribution Detection With
Rectiﬁed Activations
Yiyou Sun
Department of Computer Sciences
University of Wisconsin-Madison
sunyiyou@cs.wisc.eduChuan Guo
Facebook AI Research
chuanguo@fb.com
Yixuan Li
Department of Computer Sciences
University of Wisconsin-Madison
sharonli@cs.wisc.edu
Abstract
Out-of-distribution (OOD) detection has received much attention lately due to its
practical importance in enhancing the safe deployment of neural networks. One of
the primary challenges is tha",2021,Unknown
Rebounding Bandits for Modeling Satiation Effects,"Rebounding Bandits for Modeling Satiation Effects
Liu Leqi
Machine Learning Department
Carnegie Mellon University
Pittsburgh, PA 15213
leqi@cs.cmu.eduFatma Kılınç-Karzan
Tepper School of Business
Carnegie Mellon University
Pittsburgh, PA 15213
fkilinc@andrew.cmu.edu
Zachary C. Lipton
Machine Learning Department
Carnegie Mellon University
Pittsburgh, PA 15213
zlipton@cmu.eduAlan L. Montgomery
Tepper School of Business
Carnegie Mellon University
Pittsburgh, PA 15213
alanmontgomery@cmu.edu
Abstract",2021,Unknown
Reconstruction for Powerful Graph Representations,"Reconstruction for Powerful Graph Representations
Leonardo Cotta
Purdue University
cotta@purdue.eduChristopher Morris
Mila – Quebec AI Institute, McGill University
chris@christophermorris.info
Bruno Ribeiro
Purdue University
ribeiro@cs.purdue.edu
Abstract
Graph neural networks (GNNs) have limited expressive power, failing to represent
many graph classes correctly. While more expressive graph representation learning
(GRL) alternatives can distinguish some of these classes, they are signiﬁcantly h",2021,Unknown
Recursive Bayesian Networks_ Generalising and Unifying Probabilistic Context-Free Grammars and Dynamic Bayesian Networks,"Recursive Bayesian Networks:
Generalising and Unifying
Probabilistic Context-Free Grammars and
Dynamic Bayesian Networks
Robert Lieck∗
Digital and Cognitive Musicology Lab
École Polytechnique Fédérale de Lausanne
1015 Lausanne, Switzerland
research@robert-lieck.comMartin Rohrmeier
Digital and Cognitive Musicology Lab
École Polytechnique Fédérale de Lausanne
1015 Lausanne, Switzerland
martin.rohrmeier@epfl.ch
Abstract
Probabilistic context-free grammars (PCFGs) and dynamic Bayesian networks
(DBNs",2021,Unknown
Reducing Collision Checking for Sampling-Based Motion Planning Using Graph Neural Networks,"Reducing Collision Checking for Sampling-Based
Motion Planning Using Graph Neural Networks
Chenning Yu
Computer Science and Engineering
UC San Diego
chy010@ucsd.eduSicun Gao
Computer Science and Engineering
UC San Diego
sicung@ucsd.edu
Abstract
Sampling-based motion planning is a popular approach in robotics for ﬁnding
paths in continuous conﬁguration spaces. Checking collision with obstacles is the
major computational bottleneck in this process. We propose new learning-based
methods for reducin",2021,Unknown
Regime Switching Bandits,"Regime Switching Bandits
Xiang ZhouyYi XiongzNingyuan ChenxXuefeng Gao{
Abstract
We study a multi-armed bandit problem where the rewards exhibit regime switching.
Speciﬁcally, the distributions of the random rewards generated from all arms are
modulated by a common underlying state modeled as a ﬁnite-state Markov chain.
The agent does not observe the underlying state and has to learn the transition
matrix and the reward distributions. We propose a learning algorithm for this
problem, building o",2021,Unknown
Regularized Frank-Wolfe for Dense CRFs_ Generalizing Mean Field and Beyond,"Regularized Frank-Wolfe for Dense CRFs:
Generalizing Mean Field and Beyond
Ð.Khuê Lê-Huu Karteek Alahari
Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK
38000 Grenoble, France
{khue.le,karteek.alahari}@inria.fr
Abstract
We introduce regularized Frank-Wolfe , a general and effective algorithm for in-
ference and learning of dense conditional random ﬁelds (CRFs). The algorithm
optimizes a nonconvex continuous relaxation of the CRF inference problem using
vanilla Frank-Wolfe with approximate u",2021,Unknown
Regularized Softmax Deep Multi-Agent Q-Learning,"Regularized Softmax Deep Multi-Agent Q-Learning
Ling Pan1, Tabish Rashid2, Bei Peng3, Longbo Huang1, Shimon Whiteson2
1Institute for Interdisciplinary Information Sciences, Tsinghua University
pl17@mails.tsinghua.edu.cn ,longbohuang@tsinghua.edu.cn
2University of Oxford
tabish.rashid@cs.ox.ac.uk ,shimon.whiteson@cs.ox.ac.uk
3University of Liverpool
bei.peng@liverpool.ac.uk
Abstract
Tackling overestimation in Q-learning is an important problem that has been
extensively studied in single-agent re",2021,Unknown
Reinforcement Learning in Reward-Mixing MDPs,"Reinforcement Learning in Reward-Mixing MDPs
Jeongyeol Kwon
The University of Texas at Austin
kwonchungli@utexas.eduYonathan Efroni
Microsoft Research, NYC
jonathan.efroni@gmail.com
Constantine Caramanis
The University of Texas at Austin
constantine@utexas.eduShie Mannor
Technion, NVIDIA
shie@ee.technion.ac.il,
smannor@nvidia.com
Abstract
Learning a near optimal policy in a partially observable system remains an elusive
challenge in contemporary reinforcement learning. In this work, we consider
",2021,Unknown
Reliable and Trustworthy Machine Learning for Health Using Dataset Shift Detection,"Reliable and Trustworthy Machine Learning for
Health Using Dataset Shift Detection
Chunjong Park, Anas Awadalla, Tadayoshi Kohno, Shwetak Patel
Paul G. Allen School of Computer Science & Engineering
University of Washington
{cjparkuw, anasa2, yoshi, shwetak}@cs.washington.edu
Abstract
Unpredictable ML model behavior on unseen data, especially in the health domain,
raises serious concerns about its safety as repercussions for mistakes can be fatal.
In this paper, we explore the feasibility of usi",2021,Unknown
Reliable Decisions with Threshold Calibration,"Reliable Decisions with Threshold Calibration
Roshni Sahoo
Stanford University
rsahoo@stanford.eduShengjia Zhao
Stanford University
sjzhao@stanford.edu
Alyssa Chen
UTSW Medical Center
alyssa.chen@utsw.eduStefano Ermon
Stanford University
ermon@stanford.edu
Abstract
Decision makers rely on probabilistic forecasts to predict the loss of different
decision rules before deployment. When the forecasted probabilities match the
true frequencies, predicted losses will be accurate. Although perfect forec",2021,Unknown
Removing Inter-Experimental Variability from Functional Data in Systems Neuroscience,"Removing Inter-Experimental Variability from
Functional Data in Systems Neuroscience
Dominic Gonschorek;1
dominic.gonschorek@cin.uni-tuebingen.de
Larissa Höﬂing;1
larissa.hoefling@uni-tuebingen.deKlaudia P. Szatko1
klaudia.szatko@tuebingen.mpg.de
Katrin Franke1
katrin.franke@cin.uni-tuebingen.deTimm Schubert1
timm.schubert@cin.uni-tuebingen.de
Benjamin A. Dunn2
benjamin.dunn@ntnu.noPhilipp Berens1
philipp.berens@uni-tuebingen.de
David A. Klindt;;2
klindt.david@gmail.comThomas Euler;;1
thomas.e",2021,Unknown
Replay-Guided Adversarial Environment Design,"Replay-Guided Adversarial Environment Design
Minqi Jiang
UCL, FAIRMichael Dennis
UC BerkeleyJack Parker-Holder
University of Oxford
Jakob Foerster
FAIREdward Grefenstette
UCL, FAIRTim Rocktäschel
UCL, FAIR
Abstract
Deep reinforcement learning (RL) agents may successfully generalize to new
settings if trained on an appropriately diverse set of environment and task
conﬁgurations. Unsupervised Environment Design (UED) is a promising self-
supervised RL paradigm, wherein the free parameters of an ",2021,Unknown
Representation Learning Beyond Linear Prediction Functions,"Representation Learning Beyond Linear Prediction
Functions
Ziping Xu
Department of Statistics
University of Michigan
zipingxu@umich.eduAmbuj Tewari
Department of Statistics
University of Michigan
tewaria@umich.edu
Abstract
Recent papers on the theory of representation learning has shown the importance of
a quantity called diversity when generalizing from a set of source tasks to a target
task. Most of these papers assume that the function mapping shared representations
to predictions is linear, ",2021,Unknown
Representation Learning on Spatial Networks,"Representation Learning on Spatial Networks
Zheng Zhang
Department of Computer Science
Emory University
Atlanta, GA 30322, USA
zheng.zhang@emory.eduLiang Zhao
Department of Computer Science
Emory University
Atlanta, GA 30322, USA
liang.zhao@emory.edu
Abstract
Spatial networks are networks for which the nodes and edges are constrained by
geometry and embedded in real space, which has crucial effects on their topolog-
ical properties. Although tremendous success has been achieved in spatial and
ne",2021,Unknown
Repulsive Deep Ensembles are Bayesian,"Repulsive Deep Ensembles are Bayesian
Francesco D’Angelo
ETH Zürich
Zürich, Switzerland
dngfra@gmail.comVincent Fortuin
ETH Zürich
Zürich, Switzerland
fortuin@inf.ethz.ch
Abstract
Deep ensembles have recently gained popularity in the deep learning community
for their conceptual simplicity and efﬁciency. However, maintaining functional
diversity between ensemble members that are independently trained with gradient
descent is challenging. This can lead to pathologies when adding more ensemble
memb",2021,Unknown
ResNEsts and DenseNEsts_ Block-based DNN Models with Improved Representation Guarantees,"ResNEsts and DenseNEsts: Block-based DNN Models
with Improved Representation Guarantees
Kuan-Lin Chen1, Ching-Hua Lee1, Harinath Garudadri2, and Bhaskar D. Rao1
1Department of Electrical and Computer Engineering,2Qualcomm Institute
University of California, San Diego
La Jolla, CA 92093, USA
{kuc029,chl438,hgarudadri,brao}@ucsd.edu
Abstract
Models recently used in the literature proving residual networks (ResNets) are
better than linear predictors are actually different from standard ResNets that",2021,Unknown
ReSSL_ Relational Self-Supervised Learning with Weak Augmentation,"ReSSL: Relational Self-Supervised Learning with
Weak Augmentation
Mingkai Zheng1;2Shan You2;4Fei Wang3
Chen Qian2Changshui Zhang4Xiaogang Wang2;5Chang Xu1
1School of Computer Science, Faculty of Engineering, The University of Sydney
2SenseTime Research3University of Science and Technology of China
4Department of Automation, Tsinghua University,
Institute for Artiﬁcial Intelligence, Tsinghua University (THUAI),
Beijing National Research Center for Information Science and Technology (BNRist)
5The",2021,Unknown
Revealing and Protecting Labels in Distributed Training,"Revealing and Protecting Labels
in Distributed Training
Trung Dang
Boston University
trungvd@bu.eduOm Thakkar
Google
omthkkr@google.comSwaroop Ramaswamy
Google
swaroopram@google.com
Rajiv Mathews
Google
mathews@google.comPeter Chin
Boston University
spchin@bu.eduFrançoise Beaufays
Google
fsb@google.com
Abstract
Distributed learning paradigms such as federated learning often involve transmis-
sion of model updates, or gradients, over a network, thereby avoiding transmission
of private data. Howe",2021,Unknown
Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial Robustness,"Revisiting Hilbert-Schmidt Information Bottleneck
for Adversarial Robustness
Zifeng Wang
Northeastern University
zifengwang@ece.neu.eduTong Jian
Northeastern University
jian@ece.neu.edu
Aria Masoomi
Northeastern University
masoomi.a@northeastern.eduStratis Ioannidis
Northeastern University
ioannidis@ece.neu.eduJennifer Dy
Northeastern University
jdy@ece.neu.edu
a
Abstract
We investigate the HSIC (Hilbert-Schmidt independence criterion) bottleneck as
a regularizer for learning an adversarially ",2021,Unknown
Revisiting Model Stitching to Compare Neural Representations,"Revisiting Model Stitching to Compare Neural
Representations
Yamini Bansal
Harvard University
ybansal@g.harvard.eduPreetum Nakkiran
Harvard University
preetum@cs.harvard.eduBoaz Barak
Harvard University
b@boazbarak.org
Abstract
We revisit and extend model stitching (Lenc & Vedaldi 2015) as a methodology
to study the internal representations of neural networks. Given two trained and
frozen models AandB, we consider a “stitched model” formed by connecting the
bottom-layers of Ato the top-layers of",2021,Unknown
Revitalizing CNN Attention via Transformers in Self-Supervised Visual Representation Learning,"Revitalizing CNN Attentions via Transformers in
Self-Supervised Visual Representation Learning
Chongjian Ge1Youwei Liang2Yibing Song2∗Jianbo Jiao3Jue Wang2Ping Luo1
1The University of Hong Kong2Tencent AI Lab3University of Oxford
rhettgee@connect.hku.hk liangyouwei1@gmail.com yibingsong.cv@gmail.com
jianbo@robots.ox.ac.uk arphid@gmail.com pluo@cs.hku.hk
Abstract
Studies on self-supervised visual representation learning (SSL) improve encoder
backbones to discriminate training samples without labe",2021,Unknown
Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation,"Reward-Free Model-Based Reinforcement Learning
with Linear Function Approximation
Weitong Zhang
Department of Computer Science
University of California, Los Angeles
Los Angeles, CA 90095
weightzero@cs.ucla.eduDongruo Zhou
Department of Computer Science
University of California, Los Angeles
Los Angeles, CA 90095
drzhou@cs.ucla.edu
Quanquan Gu
Department of Computer Science
University of California, Los Angeles
Los Angeles, CA 90095
qgu@cs.ucla.edu
Abstract
We study the model-based reward-free rei",2021,Unknown
Risk-Averse Bayes-Adaptive Reinforcement Learning,"Risk-Averse Bayes-Adaptive Reinforcement Learning
Marc Rigter
Oxford Robotics Institute
University of Oxford
mrigter@robots.ox.ac.ukBruno Lacerda
Oxford Robotics Institute
University of Oxford
bruno@robots.ox.ac.uk
Nick Hawes
Oxford Robotics Institute
University of Oxford
nickh@robots.ox.ac.uk
Abstract
In this work, we address risk-averse Bayes-adaptive reinforcement learning. We
pose the problem of optimising the conditional value at risk (CVaR) of the total
return in Bayes-adaptive Markov deci",2021,Unknown
RMM_ Reinforced Memory Management for Class-Incremental Learning,"RMM: Reinforced Memory Management
for Class-Incremental Learning
Yaoyao Liu1Bernt Schiele1Qianru Sun2
1Max Planck Institute for Informatics, Saarland Informatics Campus
2School of Computing and Information Systems, Singapore Management University
{yaoyao.liu, schiele}@mpi-inf.mpg.de qianrusun@smu.edu.sg
Abstract
Class-Incremental Learning (CIL) [ 40] trains classiﬁers under a strict memory
budget: in each incremental phase, learning is done for new data, most of which
is abandoned to free space ",2021,Unknown
Robust and differentially private mean estimation,"Robust and differentially private mean estimation
Xiyang Liu, Weihao Kong, Sham Kakade, Sewoong Oh
Paul G. Allen School of Computer Science and Engineering,
University of Washington
{xiyangl,whkong,sham,sewoong}@cs.washington.edu
Abstract
In statistical learning and analysis from shared data, which is increasingly widely
adopted in platforms such as federated learning and meta-learning, there are two
major concerns: privacy and robustness. Each participating individual should be
able to contribu",2021,Unknown
Robust Regression Revisited_ Acceleration and Improved Estimation Rates,"Robust Regression Revisited:
Acceleration and Improved Estimation Rates
Arun Jambulapati
Stanford University
jmblpati@stanford.eduJerry Li
Microsoft Research
jerrl@microsoft.comTselil Schramm
Stanford University
tselil@stanford.edu
Kevin Tian
Stanford University
kjtian@stanford.edu
Abstract
We study fast algorithms for statistical regression problems under the strong con-
tamination model, where the goal is to approximately optimize a generalized linear
model (GLM) given adversarially corrupted ",2021,Unknown
Robustifying Algorithms of Learning Latent Trees with Vector Variables,"Robustifying Algorithms of Learning Latent Trees
with Vector Variables
Fengzhuo Zhang
Department of Electrical and Computer Engineering
National University of Singapore
fzzhang@u.nus.edu
Vincent Y. F. Tan
Department of Electrical and Computer Engineering
Department of Mathematics
National University of Singapore
vtan@nus.edu.sg
Abstract
We consider learning the structures of Gaussian latent tree models with vector
observations when a subset of them are arbitrarily corrupted. First, we present
th",2021,Unknown
RoMA_ Robust Model Adaptation for Offline Model-based Optimization,"RoMA: Robust Model Adaptation
for Ofﬂine Model-based Optimization
Sihyun Yu1Sungsoo Ahn2Le Song2,3Jinwoo Shin1
1Korea Advanced Institute of Science and Technology (KAIST)
2Mohamed bin Zayed University of Artiﬁcial Intelligence (MBZUAI)3BioMap
{sihyun.yu, jinwoos}@kaist.ac.kr
{Peter.Ahn, Le.Song}@mbzuai.ac.ae
Abstract
We consider the problem of searching an input maximizing a black-box objective
function given a static dataset of input-output queries. A popular approach to
solving this problem is",2021,Unknown
Sageflow_ Robust Federated Learning against Both Stragglers and Adversaries,"Sageﬂow: Robust Federated Learning against
Both Stragglers and Adversaries
Jungwuk Park
KAIST
savertm@kaist.ac.krDong-Jun Han
KAIST
djhan93@kaist.ac.krMinseok Choi
Jeju National University
ejaqmf@jejunu.ac.kr
Jaekyun Moon
KAIST
jmoon@kaist.edu
Abstract
While federated learning (FL) allows efﬁcient model training with local data at
edge devices, among major issues still to be resolved are: slow devices known
as stragglers and malicious attacks launched by adversaries. While the presence
of both",2021,Unknown
Sample Complexity Bounds for Active Ranking from Multi-wise Comparisons,"Sample Complexity Bounds for Active Ranking from
Multi-wise Comparisons
Wenbo Ren
Dept. Computer Science & Engineering
The Ohio State University
ren.453@osu.eduJia Liu
Dept. Electrical & Computer Engineering
The Ohio State University
liu.1736@osu.edu
Ness B. Shroff
Dept. Electrical & Computer Engineering and Computer Science & Engineering
The Ohio State University
shroff.11@osu.edu
Abstract
We study the sample complexity (i.e., the number of comparisons needed) bounds
for actively ranking a set ",2021,Unknown
Sample Complexity of Tree Search Configuration_ Cutting Planes and Beyond,"Sample Complexity of Tree Search Conﬁguration:
Cutting Planes and Beyond
Maria-Florina Balcan
School of Computer Science
Carnegie Mellon University
ninamf@cs.cmu.eduSiddharth Prasad
Computer Science Department
Carnegie Mellon University
sprasad2@cs.cmu.eduTuomas Sandholm
Computer Science Department
Carnegie Mellon University
Optimized Markets, Inc.
Strategic Machine, Inc.
Strategy Robot, Inc.
sandholm@cs.cmu.edu
Ellen Vitercik
EECS Department
UC Berkeley
vitercik@berkeley.edu
Abstract
Cutting-pl",2021,Unknown
Sample Selection for Fair and Robust Training,"Sample Selection for Fair and Robust Training
Yuji Roh
KAIST
yuji.roh@kaist.ac.krKangwook Lee
University of Wisconsin-Madison
kangwook.lee@wisc.edu
Steven Euijong Whang
KAIST
swhang@kaist.ac.krChangho Suh
KAIST
chsuh@kaist.ac.kr
Abstract
Fairness and robustness are critical elements of Trustworthy AI that need to be
addressed together. Fairness is about learning an unbiased model while robustness
is about learning from corrupted data, and it is known that addressing only one of
them may have an",2021,Unknown
Scalable Inference in SDEs by Direct Matching of the Fokker–Planck–Kolmogorov Equation,"Scalable Inference in SDEs by Direct Matching of the
Fokker–Planck–Kolmogorov Equation
Arno Solin
Aalto University
Espoo, Finland
arno.solin@aalto.fiElla Tamir
Aalto University
Espoo, Finland
ella.tamir@aalto.fiPrakhar Verma
Aalto University
Espoo, Finland
prakhar.verma@aalto.fi
Abstract
Simulation-based techniques such as variants of stochastic Runge–Kutta are the
de facto approach for inference with stochastic differential equations (SDEs) in
machine learning. These methods are general-purpose",2021,Unknown
Scalable Intervention Target Estimation in Linear Models,"Scalable Intervention Target Estimation in Linear
Models
Burak Varıcı
Rensselaer Polytechnic Institute
varicb@rpi.eduKarthikeyan Shanmugam
IBM Research AI
karthikeyan.shanmugam2@ibm.com
Prasanna Sattigeri
IBM Research AI
psattig@us.ibm.comAli Tajer
Rensselaer Polytechnic Institute
tajer@ecse.rpi.edu
Abstract
This paper considers the problem of estimating the unknown intervention targets
in a causal directed acyclic graph from observational and interventional data. The
focus is on soft interventi",2021,Unknown
Scaling Neural Tangent Kernels via Sketching and Random Features,"Scaling Neural Tangent Kernels
via Sketching and Random Features
Amir Zandieh∗
Max-Planck-Institut für Informatik
azandieh@mpi-inf.mpg.deInsu Han∗
Yale University
insu.han@yale.eduHaim Avron
Tel Aviv University
haimav@tauex.tau.ac.il
Neta Shoham
Tel Aviv University
shohamne@gmail.comChaewon Kim
KAIST
chaewonk@kaist.ac.krJinwoo Shin
KAIST
jinwoos@kaist.ac.kr
Abstract
The Neural Tangent Kernel (NTK) characterizes the behavior of inﬁnitely-wide
neural networks trained under least squares loss by gr",2021,Unknown
See More for Scene_ Pairwise Consistency Learning for Scene Classification,"See More for Scene: Pairwise Consistency Learning
for Scene Classiﬁcation
Gongwei Chen1;2, Xinhang Song1;2, Bohan Wang1;2, and Shuqiang Jiang1;2;3
1Institute of Computing Technology, Chinese Academy of Sciences
2University of Chinese Academy of Sciences, Beijing
3Institute of Intelligent Computing Technology, Suzhou, CAS
{gongwei.chen, xinhang.song, bohan.wang}@vipl.ict.ac.cn
sqjiang@ict.ac.cn
Abstract
Scene classiﬁcation is a valuable classiﬁcation subtask and has its own characteris-
tics whic",2021,Unknown
Self-Consistent Models and Values,"Self-Consistent Models and Values
Gregory Farquhar
DeepMindKate Baumli
DeepMindZita Marinho
DeepMindAngelos Filos
University of Oxford
Matteo Hessel
DeepMindHado van Hasselt
DeepMindDavid Silver
DeepMind
Abstract
Learned models of the environment provide reinforcement learning (RL) agents
with ﬂexible ways of making predictions about the environment. In particular,
models enable planning, i.e. using more computation to improve value functions
or policies, without requiring additional environment",2021,Unknown
Self-Diagnosing GAN_ Diagnosing Underrepresented Samples in Generative Adversarial Networks,"Self-Diagnosing GAN: Diagnosing Underrepresented
Samples in Generative Adversarial Networks
Jinhee Lee
School of Electrical Engineering
KAIST
jin.lee@kaist.ac.krHaeri Kimy
Samsung Research
Samsung Electronics
haeri.kim@samsung.com
Youngkyu Hongy
NA VER AI Lab
NA VER
youngkyu.hong@navercorp.comHye Won Chungz
School of Electrical Engineering
KAIST
hwchung@kaist.ac.kr
Abstract
Despite remarkable performance in producing realistic samples, Generative Ad-
versarial Networks (GANs) often produce lo",2021,Unknown
Self-Interpretable Model with Transformation Equivariant Interpretation,"Self-Interpretable Model with Transformation
Equivariant Interpretation
Yipei Wang, Xiaoqian Wang
Elmore School of Electrical and Computer Engineering
Purdue University
West Lafayette, IN 47907
wang4865@purdue.edu, joywang@purdue.edu
Abstract
With the proliferation of machine learning applications in the real world, the de-
mand for explaining machine learning predictions continues to grow especially
in high-stakes ﬁelds. Recent studies have found that interpretation methods can
be sensitive an",2021,Unknown
Shapeshifter_ a Parameter-efficient Transformer using Factorized Reshaped Matrices,"Shapeshifter: a Parameter-efﬁcient Transformer
using Factorized Reshaped Matrices
Aliakbar Panahi1;2;Seyran Saeedi1;3;Tom Arodz1;y
1Department of Computer Science, Virginia Commonwealth University, Richmond, V A
2C3 AI, Redwood City, CA
3Dept. of Electrical and Computer Engineering, University of California, Santa Barbara, CA
ali.panahi@c3.ai seyran@ucsb.edu tarodz@vcu.edu
Abstract
Language models employ a very large number of trainable parameters. Despite
being highly overparameterized, these",2021,Unknown
Shift Invariance Can Reduce Adversarial Robustness,"Shift Invariance Can Reduce Adversarial Robustness
Vasu Singla, Songwei Ge
Univeristy of Maryland
{vsingla, songweig}@cs.umd.eduRonen Basri
Weizmann Institute of Science
ronen.basri@weizmann.ac.il
David Jacobs
Univeristy of Maryland
dwj@cs.umd.edu
Abstract
Shift invariance is a critical property of CNNs that improves performance on
classiﬁcation. However, we show that invariance to circular shifts can also lead to
greater sensitivity to adversarial attacks. We ﬁrst characterize the margin betwe",2021,Unknown
Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection,"Single Layer Predictive Normalized Maximum
Likelihood for Out-of-Distribution Detection
Koby Bibas
School of Electrical Engineering
Tel Aviv University
kobybibas@gmail.comMeir Feder
School of Electrical Engineering
Tel Aviv University
meir@eng.tau.ac.il
Tal Hassner
Facebook AI
talhassner@gmail.com
Abstract
Detecting out-of-distribution (OOD) samples is vital for developing machine learn-
ing based models for critical safety systems. Common approaches for OOD
detection assume access to some OOD s",2021,Unknown
SketchGen_ Generating Constrained CAD Sketches,"SketchGen: Generating Constrained CAD Sketches
Wamiq Reyaz Para1Shariq Farooq Bhat1Paul Guerrero2
Tom Kelly3Niloy Mitra2;4Leonidas Guibas5Peter Wonka1
1KAUST2Adobe Research3University of Leeds
4University College London5Stanford University
Abstract
Computer-aided design (CAD) is the most widely used modeling approach for
technical design. The typical starting point in these designs is 2D sketches which
can later be extruded and combined to obtain complex three-dimensional assem-
blies. Such sket",2021,Unknown
Skyformer_ Remodel Self-Attention with Gaussian Kernel and Nystr__om Method,"Skyformer: Remodel Self-Attention with Gaussian
Kernel and Nyström Method
Yifan Chen, Qi Zeng, Heng Ji, Yun Yang
University of Illinois Urbana-Champaign
{yifanc10, qizeng2, hengji, yy84}@illinois.edu
Abstract
Transformers are expensive to train due to the quadratic time and space complexity
in the self-attention mechanism. On the other hand, although kernel machines
suffer from the same computation bottleneck in pairwise dot products, several
approximation schemes have been successfully incorp",2021,Unknown
Smooth Bilevel Programming for Sparse Regularization,"Smooth Bilevel Programming
for Sparse Regularization
Clarice Poon, Gabriel Peyréy
Abstract
Iteratively reweighted least square (IRLS) is a popular approach to solve sparsity-
enforcing regression problems in machine learning. State of the art approaches
are more efﬁcient but typically rely on speciﬁc coordinate pruning schemes. In
this work, we show how a surprisingly simple re-parametrization of IRLS, coupled
with a bilevel resolution (instead of an alternating scheme) is able to achieve
top p",2021,Unknown
Smooth Normalizing Flows,"Smooth Normalizing Flows
Jonas KöhleryAndreas KrämeryFrank Noéyzx
yDepartment of Mathematics and Computer Science, Freie Universität Berlin
zDepartment of Physics, Freie Universität Berlin
xDepartment of Chemistry, Rice University, Houston, TX
{jonas.koehler, andreas.kraemer, frank.noe}@fu-berlin.de
Abstract
Normalizing ﬂows are a promising tool for modeling probability distributions in
physical systems. While state-of-the-art ﬂows accurately approximate distributions
and energies, application",2021,Unknown
Solving Graph-based Public Goods Games with Tree Search and Imitation Learning,"Solving Graph-based Public Good Games with Tree
Search and Imitation Learning
Victor-Alexandru Darvariu1;2, Stephen Hailes1, Mirco Musolesi1;2;3
1University College London2The Alan Turing Institute3University of Bologna
{v.darvariu, s.hailes, m.musolesi}@cs.ucl.ac.uk
Abstract
Public goods games represent insightful settings for studying incentives for indi-
vidual agents to make contributions that, while costly for each of them, beneﬁt
the wider society. In this work, we adopt the perspective of",2021,Unknown
Solving Min-Max Optimization with Hidden Structure via Gradient Descent Ascent,"Solving Min-Max Optimization with Hidden
Structure via Gradient Descent Ascent
Lampros Flokas
Department of Computer Science
Columbia University
New York, NY 10025
lamflokas@cs.columbia.eduEmmanouil V . Vlatakis-Gkaragkounis
Department of Computer Science
Columbia University
New York, NY 10025
emvlatakis@cs.columbia.edu
Georgios Piliouras
Singapore University of Technology & Design
georgios.piliouras@sutd.edu.sg
Abstract
Many recent AI architectures are inspired by zero-sum games, however, the",2021,Unknown
Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter,"Solving Soft Clustering Ensemble via k-Sparse
Discrete Wasserstein Barycenter
Ruizhe Qin1Mengying Li2Hu Ding1
1School of Computer Science and Technology
2School of Data Science
University of Science and Technology of China
red46@mail.ustc.edu.cn, limengy@mail.ustc.edu.cn, huding@ustc.edu.cn
Abstract
Clustering ensemble is one of the most important problems in ensemble learning.
Though it has been extensively studied in the past decades, the existing methods
often suffer from the issues like hig",2021,Unknown
Spatiotemporal Joint Filter Decomposition in 3D Convolutional Neural Networks,"Spatiotemporal Joint Filter Decomposition in 3D
Convolutional Neural Networks
Zichen Miao1, Ze Wang1, Xiuyuan Cheng2, and Qiang Qiu1
Purdue University1Duke University2
{miaoz,zewang,qqiu}@purdue.edu xiuyuan.cheng@duke.edu
Abstract
In this paper, we introduce spatiotemporal joint ﬁlter decomposition to decouple
spatial and temporal learning, while preserving spatiotemporal dependency in a
video. A 3D convolutional ﬁlter is now jointly decomposed over a set of spatial and
temporal ﬁlter atoms resp",2021,Unknown
Speedy Performance Estimation for Neural Architecture Search,"Speedy Performance Estimation for Neural
Architecture Search
Binxin Ru1Clare Lyle1Lisa Schut1Miroslav Fil1
Mark van der Wilk2Yarin Gal1
1OATML Group, Department of Computer Science, University of Oxford, UK
2Department of Computing, Imperial College London, UK
Abstract
Reliable yet efﬁcient evaluation of generalisation performance of a proposed archi-
tecture is crucial to the success of neural architecture search (NAS). Traditional
approaches face a variety of limitations: training each archi",2021,Unknown
SSMF_ Shifting Seasonal Matrix Factorization,"SSMF: Shifting Seasonal Matrix Factorization
Koki Kawabata
SANKEN Osaka University
koki@sanken.osaka-u.ac.jpSiddharth Bhatia
National University of Singapore
siddharth@comp.nus.edu.sg
Rui Liu
National University of Singapore
xxliuruiabc@gmail.comMohit Wadhwa
mailmohitwadhwa@gmail.com
Bryan Hooi
National University of Singapore
bhooi@comp.nus.edu.sg
Abstract
Given taxi-ride counts information between departure and destination locations,
how can we forecast their future demands? In general, give",2021,Unknown
Stability and Deviation Optimal Risk Bounds with Convergence Rate $O(1_n)$,"Stability and Deviation Optimal Risk Bounds with
Convergence Rate O(1=n)
Yegor Klochkov
Cambridge-INET, Faculty of Economics
University of Cambridge
yk376@cam.ac.ukNikita Zhivotovskiy
Department of Mathematics
ETH, Zürich
nikita.zhivotovskii@math.ethz.ch
Abstract
The sharpest known high probability generalization bounds for uniformly stable
algorithms (Feldman, V ondrák, NeurIPS 2018, COLT, 2019), (Bousquet, Klochkov,
Zhivotovskiy, COLT, 2020) contain a generally inevitable sampling error term o",2021,Unknown
Stability and Generalization of Bilevel Programming in Hyperparameter Optimization,"Stability and Generalization of Bilevel Programming
in Hyperparameter Optimization
Fan Bao∗, Guoqiang Wu∗, Chongxuan Li∗, Jun Zhu†, Bo Zhang
Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua-Huawei Joint Center for AI
BNRist Center, State Key Lab for Intell. Tech. & Sys., Tsinghua University, Beijing, China
bf19@mails.tsinghua.edu.cn,{guoqiangwu90, chongxuanli1991}@gmail.com,
{dcszj, dcszb}@tsinghua.edu.cn
Abstract
The (gradient-based) bilevel programming framework is widely used in hyperp",2021,Unknown
Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation,"Stabilizing Deep Q-Learning with ConvNets and
Vision Transformers under Data Augmentation
Nicklas Hansen1Hao Su1Xiaolong Wang1
1University of California, San Diego
nihansen@ucsd.edu {haosu,xiw012}@eng.ucsd.edu
Abstract
While agents trained by Reinforcement Learning (RL) can solve increasingly chal-
lenging tasks directly from visual observations, generalizing learned skills to novel
environments remains very challenging. Extensive use of data augmentation is a
promising technique for improving g",2021,Unknown
Statistical Query Lower Bounds for List-Decodable Linear Regression,"Statistical Query Lower Bounds for
List-Decodable Linear Regression
Ilias Diakonikolas
University of Wisconsin-Madison
ilias@cs.wisc.eduDaniel M. Kane
University of California, San Diego
dakane@cs.ucsd.edu
Ankit Pensia
University of Wisconsin-Madison
ankitp@cs.wisc.eduThanasis Pittas
University of Wisconsin-Madison
pittas@wisc.edu
Alistair Stewart
Web 3 Foundation
stewart.al@gmail.com
Abstract
We study the problem of list-decodable linear regression, where an adversary can
corrupt a majority of ",2021,Unknown
Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence,"Stochastic Optimization of Areas Under
Precision-Recall Curves with Provable Convergence
Qi Qiy, Youzhi Luoz, Zhao Xuz, Shuiwang Jiz, Tianbao Yangy
yDepartment of Computer Science, The University of Iowa
zDepartment of Computer Science & Engineering, Texas A&M University
{qi-qi,tianbao-yang}@uiowa.edu, {yzluo,zhaoxu,sji}@tamu.edu
Abstract
Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common
metrics for evaluating classiﬁcation performance for imbalanced problems. Com-
pared ",2021,Unknown
Subgoal Search For Complex Reasoning Tasks,"Subgoal Search For Complex Reasoning Tasks
Konrad Czechowski
University of Warsaw
k.czechowski@mimuw.edu.plTomasz Odrzygó´ zd´ z
University of Warsaw
tomaszo@impan.pl
Marek Zbysi ´nski
University of Warsaw
m.zbysinski@
students.mimuw.edu.plMichał Zawalski
University of Warsaw
m.zawalski@uw.edu.plKrzysztof Olejnik
University of Warsaw
k.olejnik3@
student.uw.edu.pl
Yuhuai Wu
University of Toronto,
Vector Institute
ywu@cs.toronto.eduŁukasz Kuci ´nski
Polish Academy of Sciences
lkucinski@impan.plP",2021,Unknown
Subgroup Generalization and Fairness of Graph Neural Networks,"Subgroup Generalization and Fairness of Graph
Neural Networks
Jiaqi May
jiaqima@umich.eduJunwei Dengy
junweid@umich.eduQiaozhu Meiz
qmei@umich.edu
Abstract
Despite enormous successful applications of graph neural networks (GNNs), theo-
retical understanding of their generalization ability, especially for node-level tasks
where data are not independent and identically-distributed (IID), has been sparse.
The theoretical investigation of the generalization performance is beneﬁcial for
understand",2021,Unknown
Support vector machines and linear regression coincide with very high-dimensional features,"Support vector machines and linear regression
coincide with very high-dimensional features
Navid Ardeshir*
Dept. of Statistics
Columbia University
na2844@columbia.eduClayton Sanford*
Dept. of Computer Science
Columbia University
clayton@cs.columbia.eduDaniel Hsu
Dept. of Computer Science
Columbia University
djhsu@cs.columbia.edu
Abstract
The support vector machine (SVM) and minimum Euclidean norm least squares
regression are two fundamentally different approaches to fitting linear models,
but th",2021,Unknown
SyncTwin_ Treatment Effect Estimation with Longitudinal Outcomes,"SyncTwin: Treatment Effect Estimation with
Longitudinal Outcomes
Zhaozhi Qian
University of Cambridge
zq224@cam.ac.ukYao Zhang
University of Cambridge
yz555@cam.ac.ukIoana Bica
University of Oxford
The Alan Turing Institute
ioana.bica@eng.ox.ac.uk
Angela Mary Wood
University of Cambridge
amw79@medschl.cam.ac.ukMihaela van der Schaar
University of Cambridge
UCLA
The Alan Turing Institute
mv472@cam.ac.uk
Abstract
Most of the medical observational studies estimate the causal treatment effects
using",2021,Unknown
Systematic Generalization with Edge Transformers,"Systematic Generalization with Edge Transformers
Leon Bergen
University of California, San Diego
lbergen@ucsd.eduTimothy J. O’Donnell
McGill University
Quebec Artiﬁcial Intelligence Institute (Mila)
Canada CIFAR AI Chair
Dzmitry Bahdanau
Element AI, a ServiceNow company
McGill University
Quebec Artiﬁcial Intelligence Institute (Mila)
Canada CIFAR AI Chair
Abstract
Recent research suggests that systematic generalization in natural language un-
derstanding remains a challenge for state-of-the-art ",2021,Unknown
T-LoHo_ A Bayesian Regularization Model for Structured Sparsity and Smoothness on Graphs,"T-LoHo: A Bayesian Regularization Model for
Structured Sparsity and Smoothness on Graphs
Changwoo J. Lee
Department of Statistics
Texas A&M University
c.lee@stat.tamu.eduZhao Tang Luo
Department of Statistics
Texas A&M University
ztluo@stat.tamu.eduHuiyan Sang
Department of Statistics
Texas A&M University
huiyan@stat.tamu.edu
Abstract
Graphs have been commonly used to represent complex data structures. In models
dealing with graph-structured data, multivariate parameters may not only exhibit
spa",2021,Unknown
Task-Agnostic Undesirable Feature Deactivation Using Out-of-Distribution Data,"Task-Agnostic Undesirable Feature Deactivation Using
Out-of-Distribution Data
Dongmin Park1, Hwanjun Song2, MinSeok Kim1, Jae-Gil Lee1∗
1KAIST,2NA VER AI Lab
Republic of Korea
{dongminpark, minseokkim, jaegil}@kaist.ac.kr, hwanjun.song@navercorp.com
Abstract
A deep neural network (DNN) has achieved great success in many machine learning
tasks by virtue of its high expressive power. However, its prediction can be easily
biased to undesirable features, which are not essential for solving the targe",2021,Unknown
Temporally Abstract Partial Models,"Temporally Abstract Partial Models
Khimya Khetarpal1,2, Zafarali Ahmed3, Gheorghe Comanici3, Doina Precup1,2,3
1McGill University,2Mila,3DeepMind
Abstract
Humans and animals have the ability to reason and make predictions about different
courses of action at many time scales. In reinforcement learning, option models
(Sutton, Precup & Singh, 1999; Precup, 2000) provide the framework for this
kind of temporally abstract prediction and reasoning. Natural intelligent agents
are also able to focus t",2021,Unknown
Terra_ Imperative-Symbolic Co-Execution of Imperative Deep Learning Programs,"Terra: Imperative-Symbolic Co-Execution of
Imperative Deep Learning Programs
Taebum Kim
Seoul National University, FriendliAI
k.taebum@snu.ac.kr,
ktaebum@friendli.aiEunji Jeong
Samsung Research
eun-ji.jeong@samsung.com
Geon-Woo Kim
Seoul National University, FriendliAI
gwsshs22@snu.ac.kr,
gwsshs22@friendli.aiYunmo Koo
Seoul National University, FriendliAI
mpbb03@snu.ac.kr,
yunmorning@friendli.ai
Sehoon Kim
University of California, Berkeley
sehoonkim@berkeley.eduGyeong-In Yu
Seoul National Uni",2021,Unknown
Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization,"Test-Time Classiﬁer Adjustment Module for
Model-Agnostic Domain Generalization
Yusuke Iwasawa
The University of Tokyo
iwasawa@weblab.t.u-tokyo.ac.jpYutaka Matsuo
The University of Tokyo
matsuo@weblab.t.u-tokyo.ac.jp
Abstract
This paper presents a new algorithm for domain generalization (DG), test-time
template adjuster (T3A) , aiming to robustify a model to unknown distribution shift.
Unlike existing methods that focus on training phase , our method focuses test
phase , i.e., correcting its pred",2021,Unknown
Test-Time Personalization with a Transformer for Human Pose Estimation,"Test-Time Personalization with a Transformer for
Human Pose Estimation
Yizhuo Li
Shanghai Jiao Tong University
liyizhuo@sjtu.edu.cnMiao Hao
UC San Diego
mhao@ucsd.edu
Zonglin Di
UC San Diego
zodi@ucsd.eduNitesh B. Gundavarapu
UC San Diego
nbgundav@ucsd.eduXiaolong Wang
UC San Diego
xiw012@ucsd.edu
Abstract
We propose to personalize a 2D human pose estimator given a set of test images
of a person without using any manual annotations. While there is a signiﬁcant
advancement in human pose estima",2021,Unknown
The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy,"The Adaptive Doubly Robust Estimator
and a Paradox Concerning Logging Policy
Masahiro Kato
CyberAgent, Inc.Kenichiro McAlinn
Temple UniversityShota Yasui
CyberAgent, Inc.
Abstract
Thedoubly robust (DR) estimator, which consists of two nuisance parameters, the
conditional mean outcome and the logging policy (the probability of choosing an
action), is crucial in causal inference. This paper proposes a DR estimator for
dependent samples obtained from adaptive experiments. To obtain an asymptoti-
c",2021,Unknown
The Complexity of Bayesian Network Learning_ Revisiting the Superstructure,"The Complexity of Bayesian Network Learning:
Revisiting the Superstructure
Robert Ganian and Viktoriia Korchemna
Algorithms and Complexity Group, TU Wien
{rganian,vkorchemna}@ac.tuwien.ac.at
Abstract
We investigate the parameterized complexity of Bayesian Network Structure Learn-
ing (BNSL), a classical problem that has received signiﬁcant attention in empirical
but also purely theoretical studies. We follow up on previous works that have
analyzed the complexity of BNSL w.r.t. the so-called supe",2021,Unknown
The Limitations of Large Width in Neural Networks_ A Deep Gaussian Process Perspective,"The Limitations of Large Width in Neural Networks:
A Deep Gaussian Process Perspective
Geoff Pleiss
Columbia University
gmp2162@columbia.eduJohn P. Cunningham
Columbia University
jpc2181@columbia.edu
Abstract
Large width limits have been a recent focus of deep learning research: modulo com-
putational practicalities, do wider networks outperform narrower ones? Answering
this question has been challenging, as conventional networks gain representational
power with width, potentially masking any ne",2021,Unknown
The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations,"The Out-of-Distribution Problem in Explainability
and Search Methods for Feature Importance
Explanations
Peter Hase, Harry Xie, andMohit Bansal
Department of Computer Science
University of North Carolina at Chapel Hill
{peter, fengyu.xie, mbansal}@cs.unc.edu
Abstract
Feature importance (FI) estimates are a popular form of explanation, and they are
commonly created and evaluated by computing the change in model conﬁdence
caused by removing certain input features at test time. For example, in the ",2021,Unknown
The Utility of Explainable AI in Ad Hoc Human-Machine Teaming,"The Utility of Explainable AI in Ad Hoc
Human-Machine Teaming
Rohan Paleja1, Muyleng Ghuy1, Nadun R. Arachchige1, Reed Jensen2, Matthew Gombolay1
1Georgia Institute of Technology,2MIT Lincoln Laboratory
1Atlanta, GA 30332,2Lexington, MA 02420
frpaleja3, mghuy3, nkra3 g@gatech.edu, rjensen@ll.mit.edu mgombolay3@gatech.edu
Abstract
Recent advances in machine learning have led to growing interest in Explainable
AI (xAI) to enable humans to gain insight into the decision-making of machine
learning m",2021,Unknown
There Is No Turning Back_ A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning,"There Is No Turning Back:
A Self-Supervised Approach for
Reversibility-Aware Reinforcement Learning
Nathan Grinsztajn
Inria, Scool Team
CRIStAL, CNRS, Université de Lille
nathan.grinsztajn@inria.frJohan Ferret
Google Research, Brain Team
Inria, Scool Team
CRIStAL, CNRS, Université de Lille
Olivier Pietquin
Google Research, Brain TeamPhilippe Preux
Inria, Scool Team
CRIStAL, CNRS, Université de Lille
Matthieu Geist
Google Research, Brain Team
Abstract
We propose to learn to distinguish reversib",2021,Unknown
"Think Big, Teach Small_ Do Language Models Distil Occam’s Razor_","Think Big, Teach Small:
Do Language Models Distil Occam’s Razor?
Gonzalo Jaimovitch-López1David Castellano-Falcón1Cèsar Ferri1
José Hernández-Orallo1,2
1VRAIN - Universitat Politècnica de València
2Leverhulme Centre for the Future of Intelligence - University of Cambridge
{gonzalojaimovitch,dcastf01}@gmail.com,cferri@dsic.upv.es,jorallo@upv.es
Abstract
Large language models have recently shown a remarkable ability for few-shot
learning, including patterns of algorithmic nature. However, it is st",2021,Unknown
Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods,"Time Discretization-Invariant
Safe Action Repetition for Policy Gradient Methods
Seohong Park
Seoul National University
artberryx@snu.ac.krJaekyeom Kim
Seoul National University
jaekyeom@snu.ac.krGunhee Kim
Seoul National University
gunhee@snu.ac.kr
Abstract
In reinforcement learning, continuous time is often discretized by a time scale
, to which the resulting performance is known to be highly sensitive. In this
work, we seek to ﬁnd a -invariant algorithm for policy gradient (PG) methods,
whi",2021,Unknown
TopicNet_ Semantic Graph-Guided Topic Discovery,"TopicNet: Semantic Graph-Guided Topic Discovery
Zhibin Duan, Yishi Xu, Bo Chen, Dongsheng Wang, Chaojie Wang
National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China
xd_zhibin@163.com, bchen@mail.xidian.edu.cn
Mingyuan Zhou
McCombs School of Business, The University of Texas at Austin
mingyuan.zhou@mccombs.utexas.edu
Abstract
Existing deep hierarchical topic models are able to extract semantically meaningful
topics from a text corpus in an unsupervised manner and automati",2021,Unknown
Towards a Unified Game-Theoretic View of Adversarial Perturbations and Robustness,"A Unified Game-Theoretic Interpretation of
Adversarial Robustness
Jie Rena∗, Die Zhanga∗, Yisen Wangb,c∗, Lu Chena, Zhanpeng Zhoua,
Yiting Chena, Xu Chenga, Xin Wanga, Meng Zhoua,d†, Jie Shie, Quanshi Zhanga‡
aShanghai Jiao Tong University
bKey Lab. of Machine Perception, School of Artificial Intelligence, Peking University
cInstitute for Artificial Intelligence, Peking University
dCarnegie Mellon University
eHuawei technologies Inc.
Abstract
This paper provides a unified view to explain differe",2021,Unknown
Towards Better Understanding of Training Certifiably Robust Models against Adversarial Examples,"Towards Better Understanding of Training Certiﬁably
Robust Models against Adversarial Examples
Sungyoon Lee
Korea Institute for Advanced Study (KIAS)
sungyoonlee@kias.re.krWoojin Lee
Dongguk University-Seoul
wj926@dgu.ac.kr
Jinseong Park
Seoul National Univeristy
jinseong@snu.ac.krJaewook Lee
Seoul National University
jaewook@snu.ac.kr
Abstract
We study the problem of training certiﬁably robust models against adversarial
examples. Certiﬁable training minimizes an upper bound on the worst-case lo",2021,Unknown
Towards Instance-Optimal Offline Reinforcement Learning with Pessimism,"Towards Instance-Optimal Ofﬂine Reinforcement
Learning with Pessimism
Ming Yin1,2andYu-Xiang Wang1
1Department of Computer Science, UC Santa Barbara
2Department of Statistics and Applied Probability, UC Santa Barbara
ming_yin@ucsb.edu yuxiangw@cs.ucsb.edu
Abstract
We study the ofﬂine reinforcement learning (ofﬂine RL) problem, where the goal
is to learn a reward-maximizing policy in an unknown Markov Decision Process
(MDP) using the data coming from a policy . In particular, we consider the sam",2021,Unknown
Towards Lower Bounds on the Depth of ReLU Neural Networks,"Towards Lower Bounds on the Depth
of ReLU Neural Networks
Christoph Hertrich
Technische Universität Berlin
Berlin, Germany
christoph.hertrich@posteo.deAmitabh Basu
Johns Hopkins University
Baltimore, USA
basu.amitabh@jhu.edu
Marco Di Summa
Università degli Studi di Padova
Padua, Italy
disumma@math.unipd.itMartin Skutella
Technische Universität Berlin
Berlin, Germany
martin.skutella@tu-berlin.de
Abstract
We contribute to a better understanding of the class of functions that is represented
by a ne",2021,Unknown
Towards Optimal Strategies for Training Self-Driving Perception Models in Simulation,"Towards Optimal Strategies for Training Self-Driving
Perception Models in Simulation
David Acuna, Jonah Philion, Sanja Fidler
NVIDIA, University of Toronto, Vector Institute
{dacunamarrer, jphilion, sfidler}@nvidia.com
Abstract
Autonomous driving relies on a huge volume of real-world data to be labeled
to high precision. Alternative solutions seek to exploit driving simulators that
can generate large amounts of labeled data with a plethora of content variations.
However, the domain gap between",2021,Unknown
Towards Robust Bisimulation Metric Learning,"Towards Robust Bisimulation Metric Learning
Mete Kemertas
Department of Computer Science
University of Toronto
kemertas@cs.toronto.eduTristan Aumentado-Armstrong
Department of Computer Science
University of Toronto
taumen@cs.toronto.edu
Abstract
Learned representations in deep reinforcement learning (DRL) have to extract task-
relevant information from complex observations, balancing between robustness
to distraction and informativeness to the policy. Such stable and rich representa-
tions, of",2021,Unknown
Towards robust vision by multi-task learning on monkey visual cortex,"Towards robust vision by multi-task learning on
monkey visual cortex
Shahd Safarani,1,*Arne Nix,1-2Konstantin Willeke,1-2Santiago A. Cadena,2-3
Kelli Restivo,4-5George Denfield,6Andreas S. Tolias,4-5Fabian H. Sinz1-5, **
1Institute for Bioinformatics and Medical Informatics, University Tübingen, Germany
2International Max Planck Research School for Intelligent Systems, Tübingen, Germany
3Institute for Computer Science, University of Göttingen, Germany
4Department for Neuroscience, Baylor College",2021,Unknown
Towards Scalable Unpaired Virtual Try-On via Patch-Routed Spatially-Adaptive GAN,"Towards Scalable Unpaired Virtual Try-On via
Patch-Routed Spatially-Adaptive GAN
Zhenyu Xie1, Zaiyu Huang1, Fuwei Zhao1, Haoye Dong2
Michael Kampffmeyer3,Xiaodan Liang1;4
1Shenzhen Campus of Sun Yat-Sen University,2Huya Inc
3UiT The Arctic University of Norway,4Peng Cheng Laboratory
{xiezhy6,huangzy225,zhaofw}@mail2.sysu.edu.cn, donghaoye@huya.com
michael.c.kampffmeyer@uit.no, xdliang328@gmail.com
Abstract
Image-based virtual try-on is one of the most promising applications of human-
centric im",2021,Unknown
Towards Unifying Behavioral and Response Diversity for Open-ended Learning in Zero-sum Games,"Towards Unifying Behavioral and Response Diversity
for Open-ended Learning in Zero-sum Games
Xiangyu Liu1, Hangtian Jia2, Ying Wen1⇤, Yujing Hu2,
Yingfeng Chen2, Changjie Fan2, Zhipeng Hu2, Yaodong Yang3
1Shanghai Jiao Tong University,2Netease Fuxi AI Lab,3Institute for AI, Peking University
liuxiangyu999@sjtu.edu.cn, ying.wen@sjtu.edu.cn, yaodong.yang@pku.edu.cn
Abstract
Measuring and promoting policy diversity is critical for solving games with strong
non-transitive dynamics where strategic cy",2021,Unknown
Tractable Regularization of Probabilistic Circuits,"Tractable Regularization of Probabilistic Circuits
Anji Liu
Department of Computer Science
UCLA
Los Angeles, CA 90095
liuanji@cs.ucla.eduGuy Van den Broeck
Department of Computer Science
UCLA
Los Angeles, CA 90095
guyvdb@cs.ucla.edu
Abstract
Probabilistic Circuits (PCs) are a promising avenue for probabilistic modeling.
They combine advantages of probabilistic graphical models (PGMs) with those
of neural networks (NNs). Crucially, however, they are tractable probabilistic
models, supporting efﬁc",2021,Unknown
Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization,"Transfer Learning of Graph Neural Networks with
Ego-graph Information Maximization
Qi Zhu1, Carl Yang2, Yidan Xu3, Haonan Wang1, Chao Zhang4, Jiawei Han1
1University of Illinois Urbana-Champaign,2Emory University,
3University of Washington,4Georgia Institute of Technology
1{qiz3,haonan3,hanj}@illinois.edu,2j.carlyang@emory.edu ,
3yx2516@uw.edu,4chaozhang@gatech.edu
Abstract
Graph neural networks (GNNs) have achieved superior performance in various
applications, but training dedicated GNNs can ",2021,Unknown
TransformerFusion_ Monocular RGB Scene Reconstruction using Transformers,"TransformerFusion: Monocular RGB Scene
Reconstruction using Transformers
Aljaž Boži ˇc1Pablo Palafox1Justus Thies1;2Angela Dai1Matthias Nießner1
1Technical University of Munich
2Max Planck Institute for Intelligent Systems, Tübingen, Germany
aljazbozic.github.io/transformerfusion
Abstract
We introduce TransformerFusion, a transformer-based 3D scene reconstruction
approach. From an input monocular RGB video, the video frames are processed
by a transformer network that fuses the observations into ",2021,Unknown
TransMatcher_ Deep Image Matching Through Transformers for Generalizable Person Re-identification,"TransMatcher: Deep Image Matching Through
Transformers for Generalizable Person
Re-identiﬁcation
Shengcai Liaoand Ling Shao
Inception Institute of Artiﬁcial Intelligence (IIAI), Abu Dhabi, UAE
https://liaosc.wordpress.com/
Abstract
Transformers have recently gained increasing attention in computer vision. How-
ever, existing studies mostly use Transformers for feature representation learning,
e.g. for image classiﬁcation and dense predictions, and the generalizability of
Transformers is unknown",2021,Unknown
TransMIL_ Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification,"TransMIL: Transformer based Correlated Multiple
Instance Learning for Whole Slide
Image Classiﬁcation
Zhuchen Shao∗ ∗,1,Hao Bian∗,1,Yang Chen∗,1,Yifeng Wang2,Jian Zhang3,Xiangyang Ji4
Yongbing Zhang† †,2
1Tsinghua Shenzhen International Graduate School, Tsinghua University
2Harbin Institute of Technology (Shenzhen)
3School of Electronic and Computer Engineering, Peking University
4Department of Automation, Tsinghua University
Abstract
Multiple instance learning (MIL) is a powerful tool to solve ",2021,Unknown
Truncated Marginal Neural Ratio Estimation,"Truncated Marginal Neural Ratio Estimation
Benjamin Kurt Miller
University of Amsterdam
b.k.miller@uva.nlAlex Cole
University of Amsterdam
a.e.cole@uva.nlPatrick Forré
University of Amsterdam
p.d.forre@uva.nl
Gilles Louppe
University of Liège
g.louppe@uliege.beChristoph Weniger
University of Amsterdam
c.weniger@uva.nl
Abstract
Parametric stochastic simulators are ubiquitous in science, often featuring high-
dimensional input parameters and/or an intractable likelihood. Performing
Bayesian parame",2021,Unknown
Two Sides of Meta-Learning Evaluation_ In vs. Out of Distribution,"Two Sides of Meta-Learning Evaluation:
In vs. Out of Distribution
Amrith Setlur1∗Oscar Li2∗Virginia Smith2
asetlur@cs.cmu.edu oscarli@cmu.edu smithv@cmu.edu
1Language Technologies Institute2Machine Learning Department
School of Computer Science, Carnegie Mellon University
Abstract
We categorize meta-learning evaluation into two settings: in-distribution [ID],
in which the train and test tasks are sampled iidfrom the same underlying task
distribution, and out-of-distribution [OOD], in which they ",2021,Unknown
UCB-based Algorithms for Multinomial Logistic Regression Bandits,"UCB-based Algorithms for
Multinomial Logistic Regression Bandits
Sanae Amani
University of California, Los Angeles
samani@ucla.eduChristos Thrampoulidis
University of British Columbia
cthrampo@ece.ubc.ca
Abstract
Out of the rich family of generalized linear bandits, perhaps the most well studied
ones are logistic bandits that are used in problems with binary rewards: for instance,
when the learner aims to maximize the proﬁt over a user that can select one of
two possible outcomes (e.g., ‘click’ ",2021,Unknown
Understanding Deflation Process in Over-parametrized Tensor Decomposition,"Understanding Deﬂation Process in
Over-parametrized Tensor Decomposition
Rong Ge
Duke University
rongge@cs.duke.eduYunwei Ren*
Shanghai Jiao Tong University
2016renyunwei@sjtu.edu.cn
Xiang Wang*
Duke University
xwang@cs.duke.eduMo Zhou*
Duke University
mozhou@cs.duke.edu
Abstract
In this paper we study the training dynamics for gradient ﬂow on over-parametrized
tensor decomposition problems. Empirically, such training process often ﬁrst ﬁts
larger components and then discovers smaller component",2021,Unknown
Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization,"Understanding End-to-End Model-Based
Reinforcement Learning Methods as Implicit
Parameterization
Clement Gehring
Electrical Engineering and Computer Sciences
Massachusetts Institute of Technology
clement@gehring.io
Kenji Kawaguchi
Center of Mathematical Sciences and Applications
Harvard University
kkawaguchi@fas.harvard.edu
Jiaoyang Huang
Courant Institute of Mathematical Sciences
New York University
jh4427@nyu.eduLeslie Pack Kaelbling
Electrical Engineering and Computer Sciences
Massachusetts I",2021,Unknown
Understanding Instance-based Interpretability of Variational Auto-Encoders,"Understanding Instance-based Interpretability of
Variational Auto-Encoders
Zhifeng Kong
Computer Science and Engineering
University of California San Diego
La Jolla, CA 92093
z4kong@eng.ucsd.eduKamalika Chaudhuri
Computer Science and Engineering
University of California San Diego
La Jolla, CA 92093
kamalika@cs.ucsd.edu
Abstract
Instance-based interpretation methods have been widely studied for supervised
learning methods as they help explain how black box neural networks predict.
However, instan",2021,Unknown
Understanding Partial Multi-Label Learning via Mutual Information,"Understanding Partial Multi-label Learning via
Mutual Information
Xiuwen Gongy;z, Dong Yuany, Wei Baoy
yFaculty of Engineering, The University of Sydney
zHunan Huishiwei Intelligent Technology Co., Ltd.
{xiuwen.gong, dong.yuan, wei.bao}@sydney.edu.au
Abstract
To deal with ambiguities in partial multi-label learning (PML), state-of-the-art
methods perform disambiguation by identifying ground-truth labels directly. How-
ever, there is an essential question:“ Can the ground-truth labels be identiﬁe",2021,Unknown
Understanding the Generalization Benefit of Model Invariance from a Data Perspective,"Understanding the Generalization Beneﬁt of Model
Invariance from a Data Perspective
Sicheng Zhu*, Bang An*, Furong Huang
Department of Computer Science
University of Maryland, College Park
{sczhu, bangan, furongh}@umd.edu
Abstract
Machine learning models that are developed to be invariant under certain types of
data transformations have shown improved generalization in practice. However,
a principled understanding of why invariance beneﬁts generalization is limited.
Given a dataset, there is oft",2021,Unknown
UniDoc_ Unified Pretraining Framework for Document Understanding,"Uniﬁed Pretraining Framework for Document
Understanding
Jiuxiang Gu1, Jason Kuen1, Vlad I. Morariu1, Handong Zhao1,
Nikolaos Barmpalios2, Rajiv Jain1, Ani Nenkova1, Tong Sun1
1Adobe Research,2Adobe Document Cloud
{jigu,kuen,morariu,hazhao,barmpali,rajijain,nenkova,tsun}@adobe.com
Abstract
Document intelligence automates the extraction of information from documents
and supports many business applications. Recent self-supervised learning methods
on large-scale unlabeled document datasets have open",2021,Unknown
Uniform Sampling over Episode Difficulty,"Uniform Sampling over Episode Difﬁculty
Sébastien M. R. Arnold1, Guneet S. Dhillon2, Avinash Ravichandran3, Stefano Soatto3;4
1University of Southern California,2University of Oxford,
3Amazon Web Services,4University of California, Los Angeles
seb.arnold@usc.edu, guneet.dhillon@stats.ox.ac.uk,
ravinash@amazon.com, soattos@amazon.com
Abstract
Episodic training is a core ingredient of few-shot learning to train models on tasks
with limited labelled data. Despite its success, episodic training re",2021,Unknown
Unique sparse decomposition of low rank matrices,"Uniquesparsedecompositionoflowrankmatrices
Dian Jin
Rutgers University
dj370@scarletmail.rutgers.eduXinBing
Cornell University
xb43@cornell.eduYuqian Zhang
Rutgers University
yqz.zhang@rutgers.edu
Abstract
The problem of ﬁnding the unique low dimensional decomposit ion of a
givenmatrixhasbeenafundamentalandrecurrentproblemin manyareas.
Inthispaper,westudytheproblemofseekingauniquedecompo sitionofa
lowrankmatrix Y∈Rp×nthatadmitsasparserepresentation. Speciﬁcally,
weconsider Y=AX∈Rp×nwherethematri",2021,Unknown
Unsupervised Motion Representation Learning with Capsule Autoencoders,"Unsupervised Motion Representation Learning with
Capsule Autoencoders
Ziwei Xuy, Xudong Shenz, Yongkang Wongy, Mohan S Kankanhalliy
ySchool of Computing, National University of Singapore
zNUS Graduate School, National University of Singapore
{ziwei-xu, mohan}@comp.nus.edu.sg
xudong.shen@u.nus.edu, yongkang.wong@nus.edu.sg
Abstract
We propose the Motion Capsule Autoencoder (MCAE), which addresses a key
challenge in the unsupervised learning of motion representations: transforma-
tion invariance. ",2021,Unknown
USCO-Solver_ Solving Undetermined Stochastic Combinatorial Optimization Problems,"USCO-Solver: Solving Undetermined Stochastic
Combinatorial Optimization Problems
Guangmo Tong
Department of Computer and Information Sciences
University of Delaware
amotong@udel.edu
Abstract
Real-world decision-making systems are often subject to uncertainties that have to
be resolved through observational data. Therefore, we are frequently confronted
with combinatorial optimization problems of which the objective function is un-
known and thus has to be debunked using empirical evidence. In con",2021,Unknown
VigDet_ Knowledge Informed Neural Temporal Point Process for Coordination Detection on Social Media,"VigDet: Knowledge Informed Neural Temporal Point
Process for Coordination Detection on Social Media
Yizhou Zhang∗, Karishma Sharma∗, Yan Liu
Department of Computer Science
Viterbi School of Engineering
University of Southern California
{zhangyiz,krsharma,yanliu.cs}@usc.edu
Abstract
Recent years have witnessed an increasing use of coordinated accounts on social
media, operated by misinformation campaigns to influence public opinion and
manipulate social outcomes. Consequently, there is an urgent ",2021,Unknown
Visual Adversarial Imitation Learning using Variational Models,"Visual Adversarial Imitation Learning
using Variational Models
Rafael Rafailov1Tianhe Yu1Aravind Rajeswaran2,3Chelsea Finn1
{rafailov, tianheyu, cbfinn}@stanford.edu, aravraj@fb.com
1Stanford University,2University of Washington,3Facebook AI Research
Abstract
Reward function specification, which requires considerable human effort and itera-
tion, remains a major impediment for learning behaviors through deep reinforce-
ment learning. In contrast, providing visual demonstrations of desired behavi",2021,Unknown
VoiceMixer_ Adversarial Voice Style Mixup,"VoiceMixer: Adversarial Voice Style Mixup
Sang-Hoon Lee1Ji-Hoon Kim2Hyunseung Chung2
Seong-Whan Lee2
{sh_lee, jihoon_kim, hs_chung, sw.lee}@korea.ac.kr
1Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea
2Department of Artiﬁcial Intelligence, Korea University, Seoul, Korea
Abstract
Although recent advances in voice conversion have shown signiﬁcant improvement,
there still remains a gap between the converted voice and target voice. A key factor
that maintains this gap ",2021,Unknown
Voxel-based 3D Detection and Reconstruction of Multiple Objects from a Single Image,"Voxel-based 3D Detection and Reconstruction of
Multiple Objects from a Single Image
Feng Liu Xiaoming Liu
Department of Computer Science and Engineering
Michigan State University, East Lansing MI 48824
{liufeng6, liuxm}@msu.edu
Abstract
Inferring 3D locations and shapes of multiple objects from a single 2D image is
a long-standing objective of computer vision. Most of the existing works either
predict one of these 3D properties or focus on solving both for a single object. One
fundamental challe",2021,Unknown
Weisfeiler and Lehman Go Cellular_ CW Networks,"Weisfeiler and Lehman Go Cellular: CW Networks
Cristian Bodnar⇤
University of Cambridge
cb2015@cam.ac.ukFabrizio Frasca⇤
Imperial College London & Twitter
ffrasca@twitter.com
Nina Otter
UCLA
otter@math.ucla.eduYu Guang Wang
MPI-MIS, SJTU & UNSW
yuguang.wang@unsw.edu.au
Pietro Liò
University of Cambridge
pl219@cam.ac.ukGuido Montúfar
MPI-MIS & UCLA
montufar@math.ucla.eduMichael Bronstein
Imperial College London & Twitter
mbronstein@twitter.com
Abstract
Graph Neural Networks (GNNs) are limited in ",2021,Unknown
What training reveals about neural network complexity,"What training reveals about neural network
complexity
Andreas Loukas
EPFL
andreas.loukas@epfl.chMarinos Poiitis
Aristotle University of Thessaloniki
mpoiitis@csd.auth.grStefanie Jegelka
MIT
stefje@mit.edu
Abstract
This work explores the Benevolent Training Hypothesis (BTH) which argues that
the complexity of the function a deep neural network (NN) is learning can be
deduced by its training dynamics. Our analysis provides evidence for BTH by
relating the NN’s Lipschitz constant at different regio",2021,Unknown
When False Positive is Intolerant_ End-to-End  Optimization with Low FPR for Multipartite Ranking,"When False Positive is Intolerant:
End-to-End Optimization with Low FPR for
Multipartite Ranking
Peisong Wen1,2Qianqian Xu1∗Zhiyong Yang2
Yuan He3Qingming Huang1,2,4,5∗
1Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS
2School of Computer Science and Tech., University of Chinese Academy of Sciences
3Alibaba Group
4BDKM, University of Chinese Academy of Sciences
5Peng Cheng Laboratory
{wenpeisong20z,xuqianqian}@ict.ac.cn
{yangzhiyong21,qmhuang}@ucas.ac.cn heyuan.hy@alibaba-inc.com
A",2021,Unknown
Why Lottery Ticket Wins_ A Theoretical Perspective of Sample Complexity on Sparse Neural Networks,"Why Lottery Ticket Wins? A Theoretical Perspective
of Sample Complexity on Pruned Neural Networks
Shuai Zhang
Rensselaer Polytechnic Institute
Troy, NY , USA 12180
zhangs21@rpi.eduMeng Wang
Rensselaer Polytechnic Institute
Troy, NY , USA 12180
wangm7@rpi.edu
Sijia Liu
Michigan State University
East Lansing, MI, USA 48824
MIT-IBM Watson AI Lab, IBM Research
liusiji5@msu.eduPin-Yu Chen
IBM Research
Yorktown Heights, NY , USA 10562
Pin-Yu.Chen@ibm.com
Jinjun Xiong
University at Buffalo
Buffalo NY ,",2021,Unknown
Wisdom of the Crowd Voting_ Truthful Aggregation of Voter Information and Preferences,"Wisdom of the Crowd Voting: Truthful Aggregation
of Voter Information and Preferences
Grant Schoenebeck
School of Information
University of Michigan
schoeneb@umich.eduBiaoshuai Tao
John Hopcroft Center for Computer Science
Shanghai Jiao Tong University
bstao@sjtu.edu.cn
Abstract
We consider two-alternative elections where voters’ preferences depend on a state
variable that is not directly observable. Each voter receives a private signal that is
correlated to the state variable. V oters may be “",2021,Unknown
Word2Fun_ Modelling Words as Functions for Diachronic Word Representation,"Word2Fun: Modelling Words as Functions for
Diachronic Word Representation
Benyou Wang1, Emanuele Di Buccio1;2, and Massimo Melucci1
1Department of Information Engineering
2Department of Statistical Sciences
University of Padova, Padova, Italy
{wang,dibuccio,melo}@dei.unipd.it
Abstract
Word meaning may change over time as a reﬂection of changes in human so-
ciety. Therefore, modeling time in word representation is necessary for some
diachronic tasks. Most existing diachronic word representation a",2021,Unknown
You are caught stealing my winning lottery ticket! Making a lottery ticket claim its ownership,"You are caught stealing my winning lottery ticket!
Making a lottery ticket claim its ownership
Xuxi Chen1*, Tianlong Chen1*, Zhenyu Zhang2, Zhangyang Wang1
1University of Texas at Austin,2University of Science and Technology of China
{xxchen,tianlong.chen,atlaswang}@utexas.edu,zzy19969@mail.ustc.edu.cn
Abstract
Despite tremendous success in many application scenarios, the training and in-
ference costs of using deep learning are also rapidly increasing over time. The
lottery ticket hypothesis (L",2021,Unknown
Zero Time Waste_ Recycling Predictions in Early Exit Neural Networks,"Zero Time Waste: Recycling Predictions
in Early Exit Neural Networks
Maciej Wołczyky
Jagiellonian UniversityBartosz Wójcik
Jagiellonian University
Klaudia Bałazy
Jagiellonian UniversityIgor Podolak
Jagiellonian UniversityJacek Tabor
Jagiellonian University
Marek ´Smieja
Jagiellonian UniversityTomasz Trzci ´nski
Jagiellonian University,
Warsaw University of Technology,
Tooploox
Abstract
The problem of reducing processing time of large deep learning models is a fun-
damental challenge in many re",2021,Unknown
